<!DOCTYPE HTML>
<html lang="en" class="mocha" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Garuda&#x27;s infra documentation</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="Contains the documentation for the Garuda Linux infrastructure.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="./theme/mdbook-admonish.css">
        <link rel="stylesheet" href="./theme/catppuccin.css">
        <link rel="stylesheet" href="./theme/catppuccin-admonish.css">

    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "mocha" : "mocha";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('mocha')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Welcome</li><li class="chapter-item expanded "><a href="intro.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="general.html"><strong aria-hidden="true">2.</strong> General information</a></li><li class="chapter-item expanded "><a href="common.html"><strong aria-hidden="true">3.</strong> Common tasks</a></li><li class="chapter-item expanded "><a href="important-links.html"><strong aria-hidden="true">4.</strong> Important links</a></li><li class="chapter-item expanded affix "><li class="part-title">Users</li><li class="chapter-item expanded "><a href="users.html"><strong aria-hidden="true">5.</strong> Users</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="users/current_users.html"><strong aria-hidden="true">5.1.</strong> Current users</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Hosts</li><li class="chapter-item expanded "><a href="hosts/aerialis.html"><strong aria-hidden="true">6.</strong> aerialis</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="hosts/aerialis/chaotic-backend.html"><strong aria-hidden="true">6.1.</strong> chaotic-backend</a></li><li class="chapter-item expanded "><a href="hosts/aerialis/docker.html"><strong aria-hidden="true">6.2.</strong> docker</a></li><li class="chapter-item expanded "><a href="hosts/aerialis/docker-proxied.html"><strong aria-hidden="true">6.3.</strong> docker-proxied</a></li><li class="chapter-item expanded "><a href="hosts/aerialis/forum.html"><strong aria-hidden="true">6.4.</strong> forum</a></li><li class="chapter-item expanded "><a href="hosts/aerialis/mail.html"><strong aria-hidden="true">6.5.</strong> mail</a></li><li class="chapter-item expanded "><a href="hosts/aerialis/mastodon.html"><strong aria-hidden="true">6.6.</strong> mastodon</a></li><li class="chapter-item expanded "><a href="hosts/aerialis/postgres.html"><strong aria-hidden="true">6.7.</strong> postgres</a></li><li class="chapter-item expanded "><a href="hosts/aerialis/web-front.html"><strong aria-hidden="true">6.8.</strong> web-front</a></li></ol></li><li class="chapter-item expanded "><a href="hosts/stormwing.html"><strong aria-hidden="true">7.</strong> stormwing</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="hosts/stormwing/chaotic-v4.html"><strong aria-hidden="true">7.1.</strong> chaotic-v4</a></li><li class="chapter-item expanded "><a href="hosts/stormwing/firedragon-runner.html"><strong aria-hidden="true">7.2.</strong> firedragon-runner</a></li><li class="chapter-item expanded "><a href="hosts/stormwing/github-runner.html"><strong aria-hidden="true">7.3.</strong> github-runner</a></li><li class="chapter-item expanded "><a href="hosts/stormwing/iso-runner.html"><strong aria-hidden="true">7.4.</strong> iso-runner</a></li><li class="chapter-item expanded "><a href="hosts/stormwing/web-front.html"><strong aria-hidden="true">7.5.</strong> web-front</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Repository infrastructure</li><li class="chapter-item expanded "><a href="repositories/general.html"><strong aria-hidden="true">8.</strong> General information</a></li><li class="chapter-item expanded "><a href="repositories/pkgbuilds.html"><strong aria-hidden="true">9.</strong> PKGBUILDs</a></li><li class="chapter-item expanded affix "><li class="part-title">Services</li><li class="chapter-item expanded "><a href="services/chaotic-4.0.html"><strong aria-hidden="true">10.</strong> Chaotic 4.0</a></li><li class="chapter-item expanded "><a href="services/discourse.html"><strong aria-hidden="true">11.</strong> Discourse</a></li><li class="chapter-item expanded "><a href="websites/documentation.html"><strong aria-hidden="true">12.</strong> Documentation</a></li><li class="chapter-item expanded "><a href="services/tailscale.html"><strong aria-hidden="true">13.</strong> Tailscale</a></li><li class="chapter-item expanded affix "><li class="part-title">Misc</li><li class="chapter-item expanded "><a href="code-of-conduct.html"><strong aria-hidden="true">14.</strong> Code of Conduct</a></li><li class="chapter-item expanded "><a href="privacy-policy.html"><strong aria-hidden="true">15.</strong> Privacy policy</a></li><li class="chapter-item expanded "><a href="security.html"><strong aria-hidden="true">16.</strong> Security</a></li><li class="chapter-item expanded "><a href="credits.html"><strong aria-hidden="true">17.</strong> Credits</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="latte">Latte</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="frappe">FrappÃ©</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="macchiato">Macchiato</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mocha">Mocha</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Garuda&#x27;s infra documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/garuda-linux/infrastructure-nix" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-code-fork"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="garuda-linux-server-configurations"><a class="header" href="#garuda-linux-server-configurations">Garuda Linux server configurations</a></h1>
<p><a href="https://builtwithnix.org"><img src="https://img.shields.io/static/v1?logo=nixos&amp;logoColor=white&amp;label=&amp;message=Built%20with%20Nix&amp;color=41439a" alt="built with nix" /></a> <a href="https://github.com/garuda-linux/infrastructure-nix/actions/workflows/pages.yml"><img src="https://github.com/garuda-linux/infrastructure-nix/actions/workflows/pages.yml/badge.svg" alt="deploy docs" /></a></p>
<h2 id="general-information"><a class="header" href="#general-information">General information</a></h2>
<ul>
<li>Our current infrastructure is hosted in two of <a href="https://www.hetzner.com/dedicated-rootserver/ex44">these</a>.</li>
<li>The servers are being backed up to Hetzner storage boxes via <a href="https://www.borgbackup.org/">Borg</a>.</li>
<li>After multiple different setups, we settled on <a href="https://nixos.org/">NixOS</a> as our main OS as it provides reproducible
and atomically updated system states</li>
<li>Cloudflare protects most (sub)domains while also making use of its caching feature.
Exemptions are services such as our mail server and parts violating Cloudflares rules such as proxying Mastodon video content.</li>
<li>Cloudflare Access in combination with Cloudflared is used to secure access to high-risk services such as admin panels.</li>
</ul>
<h2 id="quick-links"><a class="header" href="#quick-links">Quick links</a></h2>
<ul>
<li><a href="https://docs.garudalinux.net/common">Common maintenance tasks</a></li>
<li><a href="https://docs.garudalinux.net/hosts/aerialis">Host: aerialis</a></li>
<li><a href="https://docs.garudalinux.net/hosts/stormwing">Host: stormwing</a></li>
</ul>
<h2 id="devshell-and-how-to-enter-it"><a class="header" href="#devshell-and-how-to-enter-it">Devshell and how to enter it</a></h2>
<p>This NixOS flake provides a <a href="https://github.com/numtide/devshell">devshell</a>
which contains all deployment tools as well as handy aliases for common tasks.
The only requirement for using it is having the Nix package manager available.
It can be installed on various distributions via the package manager or the following
script (<a href="https://zero-to-nix.com/start/install">click me for more information</a>):</p>
<pre><code class="language-shell">curl --proto '=https' --tlsv1.2 -sSf -L https://install.determinate.systems/nix -o nix-install.sh # Check its content afterwards
sh ./nix-install.sh install --diagnostic-endpoint=""
</code></pre>
<p>This installs the Nix packages with flakes already pre-enabled. After that, the shell can be invoked as follows:</p>
<pre><code class="language-shell">nix develop # The intended way to use the devshell
nix-shell # Legacy, non-flakes way if flakes are not available for some reason
</code></pre>
<p>This also sets up pre-commit-hooks and shows the currently implemented tasks, which can be executed by running the
command.</p>
<pre><code class="language-shell">ğŸ”¨ Welcome to Garuda's infra-nix shell â„ï¸

[[general commands]]

  ansible-core      - Radically simple IT automation
  apply             - Applies the infra-nix configuration pushed to the servers
  clean             - Runs the garbage collection on the servers
  commitizen        - Tool to create committing rules for projects, auto bump versions, and generate changelogs
  deploy            - Deploys the local NixOS configuration to the servers
  manix             - Fast CLI documentation searcher for Nix
  mdbook            - Create books from MarkDown
  mdbook-admonish   - Preprocessor for mdbook to add Material Design admonishments
  mdbook-emojicodes - MDBook preprocessor for converting emojicodes (e.g. `: cat :`) into emojis ğŸ±
  menu              - prints this menu
  pre-commit        - Framework for managing and maintaining multi-language pre-commit hooks
  restart           - Restarts all physical servers
  rsync             - Fast incremental file transfer utility
  sops              - Simple and flexible tool for managing secrets
  update            - Performs a full system update on the servers bumping flake lock

[infra-nix]

  buildiso-local    - Spawns a local buildiso shell to build to ./buildiso (needs Docker)
  buildiso-remote   - Spawns a buildiso shell on the iso-runner builder
  colmena           - Runs the Colmena deployment tool</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="general-structure"><a class="header" href="#general-structure">General structure</a></h1>
<p>A general overview of the folder structure can be found below:</p>
<pre><code class="language-shell">â”œâ”€â”€ ansible
â”‚Â Â  â”œâ”€â”€ host_vars
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ aerialis
â”‚Â Â  â”‚Â Â  â””â”€â”€ stormwing
â”‚Â Â  â””â”€â”€ playbooks
â”œâ”€â”€ assets
â”œâ”€â”€ compose
â”‚Â Â  â”œâ”€â”€ chaotic-backend
â”‚Â Â  â”œâ”€â”€ chaotic-v4
â”‚Â Â  â”œâ”€â”€ docker
â”‚Â Â  â”‚Â Â  â””â”€â”€ configs
â”‚Â Â  â”œâ”€â”€ docker-proxied
â”‚Â Â  â”œâ”€â”€ firedragon-runner
â”‚Â Â  â”œâ”€â”€ github-runner
â”‚Â Â  â”œâ”€â”€ gitlab-runner
â”‚Â Â  â””â”€â”€ mastodon
â”œâ”€â”€ docs
â”‚Â Â  â”œâ”€â”€ src
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ hosts
â”‚Â Â  â”‚Â Â  â”‚Â Â  â”œâ”€â”€ aerialis
â”‚Â Â  â”‚Â Â  â”‚Â Â  â””â”€â”€ stormwing
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ repositories
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ services
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ users
â”‚Â Â  â”‚Â Â  â””â”€â”€ websites
â”œâ”€â”€ home-manager
â”œâ”€â”€ nixos
â”‚Â Â  â”œâ”€â”€ hosts
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ aerialis
â”‚Â Â  â”‚Â Â  â””â”€â”€ stormwing
â”‚Â Â  â”œâ”€â”€ modules
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ special
â”‚Â Â  â”‚Â Â  â””â”€â”€ static
â”‚Â Â  â””â”€â”€ services
â”‚Â Â      â”œâ”€â”€ compose-runner
â”‚Â Â      â””â”€â”€ monitoring
â”œâ”€â”€ scripts
â””â”€â”€ secrets
</code></pre>
<h2 id="secrets-in-this-repository"><a class="header" href="#secrets-in-this-repository">Secrets in this repository</a></h2>
<p>Secrets are managed via the sops-nix module, which allows us to encrypt sensitive files and supply them in an encrypted way to our hosts.
They will then be decrypted at runtime by using the hosts ed25519 SSH host key.
This is done by using the <code>sops</code> tool, which encrypts files using a key stored in the <code>~/.config/sops/</code> directory.
The submodule is available in the <code>secrets</code> directory once it has been set up for the first time. It can be initialized by running:</p>
<pre><code class="language-sh">git submodule init
git submodule update
</code></pre>
<p>To view or edit any of these files, one can use the following commands:</p>
<pre><code class="language-sh">sops secrets/filename.yaml # opens editor for the file
sops -e secrets/filename.yaml # encrypts the file
sops -d secrets/filename.yaml # decrypts the file
</code></pre>
<p>This assumes a fitting sops key is available in the <code>~/.config/sops/</code> directory.
It is important to keep the <code>secrets</code> directory in the latest state before deploying a new configuration as misconfigurations might happen otherwise.</p>
<h2 id="passwords-in-general"><a class="header" href="#passwords-in-general">Passwords in general</a></h2>
<p>Our mission-critical passwords that maintainers and team members need to have access to are stored in our <a href="vault.garudalinux.org">Bitwarden instance</a>.
After creating an account, maintainers need to be invited to the Garuda Linux organisation in order to access the stored credentials.</p>
<h2 id="linting-and-formatting"><a class="header" href="#linting-and-formatting">Linting and formatting</a></h2>
<p>We utilize <a href="https://github.com/cachix/pre-commit-hooks.nix">pre-commit-hooks</a> to automatically set up the pre-commit-hook with all the tools once <code>nix-shell</code> or <code>nix develop</code> is run for the first time.
Checks can then be executed by running one of the following configs:</p>
<pre><code class="language-sh">nix flake check # checks flake outputs and runs pre-commit at the end
pre-commit run --all-files # only runs the pre-commit tools on all files
</code></pre>
<p>Its configuration can be found in the <code>flake.nix</code> file. (<a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/flake.nix">click me</a>). At the time of writing, the following tools are being run:</p>
<ul>
<li><a href="https://github.com/rhysd/actionlint">actionlint</a></li>
<li><a href="https://github.com/ansible/ansible-lint">ansible-lint</a></li>
<li><a href="https://github.com/commitizen-tools/commitizen">commitizen</a></li>
<li><a href="https://github.com/astro/deadnix">deadnix</a></li>
<li><a href="https://github.com/oxalica/nil">nil</a></li>
<li><a href="https://github.com/nix-community/nixpkgs-fmt">nixpkgs-fmt</a></li>
<li><a href="https://prettier.io/">prettier</a></li>
<li><a href="https://github.com/nerdypepper/statix">statix</a></li>
<li><a href="https://github.com/adrienverge/yamllint">yamllint</a></li>
</ul>
<p>It is recommended to run <code>pre-commit run --all-files</code> before trying to commit changes. Then use <code>cz commit</code> to generate a <code>commitizen</code> complying commit message.</p>
<h2 id="cicd"><a class="header" href="#cicd">CI/CD</a></h2>
<p>We have used pull-/push-based mirroring for this git repository, which allows easy access to Renovate without having to run a custom instance of it. The following tasks have been implemented as of now:</p>
<ul>
<li><code>nix flake check</code> runs for every labeled PR and commit on main.</li>
<li><a href="https://renovatebot.com/">Renovate</a> periodically checks <code>docker-compose.yml</code> and other supported files for version updates. It has a <a href="https://github.com/garuda-linux/infrastructure-nix/issues/5">dependency dashboard</a> as well as the <a href="https://developer.mend.io/github/garuda-linux/infrastructure-nix">developer interface</a> to check logs of individual runs. Minor updates appear as grouped PRs while major updates are separated from those. Note that this only applies to the GitHub side.</li>
<li>Deployment of our <a href="https://github.com/rust-lang/mdBook">mdBook-based</a> documentation to Cloudflare pages.</li>
<li>Deployment of our Website to Cloudflare pages.</li>
</ul>
<p>Workflows will generally only be executed if a relevant file has been changed, eg. <code>nix flake check</code> won't run if only the README was changed.</p>
<h2 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h2>
<p>Our current monitoring stack mostly relies on Netdata to provide insight into current system loads and trends.
The major reason for using it was that it provides the most vital metrics and alerts out of the box without having to create in-depth configurations.
Might switch to the Prometheus/Grafana/Loki stack in the future. We used to set up children -&gt; parent streaming in the past, though after transitioning to one big host this didn't make sense anymore.
Instead, up to 10GB of data gets stored on individual hosts.
While Netdata agents do have their dashboard, the <a href="https://app.netdata.cloud/spaces/garuda-infra/rooms/all-nodes">Dashboard provided by Netdata</a> is far superior and allows a better insight, eg. by offering the functions feature.
Additional services like Squid or Nginx have been configured to be monitored by Netdata plugins as well. Further information can be found in its <a href="https://learn.netdata.cloud/">documentation</a>.
To access the previously linked dashboard, use <code>team@garudalinux.org</code> as login, the login will be completed after opening the link sent here.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="common-maintenance-tasks"><a class="header" href="#common-maintenance-tasks">Common maintenance tasks</a></h2>
<h3 id="rebuilding--updating-the-forum-container"><a class="header" href="#rebuilding--updating-the-forum-container">Rebuilding / updating the forum container</a></h3>
<p>Sometimes Discourse needs its container to build rebuild via cli rather than the webinterface. This can be done with:</p>
<pre><code class="language-sh">ssh -p 666 $user@aerialis.garudalinux.org
sudo nixos-container root-login forum
cd /var/discourse
./launcher rebuild app
</code></pre>
<h3 id="building-iso-files"><a class="header" href="#building-iso-files">Building ISO files</a></h3>
<p>To build Garuda ISO, one needs to connect to the <code>iso-runner</code> container and execute the <code>buildiso</code> command, which opens
a shell containing the needed environment:</p>
<pre><code class="language-sh">ssh -p 220 $user@builds.garudalinux.org # if one ran nix develop before, this can be skipped
buildiso
buildiso -i # updates the iso-profiles repo
buildiso -p dr460nized
</code></pre>
<p>Further information on available commands can be found in
the <a href="https://gitlab.com/garuda-linux/tools/garuda-tools">garuda-tools</a> repository.
After the build process is finished, builds can be found
on <a href="https://iso.builds.garudalinux.org/iso/garuda/">iso.builds.garudalinux.org</a>.
No automatic pushing to Sourceforge and Cloudflare R2 happens by default, see below for more information on how to
achieve this.</p>
<h3 id="deploying-a-new-iso-release"><a class="header" href="#deploying-a-new-iso-release">Deploying a new ISO release</a></h3>
<p>We are assuming all ISOs have been tested for functionality before executing any of those commands.</p>
<pre><code class="language-sh">ssh -p 220 $user@builds.garudalinux.org
buildall # builds all ISO provided in the buildall command
deployiso -FS # sync to Cloudflare R2 and Sourceforge
deployiso -FSR # sync to Cloudflare R2 and Sourceforge while also updating the latest (stable, non-nightly) release
deployiso -Sd # to delete the old ISOs on Sourceforge once they aren't needed anymore
deployiso -FSRd # oneliner for the above-given commands
</code></pre>
<h3 id="updating-the-system"><a class="header" href="#updating-the-system">Updating the system</a></h3>
<p>One needs to have the <a href="https://gitlab.com/garuda-linux/infra-nix">infra-nix</a> repo cloned locally. Then proceed by
updating the <code>flake.lock</code> file, pushing it to the server &amp; building the configurations:</p>
<pre><code class="language-sh">nix flake update
ansible-playbook garuda.yml -l $servername # Eg. aerialis
deploy # Skip using the above command and use this one in case nix develop was used
</code></pre>
<p>Then you can either apply it via Ansible or connect to the host to view more details about the process while it runs:</p>
<pre><code class="language-sh">ansible-playbook apply.yml -l $servername # Ansible

apply # Nix develop shell

ssh -p 666 $user@builds.garudalinux.org
sudo nixos-rebuild switch
</code></pre>
<p>Keep in mind that this will restart every service whose files changed since the last system update. On our Hetzner
server, this includes a restart of every declarative <code>nixos-container</code> if needed, causing a small downtime.</p>
<h3 id="changing-system-configurations"><a class="header" href="#changing-system-configurations">Changing system configurations</a></h3>
<p>Most system configurations are contained in individual Nix files in the <code>nix</code> directory of this repo. This means
changing anything must not be done manually but by editing the corresponding file and pushing/applying the configuration
afterward.</p>
<pre><code class="language-sh">ansible-playbook garuda.yml -l $servername # Eg. aerialis
deploy # In case nix develop is used
</code></pre>
<p>As with the system update, one can either apply via Ansible or manually:</p>
<pre><code class="language-sh">ansible-playbook apply.yml -l $servername # Ansible

apply # Nix develop shell

ssh -p 666 $user@builds.garudalinux.org
sudo nixos-rebuild switch
</code></pre>
<h4 id="adding-a-user"><a class="header" href="#adding-a-user">Adding a user</a></h4>
<p>Adding users needs to be done in <code>users.nix</code>:</p>
<ul>
<li>Add a new
user <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/modules/users.nix?ref_type=heads#L14">here</a></li>
<li>Add the SSH public key
to <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/flake.nix?ref_type=heads#L43">flake inputs</a></li>
<li>Add the specialArgs <code>keys.user</code> as
seen <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/flake-module.nix?ref_type=heads#L38">here</a></li>
<li>Deploy &amp; apply the configuration</li>
</ul>
<h3 id="changing-docker-configurations"><a class="header" href="#changing-docker-configurations">Changing Docker configurations</a></h3>
<p>If configurations of services running in Docker containers need to be altered, one needs to edit the
corresponding <code>compose.yml</code> (<code>./compose/$name</code>) file or <code>.env</code> entry of our sops file in the <code>secrets</code> directory (see
the secrets section for details on that topic).
The deployment is done the same way as with normal system configuration.</p>
<h3 id="updating-docker-containers"><a class="header" href="#updating-docker-containers">Updating Docker containers</a></h3>
<p>Docker containers sometimes use the <code>latest</code> tag in case no current tag is available or in the case of services like
Piped and Searx, where it is often crucial to have the latest build to bypass Google's restrictions.
Containers using the <code>latest</code> tag are automatically updated via <a href="https://containrrr.dev/watchtower/">watchtower</a> daily.
The remaining ones can be updated by changing their version in the corresponding <code>compose.yml</code> and then
running <code>deploy</code> &amp; <code>apply</code>.
If containers are to be updated manually, this can be achieved by connecting to the host,
running <code>nixos-container root-login $containername</code>, and executing:</p>
<pre><code class="language-sh">cd /var/garuda/compose-runner/$name/ # replace $name with the actual docker-compose.yml or autocomplete via tab
sudo docker compose pull
sudo docker compose up -d
</code></pre>
<p>The updated containers will be pulled and automatically recreated using the new images.</p>
<h3 id="checking-whether-backups-were-successful"><a class="header" href="#checking-whether-backups-were-successful">Checking whether backups were successful</a></h3>
<p>To check whether backups to Hetzner are still working as expected, connect to the server and execute the following:</p>
<pre><code class="language-sh">systemctl status borgbackup-job-backupToHetzner
</code></pre>
<p>This should yield a successful unit state. The only exception is having an exit code != <code>0</code> due to files having changed
during the run.</p>
<h3 id="updating-chaotic-aur-toolbox"><a class="header" href="#updating-chaotic-aur-toolbox">Updating Chaotic-AUR toolbox</a></h3>
<p>This needs to be done by updating the flake input (git repo URL of the
website) <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nix/flake.nix?ref_type=heads#L44">src-chaotic-toolbox</a>:</p>
<pre><code class="language-sh">cd nix
nix flake lock --update-input src-chaotic-toolbox # toolbox
</code></pre>
<p>After that deploy as usual by running <code>deploy</code> and <code>apply</code>. The commit and corresponding hash will be updated and NixOS
will use it to build the toolbox using the new revision automatically.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="important-links"><a class="header" href="#important-links">Important links</a></h1>
<p>This is a collection of important links when working with the infrastructure:</p>
<h2 id="most-important"><a class="header" href="#most-important">Most important</a></h2>
<ul>
<li><a href="https://github.com/garuda-linux/infrastructure-nix">The infrastructure-nix repository</a></li>
</ul>
<h2 id="nix-related"><a class="header" href="#nix-related">Nix-related</a></h2>
<ul>
<li><a href="https://numtide.github.io/devshell/">Devshell documentation</a></li>
<li><a href="https://flake.parts">Flake-parts documentation</a>
<ul>
<li><a href="https://flake.parts/options/pre-commit-hooks-nix">Pre-commit-hooks flake-module</a></li>
</ul>
</li>
<li><a href="https://mipmip.github.io/home-manager-option-search/">Home Manager options search</a></li>
<li><a href="https://nixos-mailserver.readthedocs.io/en/latest/setup-guide.html">NixOS mailserver documentation</a></li>
<li><a href="https://nixos.org/manual/nixos/stable/">The Nix documentation</a></li>
<li><a href="https://search.nixos.org">The Nix package and option search</a></li>
<li><a href="https://github.com/Mic92/sops-nix">Sops Nix</a></li>
</ul>
<h2 id="tools-documentation"><a class="header" href="#tools-documentation">Tools documentation</a></h2>
<ul>
<li><a href="https://github.com/chaotic-aur/toolbox">Chaotic toolbox</a></li>
<li><a href="./services/chaotic-4.0.html">Chaotic infra 4.0</a></li>
<li><a href="https://github.com/rust-lang/mdBook">mdBook</a></li>
</ul>
<h2 id="web-interfaces"><a class="header" href="#web-interfaces">Web interfaces</a></h2>
<ul>
<li><a href="https://syncthing-build.garudalinux.net/">Chaotic-AUR Syncthing</a></li>
<li><a href="https://dash.cloudflare.com">Cloudflare Dashboard</a></li>
<li><a href="https://status.garudalinux.org">Status page</a></li>
<li><a href="https://accounts.hetzner.com/">Hetzner Robot</a></li>
<li><a href="https://app.netdata.cloud">Netdata</a></li>
<li><a href="https://pgadmin.garudalinux.net">PGAdmin</a></li>
<li><a href="https://login.tailscale.com/">Tailscale</a></li>
</ul>
<h2 id="services-to-be-administrated"><a class="header" href="#services-to-be-administrated">Services to be administrated</a></h2>
<ul>
<li><a href="https://vault.garudalinux.org">Vaultwarden</a></li>
<li><a href="https://forum.garudalinux.org">Discourse</a></li>
<li><a href="https://aur.chaotic.cx">Chaotic-AUR</a></li>
<li><a href="https://ffsync.garudalinux.org">Firefox syncserver</a></li>
<li><a href="https://lingva.garudalinux.org">Lingva</a></li>
<li><a href="https://social.garudalinux.org">Mastodon</a></li>
<li><a href="https://cloud.garudalinux.org">Nextcloud</a></li>
<li><a href="https://bin.garudalinux.org">PrivateBin</a></li>
<li><a href="https://reddit.garudalinux.org">Redlib</a></li>
<li><a href="https://searx.garudalinux.org">SearxNG</a></li>
<li><a href="https://irc.garudalinux.org">TheLounge</a></li>
<li><a href="https://search.garudalinux.org">Whoogle</a></li>
<li><a href="https://wiki.garudalinux.org">WikiJs</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="users"><a class="header" href="#users">Users</a></h1>
<p>Multiple kinds of users can make use of our infrastructure. A current list of users is
available <a href="./users/current_users.html">here</a>.</p>
<h2 id="adding-new-users"><a class="header" href="#adding-new-users">Adding new users</a></h2>
<p>New users can be added by supplying a fitting configuration in the <code>users.nix</code> module.
In case of a password being required, its hash needs to be generated as follows:</p>
<pre><code class="language-sh">nix-shell -p mkpasswd --run 'mkpasswd -sm bcrypt' &gt; /path/to/hashedPasswordFile
</code></pre>
<p>The file then needs to be added to our sops file and committed to our <a href="https://gitlab.com/garuda-linux/infra-nix-secrets">secrets</a> repository.
This one is only available to members of our GitLab org and usually is cloned as git submodule to <code>./secrets</code>.</p>
<h2 id="onboarding-a-new-admin"><a class="header" href="#onboarding-a-new-admin">Onboarding a new admin</a></h2>
<p>After confirming the trustworthiness of a new admin, the following actions need to be executed:</p>
<ul>
<li>Add them to the <a href="./users/current_users.html#admins">admin users</a></li>
<li>Add their ssh public key to
the <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/flake.nix?ref_type=heads#L59">flake inputs</a>
and <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/flake-module.nix?ref_type=heads#L38">specialArgs</a></li>
<li>Make them an owner of the <a href="https://gitlab.com/garuda-linux">GitLab organization</a></li>
<li>Add them to our <a href="https://vault.garudalinux.org">Vaultwarden organization</a> to allow access to passwords and email
accounts</li>
<li>Add them to the Cloudflare Account</li>
<li>Make them an admin of <a href="https://forum.garudalinux.org">Discourse</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="users-1"><a class="header" href="#users-1">Users</a></h1>
<p>These are the people who are currently allowed to use our servers.</p>
<h2 id="admins"><a class="header" href="#admins">Admins</a></h2>
<p>Admins have root access to all servers and may therefore change everything.
They are responsible for the well-being of the infrastructure and its development.</p>
<pre><code class="language-nix">    users.nico = {
      extraGroups = [
        "wheel"
        "docker"
        "chaotic_op"
      ];
      home = "/home/nico";
      isNormalUser = true;
      openssh.authorizedKeys.keyFiles = [ keys.nico ];
      hashedPasswordFile = config.sops.secrets."passwords/nico".path;
      uid = lib.mkIf garuda-lib.unifiedUID 1001;
    };
    users.sgs = {
      extraGroups = [ "wheel" ];
      home = "/home/sgs";
      isNormalUser = true;
      openssh.authorizedKeys.keys = [
        "ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDxBY8TX0iEQkf3Bym+3XVlrk8OLOwHOrj7Uy+WxjncOkkutyZ1WsY9liF4j9yjptyQG7Lx8OM8q44NE6+Rk1OXJXMF7CZ4Jq/WvMVnh2zKyNnF8wHBcspsAdG90wCxo6OmNpnY/rRRlNwwnore7raF2PrERtSlsEvLsUgvspYQ8cnLwerJP43QeETlpE1oR0FrbXWQet0I63Ky6UDEp07x0yee21VHnAG74rjGeFGwJBmCPSxnfGVNhCaR0zyu9+hh222liBrlilYm8nqLlsYGZCXiVdOxXJbBy89EVpHds7Lutf+TAYwsPGZf7U4k+g2Jx8N0JHXyzVZa0zS+I48+tqBBflEOqU9oEfGuz4cU/qWys5soLcRX2p9td+RF3OEdBKlTW4UYsINJUri6QSEUrsGaXqQZy8Ds2FBdUpb4pmFVlo9+4qRouiI80a5xVa7a1E5eS5xK5BzWH4fNg5SqtT5L9i2i1ocZp7FA0oa+ixnXNiC1umPZaY/9s+5fh1s= sgs-linux@shell.sf.net" # pragma: allowlist secret,
      ];
      hashedPasswordFile = config.sops.secrets."passwords/sgs".path;
      uid = lib.mkIf garuda-lib.unifiedUID 1002;
    };
    users.tne = {
      extraGroups = [
        "wheel"
        "docker"
        "chaotic_op"
      ];
      home = "/home/tne";
      isNormalUser = true;
      openssh.authorizedKeys.keyFiles = [ keys.tne ];
      hashedPasswordFile = config.sops.secrets."passwords/tne".path;
      uid = lib.mkIf garuda-lib.unifiedUID 1003;
    };
</code></pre>
<h2 id="maintainers"><a class="header" href="#maintainers">Maintainers</a></h2>
<p>Maintainers have restricted access, which allows them to use <code>buildiso</code> to build new ISO files via the <code>iso-runner</code>
container.</p>
<pre><code class="language-nix">    users.frank = {
      home = "/home/frank";
      isNormalUser = true;
      openssh.authorizedKeys.keyFiles = lib.mkIf config.services.garuda-iso.enable [ keys.frank ];
      shell = lib.mkIf (!config.services.garuda-iso.enable) "${pkgs.util-linux}/bin/nologin";
      uid = lib.mkIf garuda-lib.unifiedUID 1007;
    };
</code></pre>
<h2 id="chaotic-aur-maintainers"><a class="header" href="#chaotic-aur-maintainers">Chaotic-AUR maintainers</a></h2>
<p>Chaotic-AUR maintainers have access to the builder containers of our infrastructure.
They may operate the repository by doing all kinds of packaging-related tasks such as adding or removing those.</p>
<pre><code class="language-nix">    users.technetium = {
      extraGroups = lib.mkIf garuda-lib.chaoticUsers [ "chaotic_op" ];
      home = "/home/technetium";
      isNormalUser = true;
      openssh.authorizedKeys.keyFiles = lib.mkIf garuda-lib.chaoticUsers [ keys.technetium1 ];
      shell = lib.mkIf (!garuda-lib.chaoticUsers) "${pkgs.util-linux}/bin/nologin";
      uid = lib.mkIf garuda-lib.unifiedUID 1004;
    };
    users.alexjp = {
      extraGroups = lib.mkIf garuda-lib.chaoticUsers [ "chaotic_op" ];
      home = "/home/alexjp";
      isNormalUser = true;
      openssh.authorizedKeys.keyFiles = lib.mkIf garuda-lib.chaoticUsers [ keys.alexjp ];
      shell = lib.mkIf (!garuda-lib.chaoticUsers) "${pkgs.util-linux}/bin/nologin";
      uid = lib.mkIf garuda-lib.unifiedUID 1005;
    };
    users.xiota = {
      extraGroups = lib.mkIf garuda-lib.chaoticUsers [ "chaotic_op" ];
      home = "/home/xiota";
      isNormalUser = true;
      openssh.authorizedKeys.keyFiles = lib.mkIf garuda-lib.chaoticUsers [ keys.xiota ];
      shell = lib.mkIf (!garuda-lib.chaoticUsers) "${pkgs.util-linux}/bin/nologin";
      uid = lib.mkIf garuda-lib.unifiedUID 1006;
    };
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="aerialis"><a class="header" href="#aerialis">aerialis</a></h1>
<p>This is one of the two main infrastructure hosts (see also: stormwing). All services and containers for aerialis are defined in <code>nixos/hosts/aerialis.nix</code> and its submodules.</p>
<h2 id="host-configuration"><a class="header" href="#host-configuration">Host configuration</a></h2>
<pre><code class="language-nix">{
  config,
  pkgs,
  ...
}:
{
  imports = [
    ../modules
    ./../modules/special/hetzner-ex44.nix
  ];

  fileSystems."/" = {
    device = "none";
    fsType = "tmpfs";
    options = [
      "defaults"
      "size=50%"
      "mode=755"
    ];
  };

  fileSystems."/data_1" = {
    device = "/dev/disk/by-label/NIXROOT";
    fsType = "ext4";
    neededForBoot = true;
    options = [
      "defaults"
      "noatime"
      "nodiratime"
      "errors=remount-ro"
    ];
    depends = [
      "/"
    ];
  };

  fileSystems."/data_2" = {
    device = "/dev/disk/by-label/NIXDATA";
    fsType = "btrfs";
    options = [
      "defaults"
      "noatime"
      "nodiratime"
      "compress=zstd:1"
    ];
  };

  fileSystems."/boot" = {
    device = "/dev/disk/by-label/NIXBOOT";
    fsType = "vfat";
  };

  services.openssh.ports = [ 666 ];

  # Network configuration with a bridge interface
  networking = {
    defaultGateway = "157.180.57.65";
    defaultGateway6 = {
      address = "fe80::1";
      interface = "eth0";
    };
    hostName = "aerialis";
    interfaces = {
      "eth0" = {
        ipv4.addresses = [
          {
            address = "157.180.57.100";
            prefixLength = 26;
          }
        ];
      };
    };
    nat.forwardPorts = [
      {
        # web-front (HTTP)
        destination = "10.0.5.10:80";
        loopbackIPs = [ "157.180.57.100" ];
        proto = "tcp";
        sourcePort = 80;
      }
      {
        # web-front (HTTPS)
        destination = "10.0.5.10:443";
        loopbackIPs = [ "157.180.57.100" ];
        proto = "tcp";
        sourcePort = 443;
      }
      {
        # web-front (HTTPS)
        destination = "10.0.5.10:443";
        loopbackIPs = [ "157.180.57.100" ];
        proto = "udp";
        sourcePort = 443;
      }
      {
        # mail (SMTP)
        destination = "10.0.5.80:587";
        loopbackIPs = [ "157.180.57.100" ];
        proto = "tcp";
        sourcePort = 587;
      }
      {
        # mail (SMTP over SSL)
        destination = "10.0.5.80:465";
        loopbackIPs = [ "157.180.57.100" ];
        proto = "tcp";
        sourcePort = 465;
      }
    ];
    firewall.trustedInterfaces = [ "br0" ];
  };

  # Can't set this inside the containers
  boot.kernel.sysctl."vm.overcommit_memory" = "1";

  # Container config
  services.garuda-nspawn = {
    bridgeInterface = "br0";
    hostInterface = "eth0";
    hostIp = "10.0.5.1";
    dockerCache = "/data_1/dockercache/";

    defaults = {
      maxMemorySoft = 48318382080; # 45 GiB
      maxMemoryHard = 53687091200; # 50 GiB
      maxCpu = 18;
    };

    containers = {
      chaotic-backend = {
        config = import ./aerialis/chaotic-backend.nix;
        extraOptions = {
          bindMounts = {
            "chaotic" = {
              hostPath = "/data_2/containers/chaotic-backend/chaotic";
              isReadOnly = false;
              mountPoint = "/var/garuda/compose-runner/chaotic-backend";
            };
          };
          enableTun = true;
          forwardPorts = [
            {
              containerPort = 22;
              hostPort = 270;
              protocol = "tcp";
            }
          ];
        };
        ipAddress = "10.0.5.70";
        needsDocker = true;
      };
      docker = {
        config = import ./aerialis/docker.nix;
        extraOptions = {
          bindMounts = {
            "compose" = {
              hostPath = "/data_1/containers/docker/";
              isReadOnly = false;
              mountPoint = "/var/garuda/compose-runner/docker";
            };
            "nextcloud-local-backup" = {
              hostPath = "/data_2/backup/nextcloud-aio";
              isReadOnly = false;
              mountPoint = "/var/garuda/backups/nextcloud";
            };
          };
        };
        ipAddress = "10.0.5.60";
        needsDocker = true;
      };
      docker-proxied = {
        config = import ./aerialis/docker-proxied.nix;
        extraOptions = {
          bindMounts = {
            "compose" = {
              hostPath = "/data_1/containers/docker-proxied/";
              isReadOnly = false;
              mountPoint = "/var/garuda/compose-runner/docker-proxied";
            };
          };
        };
        ipAddress = "10.0.5.50";
        needsDocker = true;
      };
      forum = {
        config = import ./aerialis/forum.nix;
        extraOptions = {
          bindMounts = {
            "forum" = {
              hostPath = "/data_1/containers/forum/";
              isReadOnly = false;
              mountPoint = "/var/discourse";
            };
          };
        };
        ipAddress = "10.0.5.40";
        needsDocker = true;
      };
      mastodon = {
        config = import ./aerialis/mastodon.nix;
        needsDocker = true;
        extraOptions = {
          bindMounts = {
            "mastodon" = {
              hostPath = "/data_2/containers/mastodon/mastodon";
              isReadOnly = false;
              mountPoint = "/var/lib/mastodon";
            };
            "compose" = {
              hostPath = "/data_1/containers/mastodon/compose";
              isReadOnly = false;
              mountPoint = "/var/garuda/compose-runner/mastodon";
            };
          };
        };
        ipAddress = "10.0.5.30";
      };
      mail = {
        config = import ./aerialis/mail.nix;
        extraOptions = {
          bindMounts = {
            "acme" = {
              hostPath = "/data_2/containers/web-front/acme";
              isReadOnly = false;
              mountPoint = "/var/lib/acme";
            };
            "dkim" = {
              hostPath = "/data_1/containers/mail/dkim";
              isReadOnly = false;
              mountPoint = "/var/dkim";
            };
            "rspamd" = {
              hostPath = "/data_1/containers/mail/rspamd";
              isReadOnly = false;
              mountPoint = "/var/lib/redis-rspamd";
            };
            "sieve" = {
              hostPath = "/data_1/containers/mail/sieve";
              isReadOnly = false;
              mountPoint = "/var/sieve";
            };
            "vmail" = {
              hostPath = "/data_1/containers/mail/vmail";
              isReadOnly = false;
              mountPoint = "/var/vmail";
            };
          };
          forwardPorts = [
            {
              containerPort = 993;
              hostPort = 993;
              protocol = "tcp";
            }
          ];
        };
        ipAddress = "10.0.5.80";
      };
      postgres = {
        config = import ./aerialis/postgres.nix;
        extraOptions = {
          bindMounts = {
            "data" = {
              hostPath = "/data_1/containers/postgres/data";
              isReadOnly = false;
              mountPoint = "/var/lib/postgresql";
            };
            "postgres_backup" = {
              hostPath = "/data_2/containers/postgres/backup";
              isReadOnly = false;
              mountPoint = "/var/garuda/backups/postgres";
            };
          };
          forwardPorts = [
            {
              containerPort = 22;
              hostPort = 220;
              protocol = "tcp";
            }
            {
              containerPort = 5432;
              hostPort = 5432;
              protocol = "tcp";
            }
          ];
        };
        ipAddress = "10.0.5.20";
      };
      web-front = {
        config = import ./aerialis/web-front.nix;
        extraOptions = {
          bindMounts = {
            "acme" = {
              hostPath = "/data_2/containers/web-front/acme";
              isReadOnly = false;
              mountPoint = "/var/lib/acme";
            };
            "nginx" = {
              hostPath = "/data_2/containers/web-front/nginx";
              isReadOnly = false;
              mountPoint = "/var/log/nginx";
            };
          };
          forwardPorts = [
            {
              containerPort = 22;
              hostPort = 210;
              protocol = "tcp";
            }
          ];
        };
        ipAddress = "10.0.5.10";
      };
    };
  };

  # Make sure postgres is started before other containers
  systemd.services = {
    "container@docker".requires = [ "container@postgres.service" ];
    "container@docker-proxied".requires = [ "container@postgres.service" ];
    "container@mastodon".requires = [ "container@postgres.service" ];
    "container@chaotic-backend".requires = [ "container@postgres.service" ];
    "container@postgres" = {
      before = [
        "container@docker-proxied.service"
        "container@docker.service"
        "container@mastodon.service"
        "container@chaotic-backend.service"
      ];
    };
  };

  # Monitor a few services of the containers
  services = {
    netdata.configDir = {
      "go.d/postgres.conf" = pkgs.writeText "postgres.conf" ''
        jobs:
          - name: postgres
            dsn: 'postgres://netdata:netdata@10.0.5.20:5432/'
      '';
      "go.d/squidlog.conf" = pkgs.writeText "squidlog.conf" ''
        jobs:
          - name: squid
            path: /var/log/squid/access.log
            log_type: csv
            csv_config:
              format: '- resp_time client_address result_code resp_size req_method - - hierarchy mime_type'
      '';
      "go.d/web_log.conf" = pkgs.writeText "web_log.conf" ''
        jobs:
          - name: nginx
            path: /data_2/containers/web-front/nginx/access.log
      '';
    };
  };

  # Fix permissions of nginx log files to allow Netdata to read it (gets reset frequently)
  system.activationScripts.netdata = "chown 60:netdata -R /data_2/containers/web-front/nginx";

  # Backup configurations to Hetzner storage box
  programs.ssh.macs = [ "hmac-sha2-512" ];
  services.borgbackup.jobs = {
    backupToHetzner = {
      compression = "auto,zstd";
      doInit = true;
      encryption = {
        mode = "repokey-blake2";
        passCommand = ''
          cat "${config.sops.secrets."backup/repo_key".path}"
        '';
      };
      environment = {
        BORG_RSH = "ssh -i ${config.sops.secrets."backup/ssh_aerialis".path} -p 23";
      };
      exclude = [
        "/data_1/dockercache"
        "/data_1/dockerdata"
      ];
      paths = [
        "/data_1/containers"
        "/data_1/persistent/etc/ssh"
        "/data_2/backup/nextcloud-aio/"
        "/data_2/containers/chaotic-backend/chaotic/database"
        "/data_2/containers/mastodon"
        "/data_2/containers/postgres"
      ];
      prune.keep = {
        within = "1d";
        daily = 3;
        weekly = 1;
        monthly = 1;
      };
      repo = "u342919@u342919.your-storagebox.de:./aerialis";
      startAt = "daily";
    };
  };

  sops.secrets = {
    "backup/repo_key" = { };
    "backup/ssh_aerialis" = { };
  };

  deployment = {
    targetHost = "157.180.57.100";
    targetPort = 666;
    targetUser = "ansible";
  };
}
</code></pre>
<h2 id="containersservices"><a class="header" href="#containersservices">Containers/services</a></h2>
<ul>
<li><a href="hosts/./aerialis/chaotic-backend.html">chaotic-backend</a>: Backend services for Chaotic-AUR, including API and job processing.</li>
<li><a href="hosts/./aerialis/docker.html">docker</a>: General-purpose Docker container runner for services not packaged in Nix.</li>
<li><a href="hosts/./aerialis/docker-proxied.html">docker-proxied</a>: Docker runner for services that require special proxying or network setup.</li>
<li><a href="hosts/./aerialis/forum.html">forum</a>: Hosts the Discourse forum for the Garuda Linux community.</li>
<li><a href="hosts/./aerialis/mail.html">mail</a>: Handles mail-related services and relays for the infrastructure.</li>
<li><a href="hosts/./aerialis/mastodon.html">mastodon</a>: Runs the Mastodon social network instance.</li>
<li><a href="hosts/./aerialis/postgres.html">postgres</a>: Provides PostgreSQL database services for other containers.</li>
<li><a href="hosts/./aerialis/web-front.html">web-front</a>: Acts as the main reverse proxy and web frontend for hosted services.</li>
</ul>
<p>See the respective documentation pages for up-to-date configuration and details.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chaotic-backend-aerialis"><a class="header" href="#chaotic-backend-aerialis">chaotic-backend (aerialis)</a></h1>
<p>This container provides backend services for Chaotic-AUR, including API endpoints and job processing for the repository.</p>
<h2 id="nix-expression"><a class="header" href="#nix-expression">Nix expression</a></h2>
<pre><code class="language-nix">{
  config,
  sources,
  ...
}:
{
  imports = sources.defaultModules ++ [
    ../../modules
    ../../modules/special/ssh-allow-chaotic.nix
  ];

  garuda.services.compose-runner.chaotic-backend = {
    envfile = config.sops.secrets."compose/chaotic-backend".path;
    source = ../../../compose/chaotic-backend;
    extraEnv = {
      "SSH_KEY" = config.sops.secrets."keypairs/chaotic/private".path;
    };
  };

  sops.secrets = {
    "compose/chaotic-backend" = { };
    "keypairs/chaotic/private" = { };
    "redis/chaotic" = { };
  };

  system.stateVersion = "25.05";
}
</code></pre>
<h3 id="docker-containers"><a class="header" href="#docker-containers">Docker containers</a></h3>
<pre><code class="language-yaml">services:
  chaotic-backend:
    image: ghcr.io/chaotic-cx/chaotic-next:main
    container_name: chaotic-backend
    deploy:
      restart_policy:
        condition: always
        delay: 30s
    environment:
      AUTH0_AUDIENCE: http://localhost:3000/auth/auth0
      AUTH0_CLIENT_ID: ${AUTH0_CLIENT_ID:-?err}
      AUTH0_CLIENT_SECRET: ${AUTH0_CLIENT_SECRET:-?err}
      AUTH0_DOMAIN: ${AUTH0_DOMAIN:-?err}
      CAUR_DB_KEY: ${CAUR_DB_KEY:-?err}
      CAUR_GITLAB_ID_CAUR: 54867625
      CAUR_GITLAB_ID_GARUDA: 48461689
      CAUR_GITLAB_TOKEN: ${GITLAB_TOKEN_CX:-?err}
      CAUR_GITLAB_WEBHOOK_TOKEN: ${CAUR_GITLAB_WEBHOOK_TOKEN:-?err}
      CAUR_JWT_SECRET: ${CAUR_JWT_SECRET:-?err}
      CAUR_TRUST_PROXY: 172.18.0.1
      CAUR_USERS: ${CAUR_USERS:-?err}
      NODE_ENV: production
      PG_DATABASE: chaotic-aur
      PG_HOST: 10.0.5.20
      PG_PASSWORD: ${PG_PASSWORD:-?err}
      PG_USER: chaotic-aur
      REDIS_PASSWORD: ${REDIS_PASSWORD:-?err}
      REDIS_SSH_HOST: host.docker.internal
      REDIS_SSH_USER: package-deployer
    ports: ["3000:3000"]
    volumes: ["${SSH_KEY:-?err}:/app/sshkey"]
    extra_hosts: ["host.docker.internal:host-gateway"]
  # TODO: revert to NixOS service once it no longer segfaults
  database:
    image: redis:8.2-m01-alpine
    container_name: chaotic-database
    restart: always
    ports: ["127.0.0.1:6379:6379"]
    command: redis-server --save 20 1 --loglevel warning --requirepass "${REDIS_PASSWORD:-?err}"
    volumes: ["./database:/data"]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker-aerialis"><a class="header" href="#docker-aerialis">docker (aerialis)</a></h1>
<p>This container runs general-purpose Docker workloads for services that are not packaged natively in NixOS.</p>
<h2 id="general"><a class="header" href="#general">General</a></h2>
<p>This container is used to run regular Docker containers.
Recently, the <code>compose-runner</code> module has been replaced by native Nix expressions.</p>
<h2 id="nextcloud-aio"><a class="header" href="#nextcloud-aio">Nextcloud AIO</a></h2>
<p>This container also runs a Nextcloud AIO master container, which administrates its containers by itself.
Consult its <a href="https://github.com/nextcloud/docker">extensive documentation for more information</a>.
Since this container requires a Nextcloud volume at a fixed place, without being able to change it, it is not
included in the regular data directory.</p>
<p>Instead, backups are regularly performed via the inbuilt backup function in the admin interface.
They can be found at <code>/var/garuda/compose-runner/docker/nextcloud-aio</code>
and are included in the offsite system backups.</p>
<h2 id="nix-expression-1"><a class="header" href="#nix-expression-1">Nix expression</a></h2>
<pre><code class="language-nix">{
  config,
  sources,
  ...
}:
{
  imports = sources.defaultModules ++ [ ../../modules ];

  # This container is just for compose stuff
  garuda.services.compose-runner.docker = {
    envfile = config.sops.secrets."compose/docker".path;
    source = ../../../compose/docker;
    extraEnv = {
      "MATTERBRIDGE_CONFIG" = config.sops.secrets."compose/matterbridge".path;
    };
  };

  sops.secrets = {
    "compose/docker" = {
      restartUnits = [ "compose-runner-docker.service" ];
    };
    "compose/matterbridge" = {
      restartUnits = [ "compose-runner-docker.service" ];
    };
  };

  system.stateVersion = "25.05";
}
</code></pre>
<h3 id="docker-containers-1"><a class="header" href="#docker-containers-1">Docker containers</a></h3>
<pre><code class="language-yaml">services:
  # Nextcloud AIO (self-managed containers)
  # The dummy mounts are for creating the required volumes, even
  # though the container doesn't use them. The actual containers
  # making use of these volumes are started by the master container.
  # Do *not* change container and volume names!
  nextcloud-aio-mastercontainer:
    image: nextcloud/all-in-one:latest
    restart: always
    container_name: nextcloud-aio-mastercontainer
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - nextcloud_aio_clamav:/dummy/clamav
      - nextcloud_aio_database:/dummy/database
      - nextcloud_aio_mastercontainer:/mnt/docker-aio-config
      - nextcloud_aio_nextcloud:/dummy/nextcloud
      - nextcloud_aio_nextcloud_data:/dummy/nextcloud_data
      - nextcloud_aio_redis:/dummy/redis
    ports: ["8080:8080"]
    environment:
      APACHE_PORT: 11000
      APACHE_IP_BINDING: 10.0.5.60
      NEXTCLOUD_DATADIR: /var/garuda/compose-runner/docker/nextcloud-aio/nextcloud_data
  # Firefox syncserver
  syncserver:
    container_name: syncserver
    image: crazymax/firefox-syncserver:edge # newest, versioned one 3 years old
    volumes: ["./syncserver:/data"]
    ports: ["5001:5000"]
    environment:
      FF_SYNCSERVER_ACCESSLOG: true
      FF_SYNCSERVER_FORCE_WSGI_ENVIRON: true
      FF_SYNCSERVER_FORWARDED_ALLOW_IPS: "*"
      FF_SYNCSERVER_PUBLIC_URL: https://ffsync.garudalinux.org
      FF_SYNCSERVER_SECRET: ${FF_SYNCSERVER_SECRET:-?err}
      FF_SYNCSERVER_SQLURI: sqlite:////data/syncserver.db
      TZ: Europe/Berlin
    restart: always
  # Web IRC access
  thelounge:
    image: thelounge/thelounge:4.4.3
    container_name: thelounge
    volumes: ["./thelounge:/var/opt/thelounge"]
    ports: ["9000:9000"]
    restart: always
  # Password vault
  vaultwarden:
    image: vaultwarden/server:1.34.1-alpine
    container_name: vaultwarden
    volumes: ["./bitwarden:/data"]
    ports: ["8081:80"]
    environment:
      ADMIN_TOKEN: ${BW_ADMIN_TOKEN:-?err}
      DOMAIN: https://bitwarden.garudalinux.org
      SIGNUPS_ALLOWED: true
      SMTP_FROM: noreply@garudalinux.org
      SMTP_HOST: mail.garudalinux.org
      SMTP_PASSWORD: ${BW_SMTP_PASSWORD:-?err}
      SMTP_PORT: 587
      SMTP_SSL: false
      SMTP_USERNAME: noreply@garudalinux.org
      WEBSOCKET_ENABLED: true
      YUBICO_CLIENT_ID: ${BW_YUBICO_CLIENT_ID:-?err}
      YUBICO_SECRET_KEY: ${BW_YUBICO_ADMIN_SECRET:-?err}
    restart: always
  # Secure pastebin
  privatebin:
    image: privatebin/nginx-fpm-alpine:1.7.6
    container_name: privatebin
    volumes:
      - ./privatebin:/srv/data
      - ./configs/privatebin.cfg.php:/srv/cfg/conf.php
    ports: ["8082:8080"]
    restart: always
  # WikiJs
  wikijs:
    image: requarks/wiki:2.5
    container_name: wikijs
    volumes: ["./wikijs/assets:/wiki/assets/favicons"]
    ports: ["3001:3000"]
    environment:
      DB_TYPE: postgres
      DB_HOST: 10.0.5.20
      DB_PORT: 5432
      DB_USER: wikijs
      DB_PASS: ${DB_PASS:-?err}
      DB_NAME: wikijs
    restart: always
  # IRC/Discord/Telegram relay
  matterbridge:
    image: 42wim/matterbridge:latest
    container_name: matterbridge
    volumes:
      - ${MATTERBRIDGE_CONFIG:-?err}:/etc/matterbridge/matterbridge.toml:ro
    deploy:
      restart_policy:
        condition: always
        delay: 120s
  # Automated container updates
  watchtower:
    image: containrrr/watchtower:1.7.1
    container_name: watchtower
    command: --cleanup matterbridge wikijs privatebin vaultwarden thelounge syncserver
    volumes: ["/var/run/docker.sock:/var/run/docker.sock"]
    restart: always
volumes:
  nextcloud_aio_mastercontainer:
    name: nextcloud_aio_mastercontainer
    driver_opts:
      type: none
      device: /var/garuda/compose-runner/docker/nextcloud-aio/mastercontainer
      o: bind
  nextcloud_aio_clamav:
    name: nextcloud_aio_clamav
    driver_opts:
      type: none
      device: /var/garuda/compose-runner/docker/nextcloud-aio/clamav
      o: bind
  nextcloud_aio_database:
    name: nextcloud_aio_database
    driver_opts:
      type: none
      device: /var/garuda/compose-runner/docker/nextcloud-aio/database
      o: bind
  nextcloud_aio_nextcloud:
    name: nextcloud_aio_nextcloud
    driver_opts:
      type: none
      device: /var/garuda/compose-runner/docker/nextcloud-aio/nextcloud
      o: bind
  nextcloud_aio_nextcloud_data:
    name: nextcloud_aio_nextcloud_data
    driver_opts:
      type: none
      device: /var/garuda/compose-runner/docker/nextcloud-aio/nextcloud_data
      o: bind
  nextcloud_aio_redis:
    name: nextcloud_aio_redis
    driver_opts:
      type: none
      device: /var/garuda/compose-runner/docker/nextcloud-aio/redis
      o: bind
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker-proxied"><a class="header" href="#docker-proxied">docker-proxied</a></h1>
<h2 id="general-1"><a class="header" href="#general-1">General</a></h2>
<p>Here, all the Docker containers that need to have proxied outgoing requests are being deployed. This is mainly for privacy-focused or alternative frontends and search engines that benefit from outgoing proxying.</p>
<h3 id="container-explanations"><a class="header" href="#container-explanations">Container explanations</a></h3>
<ul>
<li><strong>whoogle</strong>: A self-hosted, ad-free, privacy-respecting metasearch engine that proxies Google Search results.</li>
<li><strong>searx</strong>: SearxNG, a privacy-respecting metasearch engine aggregating results from various sources.</li>
<li><strong>librey</strong>: Librey, a metasearch engine with a focus on privacy and alternative search sources.</li>
<li><strong>lingva</strong>: Lingva Translate, a privacy-friendly alternative frontend for Google Translate.</li>
<li><strong>redlib</strong>: Redlib, a privacy-respecting alternative frontend for Reddit.</li>
<li><strong>watchtower</strong>: Automatically updates running containers to the latest image versions.</li>
<li><strong>autoheal</strong>: Monitors containers and restarts them if they become unhealthy (e.g., Whoogle).</li>
</ul>
<h2 id="restarting-containers"><a class="header" href="#restarting-containers">Restarting containers</a></h2>
<p>This can happen via the following command:</p>
<pre><code class="language-bash">sudo systemctl restart docker-compose-proxied-root
</code></pre>
<h2 id="nix-expression-2"><a class="header" href="#nix-expression-2">Nix expression</a></h2>
<pre><code class="language-nix">{
  config,
  sources,
  ...
}:
{
  imports = sources.defaultModules ++ [ ../../modules ];

  # This container runs proxied docker containers
  garuda.services.compose-runner.docker-proxied = {
    envfile = config.sops.secrets."compose/docker-proxied".path;
    source = ../../../compose/docker-proxied;
  };

  # Let Docker use squid as outgoig proxy
  # Fails to pull images if *.docker.io is not excluded from proxy
  # systemd.services.docker = {
  #   environment = {
  #     HTTPS_PROXY = "http://10.0.5.1:3128";
  #     HTTP_PROXY = "http://10.0.5.1:3128";
  #     NO_PROXY = "localhost,127.0.0.1,*.docker.io,ghcr.io";
  #   };
  # };

  sops.secrets."compose/docker-proxied" = { };

  system.stateVersion = "25.05";
}
</code></pre>
<h3 id="docker-containers-2"><a class="header" href="#docker-containers-2">Docker containers</a></h3>
<pre><code class="language-yaml">services:
  # Whoogle search engine
  whoogle:
    image: benbusby/whoogle-search:latest # It tends do be important to stay current
    container_name: whoogle
    user: whoogle
    security_opt: [no-new-privileges]
    cap_drop: [ALL]
    tmpfs:
      - /var/lib/tor/:size=10M,uid=927,gid=927,mode=1700
      - /run/tor/:size=1M,uid=927,gid=927,mode=1700
    volumes: ['./whoogle:/config']
    ports: ['5000:5000']
    environment:
      WHOOGLE_AUTOCOMPLETE: 1
      WHOOGLE_CONFIG_LANGUAGE: lang_en
      WHOOGLE_CONFIG_NEW_TAB: 1
      WHOOGLE_CONFIG_SEARCH_LANGUAGE: lang_en
      WHOOGLE_CONFIG_STYLE: |
        :root {--whoogle-logo: #4c4f69;--whoogle-page-bg: #eff1f5;--whoogle-element-bg: #bcc0cc;--whoogle-text: #4c4f69;--whoogle-contrast-text: #5c5f77;--whoogle-secondary-text: #6c6f85;
        --whoogle-result-bg: #ccd0da;--whoogle-result-title: #7287fd;--whoogle-result-url: #dc8a78;--whoogle-result-visited: #e64553;--whoogle-dark-logo: #cdd6f4;
        --whoogle-dark-page-bg: #1e1e2e;--whoogle-dark-element-bg: #45475a;--whoogle-dark-text: #cdd6f4;--whoogle-dark-contrast-text: #bac2de;--whoogle-dark-secondary-text: #a6adc8;
        --whoogle-dark-result-bg: #313244;--whoogle-dark-result-title: #b4befe;--whoogle-dark-result-url: #f5e0dc;--whoogle-dark-result-visited: #eba0ac;}
        #whoogle-w {fill: #89b4fa;} #whoogle-h {fill: #f38ba8;}#whoogle-o-1 {fill: #f9e2af;}#whoogle-o-2 {fill: #89b4fa;}#whoogle-g {fill: #a6e3a1;}#whoogle-l {fill: #f38ba8;}
        #whoogle-e {fill: #f9e2af;}
      WHOOGLE_CONFIG_THEME: dark
      WHOOGLE_CONFIG_URL: https://search.garudalinux.org
      WHOOGLE_CONFIG_VIEW_IMAGE: 1
      WHOOGLE_RESULTS_PER_PAGE: 15
    healthcheck:
      test: [CMD-SHELL, 'wget --spider -q --tries=1 http://127.0.0.1:5000']
      interval: 30s
      timeout: 10s
      start_period: 30s
      retries: 1
    restart: always
  # Searxng search engine
  searx:
    image: searxng/searxng:latest # It tends do be important to stay current
    container_name: searx
    volumes: ['./searxng:/etc/searxng']
    ports: ['8080:8080']
    environment:
      BASE_URL: https://searx.garudalinux.org/
      BIND_ADDRESS: 0.0.0.0:8080
      INSTANCE_NAME: Garuda's SearxNG
      NO_PROXY: '*.garudalinux.org'
    cap_drop: [ALL]
    cap_add: [CHOWN, SETGID, SETUID, DAC_OVERRIDE]
    healthcheck:
      test:
        - CMD
        - wget
        - --no-verbose
        - --tries=1
        - --spider
        - http://127.0.0.1:8080/info/en/about
      interval: 2m
      timeout: 5s
    restart: always
  # Librey search engine
  librey:
    image: ghcr.io/ahwxorg/librey:latest # It tends do be important to stay current
    container_name: librey
    ports: ['8081:8080']
    environment:
      - CONFIG_CACHE_TIME=20
      - CONFIG_DISABLE_BITTORRENT_SEARCH=false
      - CONFIG_GOOGLE_DOMAIN=com
      - CONFIG_HIDDEN_SERVICE_SEARCH=true
      - CONFIG_INSTANCE_FALLBACK=true
      - CONFIG_INVIDIOUS_INSTANCE=https://invidious.snopyta.org
      - CONFIG_LANGUAGE=en
      - CONFIG_NUMBER_OF_RESULTS=10
      - CONFIG_RATE_LIMIT_COOLDOWN=25
      - CONFIG_TEXT_SEARCH_ENGINE=google
    healthcheck:
      test:
        - CMD
        - wget
        - --no-verbose
        - --tries=1
        - --spider
        - http://127.0.0.1:8080
      interval: 2m
      timeout: 5s
    restart: always
  # Lingva
  lingva:
    image: thedaviddelta/lingva-translate:latest # Only latest tag is available
    container_name: lingva
    environment:
      DARK_THEME: 'true'
      DEFAULT_SOURCE_LANG: auto
      DEFAULT_TARGET_LANG: en
      SITE_DOMAIN: lingva.garudalinux.org
    ports: ['3002:3000']
    restart: always
  # Reddit frontend
  redlib:
    image: quay.io/redlib/redlib:latest
    container_name: redlib
    environment:
      REDLIB_BANNER_: Garuda's Redlib
      REDLIB_DEFAULT_AUTOPLAY_VIDEOS: true
      REDLIB_DEFAULT_BLUR_NSFW: true
      REDLIB_DEFAULT_COMMENT_SORT: confidence
      REDLIB_DEFAULT_DISABLE_VISIT_REDDIT_CONFIRMATION: false
      REDLIB_DEFAULT_FIXED_NAVBAR: true
      REDLIB_DEFAULT_FRONT_PAGE: popular
      REDLIB_DEFAULT_HIDE_AWARDS: true
      REDLIB_DEFAULT_HIDE_HLS_NOTIFICATION=: true
      REDLIB_DEFAULT_HIDE_SCORE: false
      REDLIB_DEFAULT_LAYOUT: card
      REDLIB_DEFAULT_POST_SORT: hot
      REDLIB_DEFAULT_SHOW_NSFW: false
      REDLIB_DEFAULT_THEME: dracula
      REDLIB_DEFAULT_USE_HLS: true
      REDLIB_DEFAULT_WIDE: false
      REDLIB_PUSHSHIFT_FRONTEND: undelete.pullpush.io
      REDLIB_ROBOTS_DISABLE_INDEXING: true
      REDLIB_SFW_ONLY: false
    ports: ['8082:8080']
    user: nobody
    read_only: true
    security_opt: ['no-new-privileges:true']
    cap_drop: [ALL]
    healthcheck:
      test:
        - CMD
        - wget
        - --spider
        - -q
        - --tries=1
        - http://127.0.0.1:8080/settings
      interval: 5m
      timeout: 3s
    restart: always
  # Automated container updates
  watchtower:
    image: containrrr/watchtower:1.7.1
    container_name: watchtower
    command: --cleanup searx lingva whoogle librey
    volumes: ['/var/run/docker.sock:/var/run/docker.sock']
    restart: always
  # Auto-restart unhealthy containers (looking at you, Whoogle)
  autoheal:
    image: willfarrell/autoheal:latest
    container_name: autoheal
    environment:
      AUTOHEAL_CONTAINER_LABEL: all
    network_mode: none
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - /var/run/docker.sock:/var/run/docker.sock
    restart: always
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forum-aerialis"><a class="header" href="#forum-aerialis">forum (aerialis)</a></h1>
<p>This container hosts the Discourse forum for the Garuda Linux community, providing discussion and support.</p>
<h2 id="links"><a class="header" href="#links">Links</a></h2>
<ul>
<li><a href="https://github.com/discourse/discourse_docker">Discourse Docker</a></li>
</ul>
<h2 id="nix-expression-3"><a class="header" href="#nix-expression-3">Nix expression</a></h2>
<pre><code class="language-nix">{ sources, ... }:
{
  imports = sources.defaultModules ++ [ ../../modules ];

  # Enable Docker since we use the official Docker image in /var/discourse
  virtualisation.docker.enable = true;

  # Open required port
  networking.firewall.allowedTCPPorts = [ 80 ];

  system.stateVersion = "25.05";
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mail-aerialis"><a class="header" href="#mail-aerialis">mail (aerialis)</a></h1>
<p>This container handles mail-related services and relays for the infrastructure, such as SMTP/IMAP relaying or filtering.</p>
<h2 id="nix-expression-4"><a class="header" href="#nix-expression-4">Nix expression</a></h2>
<p>Configuration for the <code>mail</code> container on aerialis.</p>
<pre><code class="language-nix">{
  config,
  lib,
  pkgs,
  sources,
  garuda-lib,
  sops,
  ...
}:
let
  authres_status = pkgs.roundcubePlugins.roundcubePlugin rec {
    pname = "authres_status";
    version = "0.7.0";
    src = pkgs.fetchzip {
      url = "https://github.com/pimlie/authres_status/archive/refs/tags/${version}.zip";
      hash = "sha256-+rnHc2vJC4ozRdcHAYg1J5rIWe4k/yTgD5xYr9NA/Hg=";
    };
  };
in
{
  imports = sources.defaultModules ++ [ ../../modules ];

  # NixOS Mailserver
  mailserver = {
    certificateScheme = "acme-nginx";
    dmarcReporting.enable = true;
    domains = [
      "garudalinux.org"
      "dr460nf1r3.org"
    ];
    enable = true;
    fqdn = "mail.garudalinux.net";
    fullTextSearch = {
      enable = true;
      enforced = "body";
      memoryLimit = 512;
    };
    # To create the password hashes, use nix-shell -p mkpasswd --run 'mkpasswd -sm bcrypt'
    loginAccounts = {
      # garudalinux.org
      "cloud@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/cloudatgl".path;
        sendOnly = true;
      };
      "complaints@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/complaintsatgl".path;
      };
      "dr460nf1r3@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/dr460nf1r3atgl".path;
      };
      "filo@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/filoatgl".path;
      };
      "gitlab@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/gitlabatgl".path;
      };
      "mastodon@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/mastodonatgl".path;
        sendOnly = true;
      };
      "naman@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/namanatgl".path;
      };
      "noreply@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/noreplyatgl".path;
      };
      "rohit@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/rohitatgl".path;
      };
      "security@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/securityatgl".path;
      };
      "sgs@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/sgsatgl".path;
      };
      "spam-reports@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/spam-reportsatgl".path;
      };
      "team@garudalinux.org" = {
        aliases = [
          "admin@garudalinux.org"
          "ci@garudalinux.org"
          "root@garudalinux.org"
          "webmaster@garudalinux.org"
        ];
        hashedPasswordFile = config.sops.secrets."mail/teamatgl".path;
      };
      "tne@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/tneatgl".path;
      };
      "yorper@garudalinux.org" = {
        hashedPasswordFile = config.sops.secrets."mail/yorperatgl".path;
      };
      # dr460nf1r3.org
      "noreply@dr460nf1r3.org" = {
        hashedPasswordFile = config.sops.secrets."mail/noreplyatdf".path;
      };
      "test@dr460nf1r3.org" = {
        hashedPasswordFile = config.sops.secrets."mail/testatdf".path;
      };
    };
    indexDir = "/var/lib/dovecot/indices";
    # We do it via UptimeKuma, and since we don't enable NAT reflection in this server, this
    # shuts down the services.
    monitoring.enable = false;
    systemDomain = "garudalinux.org";
    systemName = "Garuda Linux";
  };

  # Fix dovecot errors caused by failed scudo allocations
  environment.memoryAllocator.provider = lib.mkForce "libc";

  # Set up push notifications
  services.dovecot2.mailPlugins.globally.enable = [
    "notify"
    "push_notification"
  ];

  # Postmaster alias
  services.postfix.postmasterAlias = "nico@dr460nf1r3.org";

  # Web UI
  services.roundcube = {
    enable = true;
    # this is the url of the vhost, not necessarily the same as the fqdn of
    # the mailserver
    hostName = "mail.garudalinux.net";
    extraConfig = ''
      # starttls needed for authentication, so the fqdn required to match
      # the certificate
      $config['smtp_server'] = "tls://${config.mailserver.fqdn}";
      $config['smtp_user'] = "%u";
      $config['smtp_pass'] = "%p";
    '';
    package = pkgs.roundcube.withPlugins (plugins: [
      authres_status
      plugins.carddav
      plugins.contextmenu
      plugins.custom_from
      plugins.persistent_login
      plugins.thunderbird_labels
    ]);
    plugins = [
      "attachment_reminder" # Roundcube internal plugin
      "authres_status"
      "carddav"
      "contextmenu"
      "custom_from"
      "managesieve" # Roundcube internal plugin
      "newmail_notifier" # Roundcube internal plugin
      "persistent_login"
      "thunderbird_labels"
      "zipdownload" # Roundcube internal plugin
    ];
  };
  services.nginx.virtualHosts."mail.garudalinux.net" = {
    forceSSL = lib.mkForce false;
  };

  # Secrets
  sops.secrets = {
    "backup/repo_key" = { };
    "backup/ssh_aerialis" = { };
    "mail/cloudatgl" = { };
    "mail/complaintsatgl" = { };
    "mail/dr460nf1r3atgl" = { };
    "mail/filoatgl" = { };
    "mail/gitlabatgl" = { };
    "mail/mastodonatgl" = { };
    "mail/namanatgl" = { };
    "mail/noreplyatgl" = { };
    "mail/rohitatgl" = { };
    "mail/securityatgl" = { };
    "mail/sgsatgl" = { };
    "mail/spam-reportsatgl" = { };
    "mail/teamatgl" = { };
    "mail/testatdf" = { };
    "mail/tneatgl" = { };
    "mail/yorperatgl" = { };
    "mail/noreplyatdf" = { };
  };

  system.stateVersion = "22.05";

  # https://nixos-mailserver.readthedocs.io/en/latest/migrations.html
  mailserver.stateVersion = 3;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mastodon-aerialis"><a class="header" href="#mastodon-aerialis">mastodon (aerialis)</a></h1>
<p>This container runs the Mastodon social network instance for Garuda Linux, providing decentralized microblogging.</p>
<h2 id="nix-expression-5"><a class="header" href="#nix-expression-5">Nix expression</a></h2>
<p>Configuration for the <code>mastodon</code> container on aerialis.</p>
<pre><code class="language-nix">{
  config,
  garuda-lib,
  lib,
  pkgs,
  sources,
  ...
}:
let
  # https://git.kempkens.io/daniel/dotfiles/src/branch/master/system/nixos/mastodon.nix
  pkg-base = pkgs.mastodon;
  pkg-mastodon = pkg-base.overrideAttrs (_: {
    mastodonModules = pkg-base.mastodonModules.overrideAttrs (
      oldMods:
      let
        tangerine-ui = pkgs.fetchFromGitHub {
          owner = "nileane";
          repo = "TangerineUI-for-Mastodon";
          rev = "v2.4.3";
          hash = "sha256-OThT3fp676RMfYY3ehzM4DnAlJOqdPoYIHpoBbN/RHQ=";
        };
      in
      {
        pname = "${oldMods.pname}+themes";

        postPatch = ''
          styleDir=$PWD/app/javascript/styles

          cp -r ${tangerine-ui}/mastodon/app/javascript/styles/* $styleDir

          echo "tangerineui: styles/tangerineui.scss" &gt;&gt;$PWD/config/themes.yml
          echo "tangerineui-purple: styles/tangerineui-purple.scss" &gt;&gt;$PWD/config/themes.yml
          echo "tangerineui-cherry: styles/tangerineui-cherry.scss" &gt;&gt;$PWD/config/themes.yml
          echo "tangerineui-lagoon: styles/tangerineui-lagoon.scss" &gt;&gt;$PWD/config/themes.yml
        '';
      }
    );

    nativeBuildInputs = [ pkgs.yq-go ];

    postBuild = ''
      # Make theme available
      echo "tangerineui: styles/tangerineui.scss" &gt;&gt;$PWD/config/themes.yml
      echo "tangerineui-purple: styles/tangerineui-purple.scss" &gt;&gt;$PWD/config/themes.yml
      echo "tangerineui-cherry: styles/tangerineui-cherry.scss" &gt;&gt;$PWD/config/themes.yml
      echo "tangerineui-lagoon: styles/tangerineui-lagoon.scss" &gt;&gt;$PWD/config/themes.yml

      yq -i '.en.themes.tangerineui = "Tangerine UI"' $PWD/config/locales/en.yml
      yq -i '.en.themes.tangerineui-purple = "Tangerine UI (Purple)"' $PWD/config/locales/en.yml
      yq -i '.en.themes.tangerineui-cherry = "Tangerine UI (Cherry)"' $PWD/config/locales/en.yml
      yq -i '.en.themes.tangerineui-lagoon = "Tangerine UI (Lagoon)"' $PWD/config/locales/en.yml
    '';
  });
in
{
  imports = sources.defaultModules ++ [ ../../modules ];

  # This container is just for compose stuff
  garuda.services.compose-runner.mastodon = {
    source = ../../../compose/mastodon;
  };

  # Our Mastodon
  services.mastodon = {
    configureNginx = true;
    database = {
      createLocally = false;
      host = "10.0.5.20";
      name = "mastodon";
      passwordFile = config.sops.secrets."mastodon/db_password".path;
      user = "mastodon";
    };
    enable = true;
    extraConfig = {
      "LOCAL_DOMAIN" = "garudalinux.org";
      "SMTP_DOMAIN" = "social.garudalinux.org";
      "WEB_DOMAIN" = "social.garudalinux.org";
    };
    extraEnvFiles = [ config.sops.secrets."mastodon/env".path ];
    localDomain = "social.garudalinux.org";
    mediaAutoRemove = {
      enable = true;
      startAt = "daily";
      olderThanDays = 7;
    };
    package = pkg-mastodon;
    smtp = {
      authenticate = true;
      fromAddress = "noreply@garudalinux.org";
      host = "mail.garudalinux.net";
      passwordFile = config.sops.secrets."mastodon/smtp_password".path;
      port = 587;
      user = "noreply@garudalinux.org";
    };
    streamingProcesses = 16;
    redis = {
      createLocally = false;
      enableUnixSocket = false;
      host = "localhost";
      port = 6379;
    };
  };

  # This disables HTTPS certificates and forced redirects
  garuda-lib.behind_proxy = true;

  services.nginx = {
    recommendedProxySettings = lib.mkForce false;
    virtualHosts."social.garudalinux.org" = {
      enableACME = lib.mkForce false;
      forceSSL = lib.mkForce false;
      extraConfig = ''
        real_ip_header          X-Real-IP;
        set_real_ip_from        10.0.5.10;
        proxy_redirect          off;
        proxy_connect_timeout   60s;
        proxy_send_timeout      60s;
        proxy_read_timeout      60s;
        proxy_http_version      1.1;
        proxy_set_header        Upgrade $http_upgrade;
        proxy_set_header        Connection $connection_upgrade;
        proxy_set_header        Host $host;
        proxy_set_header        X-Real-IP $remote_addr;
        proxy_set_header        X-Forwarded-For $remote_addr;
        # I'm a filthy liar
        proxy_set_header        X-Forwarded-Proto https;
        proxy_set_header        X-Forwarded-Host $http_x_forwarded_host;
        proxy_set_header        X-Forwarded-Server $http_x_forwarded_server;
      '';
      locations = {
        "@proxy" = {
          proxyWebsockets = lib.mkForce false;
          extraConfig = ''
            real_ip_header          X-Real-IP;
            set_real_ip_from        10.0.5.10;
            proxy_redirect          off;
            proxy_connect_timeout   60s;
            proxy_send_timeout      60s;
            proxy_read_timeout      60s;
            proxy_http_version      1.1;
            proxy_set_header        Upgrade $http_upgrade;
            proxy_set_header        Connection $connection_upgrade;
            proxy_set_header        Host $host;
            proxy_set_header        X-Real-IP $remote_addr;
            proxy_set_header        X-Forwarded-For $remote_addr;
            # I'm a filthy liar
            proxy_set_header        X-Forwarded-Proto https;
            proxy_set_header        X-Forwarded-Host $http_x_forwarded_host;
            proxy_set_header        X-Forwarded-Server $http_x_forwarded_server;
          '';
        };
        "/api/v1/streaming/" = {
          proxyWebsockets = lib.mkForce false;
        };
      };
    };
  };

  sops.secrets = {
    "mastodon/db_password" = {
      owner = "mastodon";
      group = "mastodon";
    };
    "mastodon/env" = {
      owner = "mastodon";
      group = "mastodon";
    };
    "mastodon/smtp_password" = {
      owner = "mastodon";
      group = "mastodon";
    };
  };

  system.stateVersion = "25.05";
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="postgres-aerialis"><a class="header" href="#postgres-aerialis">postgres (aerialis)</a></h1>
<p>This container provides PostgreSQL database services for other containers and applications on aerialis.</p>
<h2 id="general-2"><a class="header" href="#general-2">General</a></h2>
<p>This container houses our Postgres database. Multiple services access it:</p>
<ul>
<li>Mastodon</li>
<li>Matrix</li>
<li>Matrix bridges</li>
<li>WikiJs</li>
</ul>
<h2 id="admin-interface"><a class="header" href="#admin-interface">Admin interface</a></h2>
<p>The admin interface powered by Pgadmin can be accessed <a href="https://pgadmin.garudalinux.net">here</a>.
Authentication happens via Cloudflare Access.</p>
<h2 id="nix-expression-6"><a class="header" href="#nix-expression-6">Nix expression</a></h2>
<pre><code class="language-nix">{
  inputs,
  pkgs,
  sources,
  config,
  lib,
  ...
}:
let
  server_config = pkgs.writeText "server-config" ''
    {
      "Servers": {
        "1": {
          "Name": "Main",
          "Group": "Garuda",
          "Username": "pgadmin",
          "Host": "/var/run/postgresql",
          "Port": 5432,
          "SSLMode": "prefer",
          "MaintenanceDB": "postgres",
          "PassFile": "/dev/null",
          "Shared": true,
          "SharedUsername": "pgadmin"
        }
      }
    }
  '';
in
{
  imports = sources.defaultModules ++ [ ../../modules ];

  # Our Postgres database
  services.postgresql = {
    enable = true;
    ensureDatabases = [
      "chaotic-aur"
      "mastodon"
      "wikijs"
    ];
    ensureUsers = [
      {
        name = "mastodon";
        ensureDBOwnership = true;
      }
      {
        name = "wikijs";
        ensureDBOwnership = true;
      }
      {
        name = "pgadmin";
        ensureClauses.superuser = true;
      }
      {
        name = "chaotic-router";
      }
      {
        name = "chaotic-aur";
        ensureDBOwnership = true;
      }
    ];
    initialScript = pkgs.writeText "backend-initScript" ''
      CREATE USER netdata;
      GRANT pg_monitor TO netdata;
    '';
    authentication = lib.mkForce ''
      local all all peer
      host chaotic-aur chaotic-router 0.0.0.0/0 scram-sha-256
      # Reject anything else coming from the outside world somehow someway
      host all all 10.0.5.1/32 reject
      # Allow connections from the internal network
      host all all 10.0.5.0/24 md5
      # Allow localhost connections
      host all all 127.0.0.1/32 md5
      # Block the rest of the internet
      host all all 0.0.0.0/0 reject
    '';
    # This is publically accesible now through port 5432, however only the chaotic-router user can access the database through the internet
    enableTCPIP = true;
  };

  # Regular backups for our database (every 6h)
  services.postgresqlBackup = {
    compression = "zstd";
    enable = true;
    location = "/var/garuda/backups/postgres";
  };

  services.pgadmin = {
    enable = true;
    initialEmail = "team@garudalinux.org";
    initialPasswordFile = config.sops.secrets."postgres/pg_admin".path;
    openFirewall = true;
    settings = {
      FIXED_BINARY_PATHS = {
        "pg" = "${config.services.postgresql.package}/bin";
      };
      SUPPORT_SSH_TUNNEL = false;
      AUTHENTICATION_SOURCES = [ "webserver" ];
      WEBSERVER_REMOTE_USER = "X-Forwarded-User";
      MASTER_PASSWORD_REQUIRED = false;
    };
    package = inputs.nixpkgs-stable.legacyPackages."${pkgs.system}".pgadmin4;
  };

  systemd.services.pgadmin = {
    preStart = lib.mkAfter ''
      EMAIL=${lib.escapeShellArg config.services.pgadmin.initialEmail}
      FILE=${lib.escapeShellArg server_config}
      ${config.services.pgadmin.package}/bin/pgadmin4-cli load-servers "$FILE" --user "$EMAIL"
    '';
  };

  # Open up ports for Postgres
  networking.firewall.allowedTCPPorts = [ 5432 ];

  sops.secrets."postgres/pg_admin" = { };

  system.stateVersion = "23.05";
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="web-front-aerialis"><a class="header" href="#web-front-aerialis">web-front (aerialis)</a></h1>
<p>This container acts as the main reverse proxy and web frontend for hosted services on aerialis, handling HTTPS termination and routing.</p>
<h2 id="general-3"><a class="header" href="#general-3">General</a></h2>
<p>This container is used as a reverse proxy for all of our public facing services.
It also contains a Cloudflared instance,
which a few services are only being exposed to, instead of being reverse proxied by Nginx itself.</p>
<h2 id="nix-expression-7"><a class="header" href="#nix-expression-7">Nix expression</a></h2>
<pre><code class="language-nix">{
  config,
  garuda-lib,
  pkgs,
  sources,
  ...
}:
let
  inherit (garuda-lib) allowOnlyCloudflared;
  inherit (garuda-lib) allowOnlyCloudflareZerotrust;
  inherit (garuda-lib) generateCloudflaredIngress;

  website =
    let
      # Run Nx command with fake TTY to avoid panic
      # https://github.com/nrwl/nx/issues/22445
      nx = pkgs.writeScript "nx-wrapper" ''
        exec ${pkgs.faketty}/bin/faketty nx "$@"
      '';
    in
    pkgs.stdenv.mkDerivation (finalAttrs: {
      pname = "garuda-website";
      version = "1.0.0";

      src = sources.garuda-website;

      nativeBuildInputs = with pkgs; [
        nodejs_22
        pnpm_10.configHook
      ];
      pnpmDeps = pkgs.pnpm_10.fetchDeps {
        inherit (finalAttrs) pname version src;
        fetcherVersion = 1;
        hash = "sha256-tjcD/1Opv5jGeWdFvA4xw4V5L7nj1HBs3WiwNXPjWHk=";
      };
      buildPhase = ''
        export PATH=$(pnpm bin):$PATH
        ${nx} build &amp;&amp; ${nx} transloco:optimize
      '';
      installPhase = ''
        cp -r ./dist/website/browser $out
      '';
    });
in
rec {
  imports = sources.defaultModules ++ [ ../../modules ];

  services.nginx = {
    enable = true;
    virtualHosts = {
      "garudalinux.org" = {
        addSSL = true;
        http3 = true;
        locations = {
          "/" = {
            index = "index.html";
            root = website;
            extraConfig = ''
              # First attempt to serve request as file, then
              # as directory, then redirect to index.html (Angular) if no file found.
              try_files $uri $uri/ /index.html;
            '';
          };
          "/discord" = {
            extraConfig = "expires 12h;";
            return = "307 https://discord.gg/w5jbhq3juh";
          };
          "/telegram" = {
            extraConfig = "expires 12h;";
            return = "307 https://t.me/+TAZWHgryP6elOyS8";
          };
          "/os/garuda-update/backuprepo" = {
            extraConfig = ''
              rewrite ^/os/garuda-update/backuprepo/(.*)$ https://geo-mirror.chaotic.cx/chaotic-aur/$1 redirect;
            '';
          };
          "/os/garuda-update/remote-update" = {
            extraConfig = "expires 12h;";
            return = "301 https://gitlab.com/garuda-linux/themes-and-settings/settings/garuda-common-settings/-/snippets/2147440/raw/main/remote-update";
          };
          "/os/garuda-update/garuda-hotfixes-version" = {
            extraConfig = "expires 5m;";
            return = "200 '1'";
          };
          "/.well-known/webfinger" = {
            extraConfig = "expires 12h;";
            return = "301 https://social.garudalinux.org$request_uri";
          };
        };
        quic = true;
        serverAliases = [ "www.garudalinux.org" ];
        useACMEHost = "garudalinux.org";
      };
      "cloud-aio.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            extraConfig = ''
              client_body_buffer_size 512k;
              proxy_read_timeout 86400s;
              client_max_body_size 0;

              # Allow accessing through trusted domain
              set_real_ip_from      172.0.0.0/16;
            '';
            proxyPass = "http://10.0.5.60:11000";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "cloud-temp.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            extraConfig = ''
              client_body_buffer_size 512k;
              proxy_read_timeout 86400s;
              client_max_body_size 0;

              # Allow accessing through trusted domain
              set_real_ip_from      172.0.0.0/16;
            '';
            proxyPass = "https://10.0.5.60:8080";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "search.garudalinux.org" = allowOnlyCloudflared {
        addSSL = true;
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.50:5000";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
        extraConfig = ''
          ${garuda-lib.nginxReverseProxySettings}
        '';
      };
      "searx.garudalinux.org" = allowOnlyCloudflared {
        addSSL = true;
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.50:8080";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
        extraConfig = ''
          ${garuda-lib.nginxReverseProxySettings}
        '';
      };
      "librey.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.50:8081";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "ffsync.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.60:5001";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "irc.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.60:9000";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "bin.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.60:8082";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "bitwarden.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.60:8081";
          };
        };
        quic = true;
        serverAliases = [ "vault.garudalinux.org" ];
        useACMEHost = "garudalinux.org";
      };
      "forum.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          client_max_body_size 100M;
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.40:80";
          };
          "/c/announcements/announcements-maintenance/45.json" = {
            extraConfig = "expires 2m;";
            proxyPass = "http://10.0.5.40:80";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "social.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          client_max_body_size 100M;
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.30";
          };
          "/.well-known/webfinger" = {
            proxyPass = "http://10.0.5.30";
            extraConfig = ''
              if ($args ~* "resource=acct:(.*)@(chaotic.cx|social.garudalinux.org)$") {
                set $w1 $1;
                rewrite .* /.well-known/webfinger?resource=acct:$w1@garudalinux.org? break;
              }
            '';
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "social-video.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          client_max_body_size 100M;
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
          location ~* .(mp4|webm)$ {
            proxy_pass http://10.0.5.30;
          }
        '';
        locations = {
          "/" = {
            return = "301 https://social.garudalinux.org$request_uri";
          };
        };
        http3 = true;
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "element.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          # Redirect to forum post
          "/" = {
            return = "301 https://forum.garudalinux.org/t/39538";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "matrix.garudalinux.org" = {
        addSSL = true;
        http3 = true;
        listen = [
          {
            addr = "0.0.0.0";
            port = 443;
            ssl = true;
          }
        ];
        locations = {
          "/" = {
            # Redirect to forum post
            return = "301 https://forum.garudalinux.org/t/39538";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "lingva.garudalinux.org" = allowOnlyCloudflared {
        addSSL = true;
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.60:3002";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
        extraConfig = ''
          ${garuda-lib.nginxReverseProxySettings}
        '';
      };
      "reddit.garudalinux.org" = allowOnlyCloudflared {
        addSSL = true;
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.50:8082";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
        extraConfig = ''
          ${garuda-lib.nginxReverseProxySettings}
        '';
      };
      "pgadmin.garudalinux.net" = allowOnlyCloudflareZerotrust {
        locations = {
          "/" = {
            extraConfig = ''
              ${garuda-lib.nginxReverseProxySettings}

              proxy_pass http://10.0.5.20:5050;
              proxy_set_header X-Forwarded-User $http_cf_access_authenticated_user_email;

              proxy_hide_header Cache-Control;
              proxy_hide_header Expires;
              add_header Cache-Control 'no-store';
            '';
          };
        };
      };
      "wiki.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.60:3001";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
      };
      "chaotic-backend.garudalinux.org" = {
        addSSL = true;
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.70:3000";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.org";
        extraConfig = ''
          ${garuda-lib.nginxReverseProxySettings}
        '';
      };
      "mail.garudalinux.net" = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.80:80";
          };
        };
        quic = true;
        useACMEHost = "garudalinux.net";
      };
      # Default catch-all for unknown domains
      "_" = {
        addSSL = true;
        extraConfig = ''
          log_not_found off;
          return 404;
        '';
        http3 = true;
        quic = true;
        useACMEHost = "garudalinux.org";
      };
    };
  };

  services.garuda-cloudflared = {
    enable = true;
    ingress = {
      # "example.garudalinux.net" = "http://10.0.5.100:8085";
    } // (generateCloudflaredIngress services.nginx.virtualHosts);
    tunnel-credentials = config.sops.secrets."cloudflare/tunnels/aerialis".path;
  };

  sops.secrets."cloudflare/tunnels/aerialis" = { };

  system.stateVersion = "25.05";
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="stormwing"><a class="header" href="#stormwing">stormwing</a></h1>
<p>This is one of the two main infrastructure hosts (see also: aerialis). All services and containers for stormwing are defined in <code>nixos/hosts/stormwing.nix</code> and its submodules.</p>
<h2 id="host-configuration-1"><a class="header" href="#host-configuration-1">Host configuration</a></h2>
<pre><code class="language-nix">{
  config,
  lib,
  pkgs,
  ...
}:
{
  imports = [
    ../modules
    ./../modules/special/hetzner-ex44.nix
  ];

  fileSystems."/" = {
    device = "none";
    fsType = "tmpfs";
    options = [
      "defaults"
      "size=50%"
      "mode=755"
    ];
  };

  fileSystems."/data_1" = {
    device = "/dev/disk/by-label/NIXROOT";
    fsType = "ext4";
    neededForBoot = true;
    options = [
      "defaults"
      "noatime"
      "nodiratime"
      "errors=remount-ro"
    ];
    depends = [
      "/"
    ];
  };

  fileSystems."/data_2" = {
    device = "/dev/disk/by-label/NIXDATA";
    fsType = "btrfs";
    options = [
      "defaults"
      "noatime"
      "nodiratime"
      "compress=zstd:1"
    ];
  };

  fileSystems."/boot" = {
    device = "/dev/disk/by-label/NIXBOOT";
    fsType = "vfat";
  };

  swapDevices = [
    {
      device = "/data_1/swapfile";
      size = 32 * 1024;
    }
  ];

  services.openssh.ports = [ 666 ];

  # Network configuration with a bridge interface
  networking = {
    defaultGateway = "157.180.57.1";
    defaultGateway6 = {
      address = "fe80::1";
      interface = "eth0";
    };
    hostName = "stormwing";
    interfaces = {
      "eth0" = {
        ipv4.addresses = [
          {
            address = "157.180.57.51";
            prefixLength = 26;
          }
        ];
      };
    };
    # Specify these here to allow containers to access
    # our services from the internal network via NAT reflection
    nat.forwardPorts = [
      # Here because we need to take advantage of NAT reflection.
      # In general, SSH ports should not be here.
      {
        # chaotic-v4 (SSH)
        destination = "10.0.5.10:22";
        loopbackIPs = [ "157.180.57.51" ];
        proto = "tcp";
        sourcePort = 210;
      }
      {
        # web-front (HTTP)
        destination = "10.0.5.40:80";
        loopbackIPs = [ "157.180.57.51" ];
        proto = "tcp";
        sourcePort = 80;
      }
      {
        # web-front (HTTPS)
        destination = "10.0.5.40:443";
        loopbackIPs = [ "157.180.57.51" ];
        proto = "tcp";
        sourcePort = 443;
      }
      {
        # web-front (HTTPS)
        destination = "10.0.5.40:443";
        loopbackIPs = [ "157.180.57.51" ];
        proto = "udp";
        sourcePort = 443;
      }
    ];
    firewall.trustedInterfaces = [ "br0" ];
  };

  # Container config
  services.garuda-nspawn = {
    bridgeInterface = "br0";
    hostInterface = "eth0";
    hostIp = "10.0.5.1";
    dockerCache = "/data_1/dockercache/";

    defaults = {
      maxMemorySoft = 48318382080; # 45 GiB
      maxMemoryHard = 53687091200; # 50 GiB
      maxCpu = 18;
    };

    containers = {
      chaotic-v4 = {
        config = import ./stormwing/chaotic-v4.nix;
        extraOptions = {
          bindMounts = {
            # Begin data_1
            "chaotic" = {
              hostPath = "/data_1/containers/chaotic-v4/chaotic";
              isReadOnly = false;
              mountPoint = "/var/garuda/compose-runner/chaotic-v4";
            };
            "syncthing" = {
              hostPath = "/data_1/containers/chaotic-v4/syncthing";
              isReadOnly = false;
              mountPoint = "/var/lib/syncthing";
            };
            # End data_1
            # Begin data_2
            "chaotic-v4" = {
              hostPath = "/data_2/chaotic-v4/";
              isReadOnly = false;
              mountPoint = "/srv/http/repos";
            };
            "iso-builds" = {
              hostPath = "/data_2/iso/iso";
              isReadOnly = false;
              mountPoint = "/srv/http/iso";
            };
            # End data_2
          };
          forwardPorts = [
            {
              containerPort = 873;
              hostPort = 873;
              protocol = "tcp";
            }
            {
              containerPort = 21027;
              hostPort = 21027;
              protocol = "udp";
            }
            {
              containerPort = 22000;
              hostPort = 22000;
              protocol = "tcp";
            }
            {
              containerPort = 22000;
              hostPort = 22000;
              protocol = "udp";
            }
          ];
          enableTun = true;
        };
        ipAddress = "10.0.5.10";
        needsDocker = true;
        # Only entitled to 1/5 of the CPU resources in case of contention
        cpuWeight = 20;
        ioWeight = 20;
      };
      github-runner = {
        config = import ./stormwing/github-runner.nix;
        defaults = false;
        extraOptions = {
          bindMounts = {
            "token" = {
              hostPath = config.sops.secrets."compose/github-runner".path;
              isReadOnly = true;
              mountPoint = "/var/.github-runner.env";
            };
            "gitlab-config" = {
              hostPath = "/data_1/containers/github-runner/gitlab-runner";
              isReadOnly = false;
              mountPoint = "/etc/gitlab-runner";
            };
            "ssh-keys" = {
              hostPath = "/data_1/containers/github-runner/ssh";
              isReadOnly = false;
              mountPoint = "/etc/ssh";
            };
            "github-cache" = {
              hostPath = "/data_1/cache/github-runner";
              isReadOnly = false;
              mountPoint = "/var/cache/github-runner";
            };
          };
          forwardPorts = [
            {
              containerPort = 22;
              hostPort = 230;
              protocol = "tcp";
            }
          ];
          ephemeral = lib.mkForce true;
        };
        ipAddress = "10.0.5.30";
        needsDocker = true;
        # Only entitled to 1/5 of the CPU resources in case of contention
        cpuWeight = 20;
        ioWeight = 20;
      };
      firedragon-runner = {
        config = import ./stormwing/firedragon-runner.nix;
        defaults = false;
        extraOptions = {
          bindMounts = {
            "firedragon-runner" = {
              hostPath = "/data_1/containers/firedragon-runner";
              isReadOnly = false;
              mountPoint = "/var/garuda/compose-runner/firedragon-runner";
            };
          };
          ephemeral = lib.mkForce true;
        };
        ipAddress = "10.0.5.50";
        needsDocker = true;
        # Only entitled to 10% of the CPU resources in case of contention
        cpuWeight = 10;
        ioWeight = 10;
      };
      iso-runner = {
        config = import ./stormwing/iso-runner.nix;
        extraOptions = {
          bindMounts = {
            "iso" = {
              hostPath = "/data_2/iso/";
              isReadOnly = false;
              mountPoint = "/var/garuda/buildiso";
            };
            "cache" = {
              hostPath = "/data_1/cache/iso-runner";
              isReadOnly = false;
              mountPoint = "/var/garuda/buildiso/cache";
            };
            "pacman_cache" = {
              hostPath = "/data_1/cache/pacman-cache";
              isReadOnly = false;
              mountPoint = "/var/cache/pacman/pkg";
            };
          };
          forwardPorts = [
            {
              containerPort = 22;
              hostPort = 220;
              protocol = "tcp";
            }
          ];
        };
        ipAddress = "10.0.5.20";
        needsDocker = true;
      };
      web-front = {
        config = import ./stormwing/web-front.nix;
        extraOptions = {
          bindMounts = {
            "acme" = {
              hostPath = "/data_2/containers/web-front/acme";
              isReadOnly = false;
              mountPoint = "/var/lib/acme";
            };
            "nginx" = {
              hostPath = "/data_2/containers/web-front/nginx";
              isReadOnly = false;
              mountPoint = "/var/log/nginx";
            };
          };
          forwardPorts = [
            {
              containerPort = 22;
              hostPort = 240;
              protocol = "tcp";
            }
          ];
        };
        ipAddress = "10.0.5.40";
      };
    };
  };

  # Monitor a few services of the containers
  services = {
    netdata.configDir = {
      "go.d/web_log.conf" = pkgs.writeText "web_log.conf" ''
        jobs:
          - name: nginx
            path: /data_2/containers/web-front/nginx/access.log
      '';
    };
  };

  deployment = {
    targetHost = "157.180.57.51";
    targetPort = 666;
    targetUser = "ansible";
  };

  sops.secrets = {
    "compose/github-runner" = { };
  };
}
</code></pre>
<h2 id="containersservices-1"><a class="header" href="#containersservices-1">Containers/services</a></h2>
<ul>
<li><a href="hosts/chaotic-v4.html">chaotic-v4</a>: Main Chaotic-AUR builder and repository sync container.</li>
<li><a href="hosts/firedragon-runner.html">firedragon-runner</a>: CI runner for building and testing the Firedragon browser.</li>
<li><a href="hosts/github-runner.html">github-runner</a>: GitHub Actions runner for CI/CD tasks related to Garuda Linux projects.</li>
<li><a href="hosts/iso-runner.html">iso-runner</a>: Dedicated builder for Garuda Linux ISO images.</li>
<li><a href="hosts/web-front.html">web-front</a>: Reverse proxy and web frontend for services running on stormwing.</li>
</ul>
<p>See the respective documentation pages for up-to-date configuration and details.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chaotic-v4-stormwing"><a class="header" href="#chaotic-v4-stormwing">chaotic-v4 (stormwing)</a></h1>
<p>This container is the main Chaotic-AUR builder and repository sync node, responsible for building and distributing packages.</p>
<h2 id="general-4"><a class="header" href="#general-4">General</a></h2>
<p>This is the nspawn container used to run Chaotic-AUR's new build system, <code>infra 4.0</code>.</p>
<p>Restarting the Docker stack, in case it is needed, can happen via <code>sudo chaotic-restart</code>.
For information on how to use the new build system, please refer to the <a href="hosts/stormwing/../services/chaotic-4.0.html">documentation</a>.</p>
<p>In general, manual intervention should not be needed,
as the system is designed to be fully automated via GitLab CI or GitHub actions.</p>
<h2 id="nix-expression-8"><a class="header" href="#nix-expression-8">Nix expression</a></h2>
<pre><code class="language-nix">{
  config,
  garuda-lib,
  sources,
  pkgs,
  ...
}:
let
  wrapperScript = pkgs.writeScriptBin "chaotic-restart" ''
    echo "Restarting Chaotic-AUR containers..."
    systemctl restart compose-runner-chaotic-v4.service
    echo "Done."
  '';
in
{
  imports = sources.defaultModules ++ [
    ../../modules
    "${sources.chaotic-portable-builder}/nix/nixos.nix"
    ../../modules/special/ssh-allow-chaotic.nix
  ];

  # This container is just for compose stuff
  garuda.services.compose-runner.chaotic-v4 = {
    envfile = config.sops.secrets."compose/chaotic-v4".path;
    source = ../../../compose/chaotic-v4;
    extraEnv = {
      "REDIS_SSH_HOST" = garuda-lib.dns.aerialis;
      "REDIS_SSH_PORT" = "270";
    };
  };

  # Allow controlling infra 4.0's containers without root
  environment.systemPackages = [ wrapperScript ];
  security.sudo.extraRules = [
    {
      users = [ "xiota" ];
      commands = [
        {
          command = "${wrapperScript}/bin/chaotic-restart";
          options = [ "NOPASSWD" ];
        }
      ];
    }
  ];

  # Expose raw /proc for podman
  systemd.services.expose-raw-proc = {
    description = "Expose clean /proc for podman";
    wantedBy = [ "multi-user.target" ];
    serviceConfig.Type = "oneshot";
    script = ''
      mkdir /tmp/raw_proc
      ${pkgs.mount}/bin/mount --bind /proc /tmp/raw_proc
    '';
  };

  networking.firewall.allowedTCPPorts = [
    config.services.rsyncd.port # Rsync
    8384 # Syncthing web interface
  ];

  # Enable the user accounts of chaotic maintainers
  garuda-lib.chaoticUsers = true;

  # Syncthing setup
  services.syncthing = {
    enable = true;
    openDefaultPorts = true;
    configDir = config.services.syncthing.dataDir;
    cert = config.sops.secrets."keypairs/syncthing/cert".path;
    key = config.sops.secrets."keypairs/syncthing/private".path;
    overrideFolders = false;
    overrideDevices = false;
    user = "root";
    group = "chaotic-op";
    settings = {
      gui = {
        apikey = "garudalinux";
        insecureSkipHostcheck = true;
        inherit (garuda-lib.secrets.syncthing.esxi-build.credentials) user password;
      };
    };
    guiAddress = "10.0.5.10:8384";
  };

  # Auto reset syncthing stuff
  systemd.services.syncthing-reset = {
    serviceConfig.Type = "oneshot";
    script = ''
      "${pkgs.curl}/bin/curl" -X POST -H "X-API-Key: garudalinux" http://10.0.5.10:8384/rest/db/override?folder=${garuda-lib.secrets.syncthing.folders.chaotic-aur}
    '';
  };
  systemd.timers.syncthing-reset = {
    wantedBy = [ "timers.target" ];
    timerConfig.OnCalendar = [ "hourly" ];
  };

  # This disables HTTPS certificates and forced redirects
  garuda-lib.behind_proxy = true;

  # Nginx
  services.nginx = {
    enable = true;
    virtualHosts = {
      "builds.garudalinux.org" = {
        extraConfig = ''
          # Disable index.html
          index fully_disabled.html;
          # Our beautiful autoindex theme
          autoindex on;
          autoindex_exact_size off;
          autoindex_format xml;
          xslt_string_param path $uri;
          xslt_string_param hostname "Chaotic-AUR main node - Temeraire";

          # Security
          add_header X-XSS-Protection          "1; mode=block" always;
          add_header X-Content-Type-Options    "nosniff" always;
          add_header Referrer-Policy           "no-referrer-when-downgrade" always;
          add_header Content-Security-Policy   "default-src 'self' http: https: data: blob: 'unsafe-inline'; frame-ancestors 'self' https://aur.chaotic.cx;" always;
          add_header Permissions-Policy        "interest-cohort=()" always;

          # Locations
          location ~* ^.+\.log {
              default_type text/plain;
          }
          location ~* /repos/(chaotic-aur|garuda)/x86_64/(?!.*(chaotic-aur|garuda)\.(db|files)).+\.tar.* {
              return 301 https://cf-builds.garudalinux.org$request_uri;
              expires 2d;
          }
          location /api/ {
              proxy_pass http://127.0.0.1:8080/api/;
          }
          location /backend/ {
              proxy_pass http://10.0.5.30:3000/;
          }
          location /logs/ {
              proxy_pass http://127.0.0.1:8080/;
              proxy_buffering off;
              proxy_read_timeout 330s;
          }
          location / {
              xslt_string_param path $uri;
              xslt_string_param hostname "Chaotic-AUR main node - Temeraire ğŸ‰";
              xslt_stylesheet "${garuda-lib.xslt_style}";
              location /iso {
                  expires 2d;
                  return 301 https://iso.builds.garudalinux.org$request_uri;
              }
          }
        '';
        http3 = true;
        root = "/srv/http/";
      };
      "cf-builds.garudalinux.org" = {
        extraConfig = ''
          location ~* /repos/(chaotic-aur|garuda)/x86_64/(?!.*(chaotic-aur|garuda)\.(db|files)).+\.tar.* {
              add_header Cache-Control "max-age=150, stale-while-revalidate=150, stale-if-error=86400";
          }
          location ~* /repos/(chaotic-aur|garuda)/x86_64/(chaotic-aur|garuda)\.db.* {
              add_header Cache-Control 'no-cache';
          }
          location /repos/chaotic-aur {
              expires 5m;
              error_page 403 =301 https://builds.garudalinux.org$request_uri;
              error_page 404 =301 https://builds.garudalinux.org$request_uri;
          }
          location /repos/garuda {
              expires 5m;
              error_page 403 =301 https://builds.garudalinux.org$request_uri;
              error_page 404 =301 https://builds.garudalinux.org$request_uri;
          }
          location / {
              expires 2d;
              return 301 https://builds.garudalinux.org$request_uri;
          }
        '';
        http3 = true;
        root = "/srv/http/";
      };
      "iso.builds.garudalinux.org" = {
        extraConfig = ''
          autoindex on;
          autoindex_format xml;
          xslt_string_param path $uri;
          xslt_string_param hostname "Garuda Linux ISO Builds";
        '';
        locations."/".return = "307 https://builds.garudalinux.org";
        locations."/iso" = {
          root = "/srv/http/";
          extraConfig = ''
            xslt_stylesheet "${garuda-lib.xslt_style}";
            if ($symlink_target_rel != "") {
              rewrite ^ https://$server_name/iso/$symlink_target_rel redirect;
            }
            if ($arg_sourceforge) {
              rewrite ^/iso/(.*)$ https://sourceforge.net/projects/garuda-linux/files/$1? permanent;
            }
            if ($arg_r2) {
              set $args "";
              rewrite ^/iso/(.*)$ https://r2.garudalinux.org/iso/$1?r2request permanent;
            }
            break;
          '';
        };
      };
    };
  };

  # Rsyncd
  services.rsyncd = {
    enable = true;
    settings = {
      sections = {
        chaotic = {
          "read only" = "yes";
          comment = "Chaotic-AUR repository";
          exclude = "/chaotic-aur/archive/*** /garuda/archive/***";
          path = "/srv/http/repos/";
        };
        chaotic-minimal = {
          "read only" = "yes";
          comment = "Chaotic-AUR repository minus largest packages";
          exclude = "/chaotic-aur/archive/*** /garuda/archive/*** /chaotic-aur/x86_64/quartus* /chaotic-aur/x86_64/unrealtournament4* /chaotic-aur/x86_64/urbanterror*";
          path = "/srv/http/repos/";
        };
        iso = {
          path = "/srv/http/iso/";
          comment = "ISO downloads";
          "read only" = "yes";
        };
      };
      globalSection = {
        "max connections" = 80;
        "max verbosity" = 3;
        "transfer logging" = true;
        "use chroot" = false;
        gid = "nobody";
        uid = "nobody";
      };
    };
  };

  # Push chaotic to r2 hourly automatically
  services.garuda-rclone.chaotic = {
    src = "/srv/http/repos/";
    dest = "r2:/mirror/repos";
    config = config.sops.secrets."cloudflare/r2_rclone".path;
    args = "--s3-upload-cutoff 5G --s3-chunk-size 4G --fast-list --s3-no-head --s3-no-check-bucket --ignore-checksum --s3-disable-checksum -u --use-server-modtime --delete-during --delete-excluded --include /*/x86_64/*.pkg.tar.zst --include /*/lastupdate --order-by modtime,ascending --stats-log-level NOTICE";
    startAt = "hourly";
  };
  systemd.services.chaotic-rclone-inotify = {
    wantedBy = [ "multi-user.target" ];
    after = [ "network-online.target" ];
    wants = [ "network-online.target" ];
    # Get all file changes, upload pkg.tar.zst. Not more than 5 per 5 seconds queued and only one uploaded at the same time. Queue dropped if uploading takes longer than 15 seconds.
    # This prevents the queue from getting overloaded with nonsense requests if that ever were to happen. The hourly sync should take care of this.
    script = ''
      upload() {
        operation="''${1%%|*}"
        path="''${1#*|}"
        relative="$(realpath --relative-to="." "$path")"
        relative="''${relative#./}"
        destpath="r2:/mirror/$relative"
        if [ "$operation" != "MOVED_FROM" ]; then
        ${pkgs.flock}/bin/flock -w 30 /tmp/chaotic-rclone-inotify.lock \
          ${pkgs.rclone}/bin/rclone copyto "$path" "$destpath" --s3-upload-cutoff 5G --s3-chunk-size 4G --s3-no-head --no-check-dest --s3-no-check-bucket --ignore-checksum --s3-disable-checksum --config "${
            config.sops.secrets."cloudflare/r2_rclone".path
          }" --stats-one-line -v
        else
          ${pkgs.flock}/bin/flock -w 30 /tmp/chaotic-rclone-inotify.lock ${pkgs.rclone}/bin/rclone deletefile "$destpath" --s3-no-head --no-check-dest --s3-no-check-bucket --config "${
            config.sops.secrets."cloudflare/r2_rclone".path
          }" --stats-one-line -v
          (
            ${pkgs.flock}/bin/flock -w 200 -s 200
            ${pkgs.curl}/bin/curl -s -X POST "https://api.cloudflare.com/client/v4/zones/$CF_ZONE_GARUDALINUX_ORG/purge_cache" -H "Authorization: Bearer $CF_CACHE_API_TOKEN" -H "Content-Type:application/json" --data "{\"files\":[\"https://r2.garudalinux.org/''${relative}\"]}"
            sleep 0.5
          ) 200&gt;/tmp/chaotic-rclone-inotify-invalidate.lock
        fi
      }
      export -f upload
      ${pkgs.inotify-tools}/bin/inotifywait -m ./repos/*/x86_64 -e CLOSE_WRITE,MOVED_TO,MOVED_FROM --format "%e|%w%f" | \
        ${pkgs.gawk}/bin/awk '/\.pkg\.tar\.zst$/ { print $0; fflush(); }' | \
        xargs -rP 0 -I % ${pkgs.bash}/bin/bash -c 'upload "%"'
    '';
    serviceConfig = {
      EnvironmentFile = config.sops.secrets."cloudflare/api_keys".path;
      Restart = "always";
      WorkingDirectory = "/srv/http";
    };
  };

  sops.secrets = {
    "cloudflare/api_keys" = { };
    "cloudflare/r2_rclone" = { };
    "compose/chaotic-v4" = { };
    "keypairs/syncthing/cert" = { };
    "keypairs/syncthing/private" = { };
  };

  system.stateVersion = "25.05";
}
</code></pre>
<h3 id="docker-containers-3"><a class="header" href="#docker-containers-3">Docker containers</a></h3>
<pre><code class="language-yaml">services:
  chaotic-builder-1:
    image: registry.gitlab.com/garuda-linux/tools/chaotic-manager/manager:latest
    container_name: chaotic-builder
    command: builder
    deploy:
      restart_policy:
        condition: always
        delay: 60s
    tty: true
    environment:
      BUILDER_CLASS: 9
      BUILDER_HOSTNAME: stormwing-1
      BUILDER_TIMEOUT: 7200
      REDIS_PASSWORD: ${REDIS_PASSWORD:-?err}
      REDIS_SSH_HOST: ${REDIS_SSH_HOST:-?err}
      REDIS_SSH_PORT: ${REDIS_SSH_PORT:-270}
      REDIS_SSH_USER: package-deployer
      SHARED_PATH: /var/garuda/compose-runner/chaotic-v4/shared
      # Override the default database host
      DATABASE_HOST: host.docker.internal
      DATABASE_PORT: 22
    volumes:
      - ./shared:/shared
      - ./sshkey:/app/sshkey
      - /var/run/docker.sock:/var/run/docker.sock
    extra_hosts: ["host.docker.internal:host-gateway"]
  chaotic-builder-2:
    image: registry.gitlab.com/garuda-linux/tools/chaotic-manager/manager:latest
    container_name: chaotic-builder-2
    command: builder
    deploy:
      restart_policy:
        condition: always
        delay: 60s
    tty: true
    environment:
      BUILDER_CLASS: 6
      BUILDER_HOSTNAME: stormwing-2
      BUILDER_TIMEOUT: 7200
      REDIS_PASSWORD: ${REDIS_PASSWORD:-?err}
      REDIS_SSH_HOST: ${REDIS_SSH_HOST:-?err}
      REDIS_SSH_PORT: ${REDIS_SSH_PORT:-270}
      REDIS_SSH_USER: package-deployer
      SHARED_PATH: /var/garuda/compose-runner/chaotic-v4/shared-2
      BUILDER_SRCDEST_CACHE_OVERRIDE: /var/garuda/compose-runner/chaotic-v4/shared/srcdest_cache
      # Override the default database host
      DATABASE_HOST: host.docker.internal
      DATABASE_PORT: 22
    volumes:
      - ./shared-2:/shared
      - ./shared/srcdest_cache:/shared/srcdest_cache
      - ./sshkey:/app/sshkey
      - /var/run/docker.sock:/var/run/docker.sock
    extra_hosts: ["host.docker.internal:host-gateway"]
  chaotic-manager:
    image: registry.gitlab.com/garuda-linux/tools/chaotic-manager/manager:latest
    container_name: chaotic-manager
    command: database --web-port 8080
    deploy:
      restart_policy:
        condition: always
        delay: 60s
    tty: true
    environment:
      # Address published to outside world
      DATABASE_HOST: builds.garudalinux.org
      DATABASE_PORT: 210
      CI_CODE_SKIP: 123
      DATABASE_USER: package-deployer
      GPG_PATH: /var/garuda/compose-runner/chaotic-v4/gnupg
      LANDING_ZONE_PATH: /var/garuda/compose-runner/chaotic-v4/landing-zone
      LOGS_URL: https://builds.garudalinux.org/logs/logs.html
      REDIS_PASSWORD: ${REDIS_PASSWORD:-?err}
      REDIS_SSH_HOST: ${REDIS_SSH_HOST:-?err}
      REDIS_SSH_PORT: ${REDIS_SSH_PORT:-270}
      REDIS_SSH_USER: package-deployer
      REPO_PATH: /srv/http/repos
      TELEGRAM_BOT_TOKEN: ${TELEGRAM_BOT_TOKEN:-?err}
      TELEGRAM_CHAT_ID: ${TELEGRAM_CHAT_ID:-?err}
      PACKAGE_REPOS: &gt;-
        {
            "chaotic-aur": {
                "url": "https://gitlab.com/chaotic-aur/pkgbuilds"
            },
            "garuda": {
                "url": "https://gitlab.com/garuda-linux/pkgbuilds"
            }
        }
      PACKAGE_TARGET_REPOS: &gt;-
        {
            "chaotic-aur": {
                "extra_repos": [
                    {
                        "name": "chaotic-aur",
                        "servers": [
                            "https://builds.garudalinux.org/repos/chaotic-aur/x86_64"
                        ]
                    }
                ],
                "extra_keyrings": [
                    "https://cdn-mirror.chaotic.cx/chaotic-aur/chaotic-keyring.pkg.tar.zst"
                ]
            },
            "garuda": {
                "extra_repos": [
                    {
                        "name": "garuda",
                        "servers": [
                            "https://builds.garudalinux.org/repos/garuda/x86_64"
                        ]
                    },
                    {
                        "name": "chaotic-aur",
                        "servers": [
                            "https://builds.garudalinux.org/repos/chaotic-aur/x86_64"
                        ]
                    }
                ],
                "extra_keyrings": [
                    "https://cdn-mirror.chaotic.cx/chaotic-aur/chaotic-keyring.pkg.tar.zst"
                ]
            }
        }
      PACKAGE_REPOS_NOTIFIERS: &gt;-
        {
            "chaotic-aur": {
                "id": "54867625",
                "token": "${GITLAB_TOKEN_CX:-?err}",
                "check_name": "chaotic-aur: %pkgbase%"
            },
            "garuda": {
                "id": "48461689",
                "token": "${GITLAB_TOKEN:-?err}",
                "check_name": "garuda: %pkgbase%"
            }
        }
    volumes:
      - ./sshkey:/app/sshkey
      - /var/run/docker.sock:/var/run/docker.sock
      - /srv/http/repos:/repo_root
    extra_hosts: ["host.docker.internal:host-gateway"]
    ports: ["127.0.0.1:8080:8080", "127.0.0.1:3030:3030"]
  # Automated container updates
  watchtower:
    image: containrrr/watchtower:latest
    container_name: watchtower
    deploy:
      restart_policy:
        condition: always
        delay: 60s
    command: --cleanup chaotic-builder chaotic-builder-2 chaotic-manager watchtower --interval 3600
    volumes: ["/var/run/docker.sock:/var/run/docker.sock"]
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="firedragon-runner-stormwing"><a class="header" href="#firedragon-runner-stormwing">firedragon-runner (stormwing)</a></h1>
<p>This container is a CI runner for building and testing the Firedragon browser in an isolated environment.
It is separate from the other GitLab runner to ensure only one build runs at a time, while the others can run in parallel.</p>
<h2 id="nix-expression-9"><a class="header" href="#nix-expression-9">Nix expression</a></h2>
<pre><code class="language-nix">{
  sources,
  ...
}:
{
  imports = sources.defaultModules ++ [ ../../modules ];

  garuda.services.compose-runner.firedragon-runner = {
    source = ../../../compose/firedragon-runner;
  };

  system.stateVersion = "25.05";
}
</code></pre>
<h3 id="docker-containers-4"><a class="header" href="#docker-containers-4">Docker containers</a></h3>
<pre><code class="language-yaml">services:
  firedragon-runner:
    image: gitlab/gitlab-runner:alpine
    container_name: firedragon-runner
    volumes:
      - ./firedragon-runner:/etc/gitlab-runner
      - /var/run/docker.sock:/var/run/docker.sock
    restart: 'no'
  firedragon-runner-dind:
    image: gitlab/gitlab-runner:alpine
    container_name: firedragon-runner-dind
    volumes:
      - ./firedragon-runner-dind:/etc/gitlab-runner
      - /var/run/docker.sock:/var/run/docker.sock
    restart: 'no'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="github-runner-stormwing"><a class="header" href="#github-runner-stormwing">github-runner (stormwing)</a></h1>
<p>This container is a GitHub Actions runner for CI/CD tasks related to Garuda Linux projects.</p>
<h2 id="general-5"><a class="header" href="#general-5">General</a></h2>
<p>With this container, we provide a GitHub runner as well as (more recently), a GitLab runner. This container does <strong>not</strong>
have the regular Garuda configurations because it is considered untrusted.
Access needs to happen by running <code>nixos-container root-login</code>
on <code>immortalis</code> (<a href="http://docs.garudalinux.net/hosts/immortalis.html#connecting-to-the-server">click me</a>).</p>
<h2 id="restarting-containers-1"><a class="header" href="#restarting-containers-1">Restarting containers</a></h2>
<p>This can happen via the following command:</p>
<pre><code class="language-bash">sudo systemctl restart docker-compose-gitlab-runner-root
</code></pre>
<p>Watchtower additionally keeps the containers up to date.</p>
<h2 id="nix-expression-10"><a class="header" href="#nix-expression-10">Nix expression</a></h2>
<pre><code class="language-nix">{
  keys,
  ...
}:
{
  # No default modules, untrusted container!
  # imports = sources.defaultModules ++ [
  #   ./garuda/garuda.nix
  # ];

  imports = [
    ../../modules/hardening.nix
    ../../modules/motd.nix
    ../../services/compose-runner/compose-runner.nix
  ];

  # Common Docker configurations
  virtualisation.docker = {
    autoPrune.enable = true;
    autoPrune.flags = [ "-a" ];
  };

  # This container is just for compose stuff
  garuda.services.compose-runner.github-runner = {
    envfile = "/var/.github-runner.env";
    source = ../../../compose/github-runner;
  };
  garuda.services.compose-runner.gitlab-runner = {
    source = ../../../compose/gitlab-runner;
  };

  # Enable SSH
  services.openssh.enable = true;

  # No custom users - only Pedro and root via nixos-container root-login
  users = {
    allowNoPasswordLogin = true;
    mutableUsers = false;
    users.pedrohlc = {
      home = "/home/pedrohlc";
      isNormalUser = true;
      openssh.authorizedKeys.keyFiles = [ keys.pedrohlc ];
    };
  };

  # Make Pedro god here
  nix.settings.trusted-users = [ "pedrohlc" ];
  security.sudo.extraRules = [
    {
      users = [ "pedrohlc" ];
      commands = [
        {
          command = "ALL";
          options = [ "NOPASSWD" ];
        }
      ];
    }
  ];

  # OOM prevention
  systemd.oomd = {
    enable = true; # This is actually the default, anyways...
    enableSystemSlice = true;
    enableUserSlices = true;
  };

  system.stateVersion = "25.05";
}
</code></pre>
<h3 id="docker-containers-github"><a class="header" href="#docker-containers-github">Docker containers (GitHub)</a></h3>
<pre><code class="language-yaml">services:
  github-runner:
    image: myoung34/github-runner:latest
    container_name: github-runner
    privileged: true
    environment:
      ACCESS_TOKEN: ${ACCESS_TOKEN:-?err}
      EPHEMERAL: true
      LABELS: nyxbuilder
      ORG_NAME: chaotic-cx
      RUNNER_NAME: immortalis
      RUNNER_SCOPE: org
      RUNNER_WORKDIR: /var/cache/github-runner/work
    volumes: ['/var/cache/github-runner/work:/var/cache/github-runner/work']
    restart: 'no'
</code></pre>
<h3 id="docker-containers-gitlab"><a class="header" href="#docker-containers-gitlab">Docker containers (GitLab)</a></h3>
<pre><code class="language-yaml">services:
  github-runner:
    image: myoung34/github-runner:latest
    container_name: github-runner
    privileged: true
    environment:
      ACCESS_TOKEN: ${ACCESS_TOKEN:-?err}
      EPHEMERAL: true
      LABELS: nyxbuilder
      ORG_NAME: chaotic-cx
      RUNNER_NAME: immortalis
      RUNNER_SCOPE: org
      RUNNER_WORKDIR: /var/cache/github-runner/work
    volumes: ['/var/cache/github-runner/work:/var/cache/github-runner/work']
    restart: 'no'
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="iso-runner-stormwing"><a class="header" href="#iso-runner-stormwing">iso-runner (stormwing)</a></h1>
<p>This container is a dedicated builder for Garuda Linux ISO images, providing a reproducible build environment.</p>
<h2 id="general-6"><a class="header" href="#general-6">General</a></h2>
<p>This container is used to build our ISO via a Docker container.
It has been used to provide a GitHub runner as well,
though this one got moved to its <a href="hosts/stormwing/github-runner.html">own container</a> recently.</p>
<h2 id="nix-expression-11"><a class="header" href="#nix-expression-11">Nix expression</a></h2>
<pre><code class="language-nix">{
  lib,
  pkgs,
  sources,
  ...
}:
let
  # Simple wrapper to dispatch SSH commands to NixOS
  ci-trigger = pkgs.writeShellScriptBin "ci-trigger" ''
    echo $SSH_ORIGINAL_COMMAND
    _FLAVOUR=$(echo "$SSH_ORIGINAL_COMMAND" | cut -d' ' -f2)
    _KERNEL=$(echo "$SSH_ORIGINAL_COMMAND" | cut -d' ' -f3)

    case "$SSH_ORIGINAL_COMMAND" in
      "ci-trigger buildall")
        echo "Ensuring container and garuda-tools are up-to-date.."
        docker exec buildiso pacman -Syu --noconfirm || exit 1
        echo "Building all ISO Garuda currently offers.."
        docker exec buildiso buildall || exit 1
        ;;
      "ci-trigger "* )
        echo "Ensuring container and garuda-tools are up-to-date.."
        docker exec buildiso pacman -Syu --noconfirm || exit 2
        echo "Building $_FLAVOUR.."
        docker exec buildiso buildiso -i || exit 2
        [[ $_KERNEL != "" ]] &amp;&amp; (docker exec buildiso buildiso -p "$_FLAVOUR" -k "$_KERNEL" || exit 3)
        docker exec buildiso buildiso -p "$_FLAVOUR" || exit 3
        ;;
      *)
        echo "Access only allowed for building purposes!"
        exit 4
    esac
  '';
in
{
  imports = sources.defaultModules ++ [ ../../modules ];

  # Lets build Garuda ISO here, serving is done via
  # Temeraire already
  services = {
    garuda-iso.enable = true;
    nginx.enable = lib.mkForce false;
    rsyncd.enable = lib.mkForce false;
  };

  # Create a locked down user for GitLab CI who can only access our wrapper
  users.users.gitlab = {
    extraGroups = [ "docker" ];
    isNormalUser = true;
    openssh.authorizedKeys.keys = [
      "restrict,pty,command=\"${ci-trigger}/bin/ci-trigger\"  ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIN7W5KtNH5nsjIHBN1zBwEc0BZMhg6HfFurMIJoWf39p"
    ];
  };

  # Let maintainers use buildiso (which is a wrapper around the Docker container)
  # without having to enter a password - our devshell should work just like that
  security.sudo.extraRules = [
    {
      users = [ "frank" ];
      commands = [
        {
          command = "/run/current-system/sw/bin/buildiso";
          options = [ "NOPASSWD" ];
        }
      ];
    }
  ];
  users.users.frank.extraGroups = [ "docker" ];

  system.stateVersion = "25.05";
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="web-front-stormwing"><a class="header" href="#web-front-stormwing">web-front (stormwing)</a></h1>
<p>This container acts as the reverse proxy and web frontend for services running on stormwing, handling HTTPS and routing.</p>
<h2 id="nix-expression-12"><a class="header" href="#nix-expression-12">Nix expression</a></h2>
<p>Configuration for the <code>web-front</code> container on stormwing.</p>
<pre><code class="language-nix">{
  config,
  garuda-lib,
  sources,
  ...
}:
let
  inherit (garuda-lib) allowOnlyCloudflareZerotrust;
  inherit (garuda-lib) generateCloudflaredIngress;
in
rec {
  imports = sources.defaultModules ++ [ ../../modules ];

  services.nginx = {
    enable = true;
    virtualHosts = {
      "builds.garudalinux.org" = {
        addSSL = true;
        extraConfig = ''
          proxy_buffering off;
          ${garuda-lib.setRealIpFromConfig}
          ${garuda-lib.nginxReverseProxySettings}
        '';
        http3 = true;
        locations = {
          "/" = {
            proxyPass = "http://10.0.5.10:80";
          };
          "/logs/" = {
            proxyPass = "http://10.0.5.10:80";
            extraConfig = ''
              proxy_buffering off;
              proxy_read_timeout 330s;
            '';
          };
        };
        quic = true;
        serverAliases = [
          "cf-builds.garudalinux.org"
          "iso.builds.garudalinux.org"
        ];
        useACMEHost = "garudalinux.org";
      };
      "syncthing-build.garudalinux.net" = allowOnlyCloudflareZerotrust {
        extraConfig = ''
          ${garuda-lib.nginxReverseProxySettings}
        '';
        locations = {
          "/" = {
            extraConfig = ''
              proxy_pass http://10.0.5.10:8384;
              proxy_set_header Authorization "Basic ${garuda-lib.secrets.syncthing.esxi-build.credentials.base64}";
            '';
          };
        };
      };
      # Default catch-all for unknown domains
      "_" = {
        addSSL = true;
        extraConfig = ''
          log_not_found off;
          return 404;
        '';
        http3 = true;
        quic = true;
        useACMEHost = "garudalinux.org";
      };
    };
  };

  services.garuda-cloudflared = {
    enable = true;
    ingress = {
      # "example.garudalinux.net" = "http://10.0.5.100:8085";
    } // (generateCloudflaredIngress services.nginx.virtualHosts);
    tunnel-credentials = config.sops.secrets."cloudflare/tunnels/stormwing".path;
  };

  sops.secrets."cloudflare/tunnels/stormwing" = { };

  system.stateVersion = "25.05";
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="repositories"><a class="header" href="#repositories">Repositories</a></h1>
<h2 id="notifications-for-new-events-at-gitlab"><a class="header" href="#notifications-for-new-events-at-gitlab">Notifications for new events at GitLab</a></h2>
<p>Since GitLab has an inbuilt Telegram integration, we can leverage this feature to send notifications to our
dedicated <a href="https://t.me/garuda_updates">Telegram development updates channel</a>.
Posts are sent for all kinds of relevant, but non-confidential events like commits, comments or new merge requests.
Failed pipelines would also be reported here.</p>
<h2 id="backing-up-current-repositories"><a class="header" href="#backing-up-current-repositories">Backing up current repositories</a></h2>
<p>Current repositories may be backed up using <a href="https://github.com/gabrie30/ghorg">ghorg</a>.
To use ghorg, one needs a GitLab access token and the application itself. To generate a fitting token,
follow <a href="https://github.com/gabrie30/ghorg?tab=readme-ov-file#gitlab-setup">these instructions</a>.</p>
<pre><code class="language-sh">ghorg clone --scm gitlab --token "glpat-1234567890" garuda-linux # regular system
nix run nixpkgs#ghorg -- clone --scm gitlab --token "glpat-1234567890" garuda-linux # oneliner on Nix
</code></pre>
<h2 id="archive"><a class="header" href="#archive">Archive</a></h2>
<p>We have an <a href="https://gitlab.com/garuda-linux/archive">archive repository</a> for all files, which are no longer needed for
our current operations.
It contains old PKGBUILDs and settings packages, eg. The state of the ones before we moved to a unified PKGBUILD
repository.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pkgbuilds"><a class="header" href="#pkgbuilds">PKGBUILDs</a></h1>
<h2 id="types-of-pkgbuilds"><a class="header" href="#types-of-pkgbuilds">Types of PKGBUILDs</a></h2>
<p>There are two types of repo packaging-wise:</p>
<ol>
<li>The ones that have all required files in the new pkgbuilds repo and don't reference any external repo in PKGBUILDs <code>source()</code></li>
<li>The ones requiring external repositories as a source. These are listed in the SOURCES files below, packages <em>not</em> listed here are automatically packages of the first category:</li>
</ol>
<p><a href="https://gitlab.com/garuda-linux/pkgbuilds/-/blob/main/SOURCES">This file</a> provides the needed information to check for the new version with the scheme <code>$repourl $pkgbuildPathInPkgbuildsRepo $GitlabProjectId</code></p>
<h2 id="releasing-a-new-version"><a class="header" href="#releasing-a-new-version">Releasing a new version</a></h2>
<p>This means executing the following for doing changes and releasing a new version:</p>
<ol>
<li>Would be modified directly in the new pkgbuilds repo, along with their source.
Versions are bumped in the PKGBUILD itself and deployments need to happen by increasing <code>pkgver</code> + supplying a fitting commit message (append <em>[deploy pkgname ]</em> to it)</li>
<li>In case of modifying these, one would make the changes to the source files repo (not the new PKGBUILDs one).
Then, if a new version should be built, one would push the corresponding tag to that repo (omitting "v", adding v breaks the PKGBUILD!).
That's everything needed in case no packaging changes (adding new dependencies for example) that require changing the PKGBUILD occur.
The <a href="https://gitlab.com/garuda-linux/pkgbuilds/-/pipeline_schedules">half-hourly pipeline</a> of the <a href="https://gitlab.com/garuda-linux/pkgbuilds">PKGBUILD repo</a> then checks for the existence of a new tag.
Once a new one gets detected, the PKGBUILD gets updated and deployment occurs via <code>[deploy *]</code> in the commit message.
<em>If PKGBUILD changes need to be implemented, this would of course indicate doing it as described in 1. This would increase pkgrel only and not the actual version.</em></li>
</ol>
<p>There are currently three bash scripts responsible for CI/CD:</p>
<ul>
<li><a href="https://gitlab.com/garuda-linux/pkgbuilds/-/blob/main/.ci/lint.sh?ref_type=heads">Checking PKGBUILDs/code style</a></li>
<li><a href="https://gitlab.com/garuda-linux/pkgbuilds/-/blob/main/.ci/version-bump.sh?ref_type=heads">Updating the package versions automatically</a></li>
<li><a href="https://gitlab.com/garuda-linux/pkgbuilds/-/blob/main/.ci/what-to-deploy.sh?ref_type=heads">Triggering automated deployments via commit message</a></li>
</ul>
<p>Past pipeline runs may be reviewed by visiting the <a href="https://gitlab.com/garuda-linux/pkgbuilds/-/pipelines">pipelines</a> page.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chaotic-aur-infra-40"><a class="header" href="#chaotic-aur-infra-40">Chaotic-AUR infra 4.0</a></h1>
<p>This is a manual for handling our new Chaotic-AUR infrastructure, which is based on GitLab CI and GitHub Actions.
It is powering the <code>garuda</code> repository, which contains all PKGBUILDs and other necessary files to build packages for
Garuda Linux.
Content has mostly been pasted from the original documentation for visibility.</p>
<h2 id="reasoning"><a class="header" href="#reasoning">Reasoning</a></h2>
<p>Our previous build tools, the so-called <a href="https://github.com/chaotic-aur/toolbox">toolbox</a> was initially created by
@pedrohlc to deal with one issue: having a lot of packages to compile while not having many maintainers for all of the
packages.
Additionally, Chaotic-AUR has quite inhomogeneous builders: servers, personal devices, and one HPC which all need to be
integrated somehow.
The toolbox had a nice approach to this - keeping things as KISS as possible and using Git to distribute package builds
between builders. These would then grab builds according to their activated routines. While this works fairly well, it
had a few problems which we tried to get rid of in the new version.
A few key ideas about this new setup:</p>
<ul>
<li>Since we like working with CI a lot besides it providing great enhancement for automating boring tasks as well as
making the whole process more transparent to the public as well, it was clear CI should be a major part of it.</li>
<li>The system should have a scheduler that distributes build tasks to nodes, which prevents useless build routines and
enables nodes to grab jobs whenever they are queued.</li>
<li>The tools should be available as Docker containers to make them easy to use on other systems than Arch.</li>
<li>All logic besides the scheduler (which is written in TypeScript using BullMQ) should be written in Bash</li>
</ul>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How it works</a></h2>
<p>The new system consists of three integral parts:</p>
<ul>
<li>The CI (which can be both GitLab CI and GitHub Actions!) handles PKGBUILDs, their changes, and figuring out what to
build, utilizing a Chaotic Manager container to schedule packages via the central Redis instance.</li>
<li>The central Redis instance storing information about currently scheduled builds.</li>
<li>The <a href="https://gitlab.com/garuda-linux/tools/chaotic-manager">Chaotic Manager</a> which is used to add new builds to the
queue and execute them via the main manager container. All containers have SSH-tunneled access to the Redis instance,
enabling the build containers to grab new builds whenever they enter the queue.</li>
</ul>
<p>Compared to Infra 3.0, this means we have the following key differences:</p>
<ul>
<li>We no longer have package lists but a repository full of PKGBUILD folders. These PKGBUILDs are getting pulled either
from AUR once a package has been updated or updated manually in case a Git repository and its tags serve as a source.</li>
<li>No more dedicated builders (might change in the future, eg. for heavy builds?) but a common build queue.</li>
<li>Routines are no longer necessary - CI determines and adds packages to the schedule as needed. The only "routine-like"
thing we have is the CI schedule, executing tasks like PKGBUILD or version updates.</li>
<li>The actual logic behind the build process (like <code>interfere.sh</code> or database management) was moved to
the <a href="https://gitlab.com/garuda-linux/tools/chaotic-manager/-/tree/main/builder-container?ref_type=heads">builder container of Chaotic Manager</a> -
this one updates daily/on-commit and gets pulled regularly by the Manager instance.</li>
<li>Live-updating build logs will be available via CI - multiple revisions instead of only the latest.</li>
<li>The interfere repo is no longer needed, instead, package builds can be configured via the <code>.CI</code> folder in their
respective PKGBUILD folders. All known interfere types can be put here (eg. <code>PKGBUILD.append</code> or <code>prepare.sh</code>),
keeping existing interferes working.</li>
<li>The CI's behavior concerning each package can be configured via a <code>config</code> file in the <code>.CI</code> folder: this file stores
information like PKGBUILD source (it can be AUR or something different), PKGBUILD timestamp on AUR, most recent Git
commit as well as settings like whether to push a PKGBUILD change back to AUR.</li>
<li>PKGBUILD changes can now be reviewed in case of major (all changes other than pkgver, hashes, pkgrel) updates - CI
automatically creates a PR containing the changes for human review.</li>
<li>Adding and removing packages is entirely controlled via Git - after adding a new PKGBUILD folder via commit, the
corresponding package will automatically be deployed. Removing it has the opposite effect.</li>
</ul>
<h2 id="workflows-and-information"><a class="header" href="#workflows-and-information">Workflows and information</a></h2>
<h3 id="adding-packages"><a class="header" href="#adding-packages">Adding packages</a></h3>
<p>Adding packages is as easy as creating a new folder named after the <code>$pkgbase</code> of the package. Put the PKGBUILD and all
other required files in here.
Adding AUR packages is therefore as simple as cloning its repo and removing the <code>.git</code> folder.
CI relies on <code>.SRCINFO</code> files to parse most information, therefore, it is important to have them in place and up-to-date
in case of self-managed packages.
Finally, add a <code>.CI</code> folder containing the basic config (<code>CI_PKGBUILD_SOURCE</code> is required in case its external package,
self-managed PKBUILDs don't need it), commit any changes, and push the changes back to the main branch.
Please follow the <a href="https://www.conventionalcommits.org/en/v1.0.0/">conventional commit convention</a> while doing
so (<a href="https://github.com/commitizen/cz-cli">cz-cli</a> can help with that!). This means commits like:</p>
<ul>
<li><code>feat($pkgname): init</code></li>
<li><code>fix($pkgname): fix xyz</code></li>
<li><code>chore($pkgname): update PKGBUILD</code></li>
<li><code>ci(config): update</code></li>
</ul>
<p>This not only helps with having a uniform commit history, it also allows automatic changelog generation.</p>
<h3 id="removing-packages"><a class="header" href="#removing-packages">Removing packages</a></h3>
<p>This can be done by removing the folder containing a package's PKGBUILD. A cleanup job will then automatically remove
any obsolete package via the <code>on-commit</code> pipeline run. This will also consider any split packages that a package might
produce.
Renaming folders does also count as removing packages.</p>
<h3 id="on-commit-pipeline"><a class="header" href="#on-commit-pipeline">On-commit pipeline</a></h3>
<p>Whenever pushing a new commit, the CI pipeline will carry out the following actions:</p>
<ul>
<li>Checking when the last <code>scheduled</code> tag was created. This is used to determine which packages need to be scheduled.</li>
<li>It parses each commit for a <code>[deploy $foldername]</code> string, only accepting valid values derived from the existing
PKGBUILD folders. <code>[deploy all]</code> is a valid parameter as well. Misspelling <code>$pkgname</code> is a fatal error here. Any
issues must be fixed and force-pushed.</li>
<li>Then, the changed files are parsed. This also includes removed packages. Any changed relevant folder content will
cause a package deployment of the corresponding package.</li>
<li>The final action is to build the schedule parameters (handing it over to the scheduled job via artifacts) and remove
all obsolete packages in case an earlier step is detected.</li>
<li>In case all of these actions succeed, the <code>scheduled</code> tag gets updated, so we can refer to it on a later pipeline run.</li>
</ul>
<h3 id="on-schedule-pipeline"><a class="header" href="#on-schedule-pipeline">On-schedule pipeline</a></h3>
<h4 id="half-hourly"><a class="header" href="#half-hourly">Half-hourly</a></h4>
<p>Every half an hour, the on-schedule pipeline will carry out a few tasks:</p>
<ul>
<li>Updating the CI template from the template repository (in case this is enabled via <code>.ci/config</code>)</li>
<li>Check if the scheduled tag does not exist or scheduled does not point to HEAD (in this case abort mission!)</li>
<li>Check whether the .state worktree containing the state of the packages exists, if it does, it sets it up. Otherwise,
it re-creates it from scratch (e.g., on force push)</li>
<li>Check whether the last commit is automated (containing "chore(packages): update packages [skip ci]"), if yes, the
commit resulting from the schedule will overwrite it to keep the commit history clean.</li>
<li>Collect AUR timestamps of packages to determine whether a PKGBUILD changed</li>
<li>Loop through each valid package and carry out the following actions:
<ul>
<li>Read the <code>.CI/config</code> file to gain information about the package configuration (e.g., whether to manage the AUR
repository, the source of the PKGBUILD, etc.)</li>
<li>Update PKGBUILD in the following cases:
<ul>
<li>CI_PKGBUILD_SOURCE is set to <code>gitlab</code>: Updates the PKGBUILD from the GitLab repository tags</li>
<li>CI_PKGBUILD_SOURCE is set to <code>aur</code>: Updates the PKGBUILD from the AUR repository, pulling in the git repo and
replacing the existing files with the new ones.
If the AUR timestamp could not be collected earlier, the package update gets skipped.</li>
<li>CI_PKGBUILD_SOURCE is not set to <code>gitlab</code> or <code>aur</code>:
tries to update the PKGBUILD by pulling the repository specified in CI_PKGBUILD_SOURCE.
In case cloning was not successful after 2 tries, the update process gets skipped.</li>
</ul>
</li>
<li>In case CI_GIT_COMMIT is set in the packages configuration variables, the latest commit of the git URL set in
the <code>source</code> section of the PKGBUILD is
updated. If it differs, schedule a build.</li>
<li>In case a custom hook exists (<code>.CI/update.sh</code> inside the package directory), it gets executed - this can be used
for
updating PKGBUILDs with a custom script.</li>
<li>Writing needed variables back to <code>.CI/config</code> (eg. Git hash)</li>
</ul>
</li>
<li>Either update the PKGBUILD silently in case of minor changes, create a PR for review in case of major updates (and
only if <code>CI_HUMAN_REVIEW</code> is true)
<ul>
<li>Updates are only considered if diff actually reports changes between current PKGBUILD folder and AUR PKGBUILD repo</li>
<li>Any change made to the source files is detected, this however does <em>not</em> detect malicious changes in the upstream
project source that the package builds</li>
</ul>
</li>
<li>The state worktree gets updated with new information</li>
<li>Schedule parameters are getting built and handed over to the scheduled job via artifact</li>
<li>Obsolete branches (eg. merged review PRs) are getting pruned</li>
<li>The scheduled tag gets updated again</li>
</ul>
<h4 id="daily"><a class="header" href="#daily">Daily</a></h4>
<p>A daily pipeline schedule has been added for specific packages which generate their <code>pkgver</code> dynamically.
To make use of it, set <code>CI_ON_TRIGGER=daily</code> inside the <code>.CI/config</code> file of the package.</p>
<h3 id="manual-scheduling"><a class="header" href="#manual-scheduling">Manual scheduling</a></h3>
<h4 id="scheduling-packages-without-git-commits"><a class="header" href="#scheduling-packages-without-git-commits">Scheduling packages without git commits</a></h4>
<p>Packages can be added to the schedule manually by going to
the <a href="https://gitlab.com/chaotic-aur/pkgbuilds/-/pipelines">pipeline runs</a> page, selecting "Run pipeline" and
adding <code>PACKAGES</code> as a variable with the package names as its value. The pipeline will then pick up the packages and
schedule them.
<code>PACKAGES</code> can also be set to <code>all</code> to schedule all packages. In case one or many packages are getting scheduled, it
needs to follow the format <code>pkgname1:pkgname2:pkgname3</code>.</p>
<h4 id="running-scheduled-pipelines-on-demand"><a class="header" href="#running-scheduled-pipelines-on-demand">Running scheduled pipelines on-demand</a></h4>
<p>This can be done by going to the <a href="https://gitlab.com/chaotic-aur/pkgbuilds/-/pipeline_schedules">pipeline runs</a> page,
selecting "Run pipeline" (the play symbol). A link to the pipeline page will be provided, where the pipeline logs can be
obtained.</p>
<h3 id="adding-interfere"><a class="header" href="#adding-interfere">Adding interfere</a></h3>
<p>Put the required interfere file in the <code>.CI</code> folder of a PKGBUILD folder:</p>
<ul>
<li>
<p><code>prepare</code>: A script that is executed after the building chroot has been set up. It can be used to source
environment variables or modify other things before compilation starts.</p>
<ul>
<li>If something needs to be set up before the actual compilation process, commands can be pushed by inserting
eg. <code>$CAUR_PUSH 'source /etc/profile'</code>. Likewise, package conflicts can be solved, eg. as
follows: <code>$CAUR_PUSH 'yes | pacman -S nftables'</code> (single quotes are important because we want the variables/pipes
to
evaluate in the guest's runtime and not while interfering)</li>
</ul>
</li>
<li>
<p><code>interfere.patch</code>: a patch file that can be used to fix multiple files when many changes are
required. All changes need to be added to this file.</p>
</li>
<li>
<p><code>PKGBUILD.prepend</code>: contents of this file are added to the beginning of PKGBUILD.
This can be used to set configuration variables.</p>
</li>
<li>
<p><code>PKGBUILD.append</code>: contents of this file are added to the end of PKGBUILD.
This can be used for all kinds of fixes.
To fix <code>build()</code>, include the replacement in this file.
To add an item to an array, <code>makedepend+=(somepackage)</code>.</p>
<p>To skip build, <code>return $CI_CODE_SKIP</code>. This can be used to conditionally skip builds based on upstream check-in
results. See <code>kicad-git</code> for a GitLab example. See <code>openvino-git</code> and <code>scummvm-git</code> for GitHub examples.</p>
</li>
<li>
<p><code>on-failure.sh</code>: A script that is executed if the build fails.</p>
</li>
<li>
<p><code>on-success.sh</code>: A script that is executed if the build succeeds.</p>
</li>
</ul>
<h3 id="bumping-pkgrel"><a class="header" href="#bumping-pkgrel">Bumping pkgrel</a></h3>
<p>This is now carried out by adding the required variable <code>CI_PACKAGE_BUMP</code> to <code>.CI/config</code>. See below for more
information.</p>
<h3 id="dependency-trees"><a class="header" href="#dependency-trees">Dependency trees</a></h3>
<p>The CI builds dependency trees automatically. They are passed to the Chaotic manager as a CI artifact and read whenever
a schedule command is being executed.
No manual intervention is needed.</p>
<h3 id="ciconfig"><a class="header" href="#ciconfig">.CI/config</a></h3>
<p>The <code>.CI/config</code> file inside each package directory contains additional flags to control the pipelines and build
processes with.</p>
<ul>
<li><code>CI_MANAGE_AUR</code>: By setting this variable to <code>true</code>, the CI will update the corresponding AUR repository at the end of
a
pipeline run if changes occur (omitting CI-related files)</li>
<li><code>CI_PACKAGE_BUMP</code>: Controls package bumps for all packages which don't have <code>CI_MANAGE_AUR</code> set to <code>true</code>. The format
this needs
to follow is either <code>1:1.2.3-1/1</code> (full current version and bump count after the slash) or <code>1.2.3</code> (full current
package version,
resolves to bump count <code>1</code>).</li>
<li><code>CI_PKGBUILD_SOURCE</code>: Sets the source for all PKGBUILD-related files, used for pulling updated files from remote
repositories.
Valid values as of now are:
<ul>
<li><code>gitlab</code>: Pulls the PKGBUILD from the GitLab repository tags. It needs to follow the format <code>gitlab:$PROJECT_ID</code>.
The ID can be obtained by browsing the repository settings general section.</li>
<li><code>aur</code>: Pulls the PKGBUILD from the AUR repository, pulling in the git repo and replacing the existing files with
the
new ones.</li>
</ul>
</li>
<li><code>CI_ON_TRIGGER</code>: Can be provided in case a special schedule trigger should schedule the corresponding package. This
can be used to schedule packages daily, by setting the value to <code>daily</code>.
Since this checks whether "$TRIGGER == $CI_ON_TRIGGER", any custom schedule can be created using pipeline schedules
and setting <code>TRIGGER</code> to <code>midnight</code>, adding a fitting schedule and setting <code>CI_ON_TRIGGER</code> for any affected package
to <code>midnight</code>.
Packages having this variable set will <strong>not</strong> be scheduled via the regular on-schedule pipeline, hence this one can
also be used to prevent wasting builder resources, e.g. useful for huge <code>-git</code> packages with a lot of commit activity,
like <code>llvm-git</code>.</li>
<li><code>CI_REBUILD_TRIGGERS</code>: Add packages known to be causing rebuilds to this variable. A list of repositories to track
package versions for is provided via the repositories' <code>CI_LIB_DB</code> parameter. Each package version is hashed and
dumped to <code>.ci/lib.state</code>. Each scheduled pipeline run compares versions by checking hash mismatches and will bump
each each affected package via <code>CI_PACKAGE_BUMP</code>.</li>
<li><code>BUILDER_CACHE_SOURCES</code>: Can be set to <code>true</code> in case the sources should be cached between builds. This can be useful
in case of slow sources or sources that are not available all the time. Sources will be cleared automatically after 1
month, which is important in case packages are getting removed or the source changes.</li>
</ul>
<h3 id="known-state-variables"><a class="header" href="#known-state-variables">Known state variables</a></h3>
<p>State will be kept in the .state worktree. It can be viewed by browsing the <code>state</code> branch of a PKGBUILD repository.
Each package will have their own file named after the package name. The following variables are known to be stored:</p>
<ul>
<li><code>CI_GIT_COMMIT</code>: Used by CI to determine whether the latest commit changed. Used by <code>fetch-gitsrc</code> to schedule new
builds. Needs to be provided in case the package should be treated as a git package. CI will automatically update the
latest available commit of the git URL set in the <code>source</code> section of the PKGBUILD. If it differs, schedule a
build. -<code>CI_PKGBUILD_TIMESTAMP</code>: The last modified date of the PKGBUILD on AUR. This is used to determine whether the
PKGBUILD has changed. If it differs, schedule a build. Will be maintained automatically.</li>
</ul>
<h3 id="ci-pipeline-variables"><a class="header" href="#ci-pipeline-variables">CI pipeline variables</a></h3>
<p>These variables can be set in in the repo root's<code>.ci/config</code> to configure the pipeline behavior globally as follows:</p>
<ul>
<li><code>BUILD_REPO</code>: The target repository that will be the deploy target</li>
<li><code>GIT_AUTHOR_EMAIL</code>: The email of the user that will be used to commit</li>
<li><code>GIT_AUTHOR_NAME</code>: The name of the user that will be used to commit</li>
<li><code>REDIS_SSH_HOST</code>: The Redis SSH host for the target repository (for SSH tunneling)</li>
<li><code>REDIS_SSH_PORT</code>: The Redis SSH port for the target repository (for SSH tunneling)</li>
<li><code>REDIS_SSH_USER</code>: The Redis SSH user for the target repository (for SSH tunneling)</li>
<li><code>REDIS_PORT</code>: The redis port for the target repository (inside the SSH tunnel)</li>
<li><code>REPO_NAME</code>: The name that this repository is referred to in Chaotic Manager's config</li>
<li><code>CI_HUMAN_REVIEW</code>: If merge/pull requests should be created for non pkgver changes</li>
<li><code>CI_MANAGE_AUR</code>: This should be set to true in case select AUR repositories should be managed by CI</li>
<li><code>CI_OVERWRITE_COMMITS</code>: If we should overwrite existing automated commits to reduce the size of the git history</li>
<li><code>CI_CLONE_DELAY</code>: How long to wait between every executed git clone command for rate limits</li>
<li><code>CI_AUR_PROXY</code>: Proxy to use for AUR requests</li>
</ul>
<h3 id="managing-aur-packages"><a class="header" href="#managing-aur-packages">Managing AUR packages</a></h3>
<p>AUR packages can also be managed via this repository in an automated way using <code>.CI_CONFIG</code>.
This means that after each scheduled and on-commit pipeline, the AUR repository will be updated to reflect the changes
done to the PKGBUILD folder's files.
Files not relevant to AUR maintenance (e.g. <code>.CI</code> folders) will be omitted.
The commit message reflects the fact that the commit was created by a CI pipeline
and contains the link to the source repository's commit history and the pipeline run which triggered the update commit.</p>
<h3 id="updating-the-cis-scripts"><a class="header" href="#updating-the-cis-scripts">Updating the CI's scripts</a></h3>
<p>This is done automatically via the CI pipeline. Once changes have been detected on the template repository, all files
will be updated to the current version.</p>
<h3 id="issues-and-pipeline-failures"><a class="header" href="#issues-and-pipeline-failures">Issues and pipeline failures</a></h3>
<h4 id="last-on-commit-pipeline-failed"><a class="header" href="#last-on-commit-pipeline-failed">Last on-commit pipeline failed</a></h4>
<p>This can happen in case of a few reasons, for example having provided an invalid package name. This causes
the <code>scheduled</code> tag to not be updated.
In this case, the on-schedule pipeline will not be able to run.
The last on-commit pipeline needs to be fixed before the on-schedule pipeline can run again.
Build failures however are not accounted as the <code>scheduled</code> tag would be updated already as soon as the scheduling
parameters were generated.
Force pushing a fixed up commit is actively encouraged in such a case, as pushing another commit will cause the CI to
evaluate the previous commits it missed, leading to noticing the same issue again and bailing out instead of silently
continuing.
This has been a design decision to prevent failures from being overlooked.</p>
<h4 id="resetting-the-build-queue"><a class="header" href="#resetting-the-build-queue">Resetting the build queue</a></h4>
<p>There might be rare cases in which a reset of the build queue is needed. This can be done by shutting down the central
Redis instance, removing its dump, and restarting its service.</p>
<h3 id="deploying-to-different-repos-using-the-same-infrastructure"><a class="header" href="#deploying-to-different-repos-using-the-same-infrastructure">Deploying to different repos using the same infrastructure</a></h3>
<p>This is now an officially supported use case. The only thing required is to use another repository that is going to
store PKGBUILDs and execute CI pipelines.
The environment variables passed to the main Chaotic Manager instance control which repositories are available to use
while scheduling packages. See below for more information.</p>
<h2 id="chaotic-manager"><a class="header" href="#chaotic-manager">Chaotic Manager</a></h2>
<p>This tool is distributed as Docker containers and consists of a pair of manager and builder instances.</p>
<ul>
<li>Manager: <code>registry.gitlab.com/garuda-linux/tools/chaotic-manager/manager</code>
<ul>
<li>Manages builds by adding them to the schedule, used e.g. in the schedule step of CI pipelines</li>
<li>Provides log management and the live-updating logs</li>
<li>Manages any existing builds by spinning up build containers, picking from the available BullMQ builder / database
queues</li>
<li>Picks up already built package archives from the landing zone (builder containers push finished build archives
here)
to add them to the database of the target repository</li>
</ul>
</li>
<li>Builder: <code>registry.gitlab.com/garuda-linux/tools/chaotic-manager/builder</code>
<ul>
<li>This one contains the actual logic behind package builds (
seen <a href="https://gitlab.com/garuda-linux/tools/chaotic-manager/-/tree/main/builder-container?ref_type=heads">here</a>)
known from infra 3.0 like <code>interfere.sh</code>, <code>database.sh</code> etc.</li>
<li>This one is used by an executing manager instance to run the build processes with. It runs jobs present in the
builder BullMQ queue.</li>
</ul>
</li>
</ul>
<p>An example of a valid config can be found in
the <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/docker-compose/chaotic-v4/docker-compose.yml?ref_type=heads#L38">Garuda Linux infrastructure repository</a>.
The following variables can be set in Docker environment:</p>
<ul>
<li><code>DATABASE_HOST</code>: database address published to the outside world</li>
<li><code>DATABASE_PORT</code>: the port behind packages can be deployed to</li>
<li><code>DATABASE_USER</code>: the user to use to deploy packages</li>
<li><code>GPG_PATH</code>: where the <code>.gnupg</code> folder resides (holding the key for signing packages)</li>
<li><code>LANDING_ZONE_PATH</code>: where the landing zone is (here packages get deployed and later picked up by the database job
before getting into the final repository)</li>
<li><code>LOGS_URL</code>: the URL that serves the logfiles (we get sent here when clicking CI's external stages)</li>
<li><code>PACKAGE_REPOS_NOTIFIERS</code>: needed configs to provide external CI stages for GitLab CI/GitHub Actions</li>
<li><code>PACKAGE_REPOS</code>: the source repositories containing PKGBUILD folders</li>
<li><code>PACKAGE_TARGET_REPOS</code>: the repository a package is getting deployed to (including its URL and extra keyrings/repos
needed)</li>
<li><code>REDIS_PASSWORD</code>: password for accessing the Redis instance</li>
<li><code>REDIS_SSH_HOST</code>: where to access the Redis instance</li>
<li><code>REDIS_SSH_USER</code>: the user who can access the Redis instance</li>
<li><code>REPO_PATH</code>: the path where the final package deployment happens</li>
<li><code>TELEGRAM_BOT_TOKEN</code>: the token for the Telegram bot, used for notifications</li>
<li><code>TELEGRAM_CHAT_ID</code>: the chat ID for the Telegram bot to send deployment or failure notifications to</li>
</ul>
<p>The following variables are only relevant for builder instances:</p>
<ul>
<li><code>BUILDER_HOSTNAME</code>: the hostname of the builder will be displayed in package logs to determine which builder built a
package</li>
<li><code>BUILDER_TIMEOUT</code>: the timeout for a package build, 3600 seconds by default. Should be increased on slow builders</li>
</ul>
<h3 id="setting-up"><a class="header" href="#setting-up">Setting up</a></h3>
<h4 id="requirements"><a class="header" href="#requirements">Requirements</a></h4>
<p>The base requirements for running this kind of setup are as follows:</p>
<ul>
<li>
<p>Docker/Podman must be installed in the target system, docker-/podman-compose are good to have as well. We will use it
in our following examples.</p>
</li>
<li>
<p>A Redis instance must be available, e.g. installed on the host system or added to Â´docker-compose.yml`:</p>
<pre><code class="language-yml">chaotic-redis:
  image: redis:alpine
  container_name: chaotic-redis
  restart: always
  ports:
    - "6379:6379"
  command: redis-server --save 60 1 --loglevel warning --requirepass verysecurepassword
  volumes:
    - ./redis-data:/data
</code></pre>
<p>The following examples assume Redis to be installed on the host system. In case it is added to <code>docker-compose.yml</code>,
replace any occurances of <code>host.docker.internal</code> with <code>chaotic-redis</code>.</p>
</li>
<li>
<p>A reverse proxy like Nginx to expose the Chaotic Manager's logs to the public in a secure way should be available.
E.g., using Nginx it is sufficient to <code>proxy_pass</code> the specified <code>--web-port</code> value to the Manager instance container.
Additionally, the following settings might be usedful:</p>
<pre><code class="language-Ç¹ginx">proxy_buffering off;
proxy_read_timeout 330s;
</code></pre>
</li>
</ul>
<h4 id="repository-setup"><a class="header" href="#repository-setup">Repository setup</a></h4>
<p>The repository needs to be derived from
the <a href="https://github.com/chaotic-cx/chaotic-repository-template">repository template</a>. On GitHub,
the <a href="https://github.com/new?template_name=chaotic-repository-template&amp;template_owner=chaotic-cx">"Use this template"</a>
feature may be used.
Afterward, customize the <code>.ci/config</code> file according to your needs. This file contains global configuration for pipeline
runs and CI behaviour.
The following options exist as of today:</p>
<ul>
<li><code>BUILD_REPO</code>: The target repository that will be the deploy target</li>
<li><code>GIT_AUTHOR_EMAIL</code>: The email of the user that will be used to commit</li>
<li><code>GIT_AUTHOR_NAME</code>: The name of the user that will be used to commit</li>
<li><code>REDIS_SSH_HOST</code>: The redis host for the target repository</li>
<li><code>REDIS_SSH_PORT</code>: The redis port for the target repository</li>
<li><code>REDIS_SSH_USER</code>: The redis user for the target repository</li>
<li><code>REDIS_PORT</code>: The redis port for the target repository</li>
<li><code>REPO_NAME</code>: The name that this repository is referred to in chaotic-manager's config</li>
<li><code>CI_HUMAN_REVIEW</code>: Whether merge/pull requests should be created for non pkgver changes (false/true)</li>
<li><code>CI_MANAGE_AUR</code>: This should be set to true in case select AUR repositories should be managed by CI. A fitting SSH key
needs to be deployed as AUR_KEY via secret CI variable.</li>
<li><code>CI_OVERWRITE_COMMITS</code>: Whether we should overwrite existing automated commits to reduce the size of the git history (
false/true)</li>
<li><code>CI_CLONE_DELAY</code>: How long to wait between every executed git clone command for ratelimits (false/true)</li>
<li><code>CI_AUR_PROXY</code>: Proxy to use for AUR requests</li>
<li><code>CI_LIB_DB</code>: Archlinux / Chaotic-AUR repo mirror to use for pulling db files from, in the following
format: <code>https://arch.mirror.constant.com/core/os/x86_64/core.db https://arch.mirror.constant.com/community/os/x86_64/community.db ...</code></li>
</ul>
<h4 id="exemplary-manager-instance-setup"><a class="header" href="#exemplary-manager-instance-setup">Exemplary manager instance setup</a></h4>
<pre><code class="language-yaml">chaotic-manager:
  image: registry.gitlab.com/garuda-linux/tools/chaotic-manager/manager:latest
  container_name: chaotic-manager
  command: database --web-port 8080
  environment:
    DATABASE_HOST: sub.domain.tld
    DATABASE_PORT: 22
    DATABASE_USER: package-deployer
    GPG_PATH: /var/awesome-repo/gnupg
    LANDING_ZONE_PATH: /var/awesome-repo/landing-zone
    LOGS_URL: https://sub.domain.tld/logs/logs.html
    REDIS_PASSWORD: verysecurepassword
    REDIS_SSH_HOST: host.docker.internal
    REDIS_SSH_USER: package-deployer
    REPO_PATH: /srv/http/repos
    TELEGRAM_BOT_TOKEN: 1234567890
    TELEGRAM_CHAT_ID: 0987654321
    PACKAGE_REPOS: &gt;-
      {
          "awesome-repo": {
              "url": "https://gitlab.com/awesome-repo/pkgbuilds"
          }
      }
    PACKAGE_TARGET_REPOS: &gt;-
      {
          "awesome-repo": {
              "extra_repos": [
                  {
                      "name": "awesome-repo",
                      "servers": [
                          "https://sub.domain.tld/awesome-repo/x86_64"
                      ]
                  }
              ],
              "extra_keyrings": [
                  "https://sub.domain.tld/awesome-repo/awesome-keyring.pkg.tar.zst"
              ]
          }
      }
    PACKAGE_REPOS_NOTIFIERS: &gt;-
      {
          "awesome-repo": {
              "id": "123456",
              "token": "GITLABAPITOKENWITHAPIACCESS",
              "check_name": "awesome-repo: %pkgbase%"
          }
      }
  volumes:
    - ./sshkey:/app/sshkey
    - /var/run/docker.sock:/var/run/docker.sock
    - /srv/http/repos:/repo_root
  extra_hosts:
    - "host.docker.internal:host-gateway"
  ports: [8080:8080]
</code></pre>
<p>The following things are to note:</p>
<ul>
<li><code>PACKAGE_REPOS</code>, <code>PACKAGE_TARGET_REPOS</code> and <code>PACKAGE_REPOS_NOTIFIERS</code> are JSON values and need to be valid JSON in
order to be processed.</li>
<li>The above setup assumes the docker-compose.yml to be present in <code>var/awesome-repo</code>.</li>
<li><code>LOGS_URL</code> needs to match the address which the reverse proxy publishes <code>--web-port 8080</code> to the outside world.</li>
<li><code>REPO_PATH</code> is the path of the repository <em>on the Docker host</em>. The same path must be mapped to <code>/repo_root</code> inside
the container via volumes.</li>
<li><code>/app/sshkey</code> is assumed to be the private SSH key</li>
<li>Ports don't have to explicitly exposed if using an Nginx Docker container, in this setup however, our Nginx and Redis
instance are present on the host system.</li>
<li><code>PACKAGE_REPOS_NOTIFIERS</code> and <code>TELEGRAM_*</code> variables are optional but provide additional functionality of they are
set.</li>
<li><code>DATABASE_HOST</code> refers to the address published to the outside world, e.g. for additional builders an other servers.</li>
</ul>
<h4 id="examplary-builder-instance-setup"><a class="header" href="#examplary-builder-instance-setup">Examplary builder instance setup</a></h4>
<pre><code class="language-yaml">---
services:
  chaotic-builder:
    image: registry.gitlab.com/garuda-linux/tools/chaotic-manager/manager:latest
    container_name: chaotic-builder
    command: builder
    environment:
      BUILDER_TIMEOUT: 7200
      BUILDER_HOSTNAME: awesome-builder
      REDIS_PASSWORD: verysecurepassword
      REDIS_SSH_HOST: host.docker.internal
      REDIS_SSH_USER: package-deployer
      SHARED_PATH: /var/chaotic/shared
      DATABASE_HOST: host.docker.internal
      DATABASE_PORT: 22
    volumes:
      - ./shared:/shared
      - ./sshkey:/app/sshkey
      - /var/run/docker.sock:/var/run/docker.sock
    extra_hosts:
      - "host.docker.internal:host-gateway"
</code></pre>
<p>The following things are to note:</p>
<ul>
<li>The above setup assumes the docker-compose.yml to be present in <code>var/awesome-repo</code>.</li>
<li>The <code>SHARED_PATH</code> variable needs to match the directory mapped to <code>/shared</code> inside the container.</li>
<li><code>DATABASE_HOST</code> can in theory be any other host, but can be set to <code>host.docker.internal</code> in case the Redis instance
runs on the Docker host.</li>
<li>The Docker socket needs to be mounted as the builder instance will use it to spin up build container instances.</li>
<li><code>/app/sshkey</code> is assumed to be the private SSH key used for pushing finished package builds to the manager instance's
landing zone.</li>
<li><code>BUILDER_TIMEOUT</code> only needs to be set in case it is a slower build machine which does not finish heaver tasks in one
hour.</li>
<li>As many instances of this container can be added the setup as wanted. Each of them will allow processing another build
at the same time in total.</li>
</ul>
<h3 id="features"><a class="header" href="#features">Features</a></h3>
<h4 id="chaotic-manager-container-commands"><a class="header" href="#chaotic-manager-container-commands">Chaotic-Manager container commands</a></h4>
<ul>
<li><code>schedule</code>: Schedules a new package build by adding it to the Redis instance. It takes the following arguments:
<ul>
<li><code>arch</code>: The architecture to build the package for</li>
<li><code>target-repo</code>: The target repository to deploy the package to, referring to the <code>PACKAGE_TARGET_REPOS</code> variable
set
in the Docker environment variables.</li>
<li><code>source-repo</code>: The source repository to pull the package from, referring to the <code>PACKAGE_REPOS</code> variable set in
the
Docker environment variables.</li>
<li><code>commit</code>: The commit hash which the schedule call originates from</li>
<li><code>deptree</code>: the dependency tree built by the CI pipeline. This parameter is omitted in CI pipelines and instead
passed as file, reading from <code>/.ci/deptree.txt</code>. The reason is that the parameter will be to huge to be processed
by
the shell if 100+ packages are
scheduled at the same time.
It contains information about the build order of packages and their dependencies.</li>
</ul>
</li>
<li><code>builder</code>: Starts the build job, which then grabs any available build jobs from the build queue.</li>
<li><code>auto-repo-remove</code>: Removes obsolete packages from the target repository. Further parameters must include the pkgbases
to be removed.</li>
<li><code>database</code>: Starts the manager instance, which is responsible for managing queues, logs and database jobs. It
additionally spins up a web server to serve logs from if <code>--web-port</code> is passed as argument.</li>
<li><code>web</code>: Starts the web server to serve logs from. This is only needed in case the manager instance does not run the web
server.</li>
</ul>
<h4 id="web-server"><a class="header" href="#web-server">Web server</a></h4>
<p>Available routes on the port set up be the <code>--web-port</code> parameter are as follows:</p>
<ul>
<li><code>/api/logs/:id/:timestamp</code>: Returns the log file of a package build. The <code>id</code> is the package's ID, the <code>timestamp</code> is
the timestamp of the build.</li>
<li><code>/api/logs/:id</code>: Returns the latest log file of a package build. The <code>id</code> is the package's ID.</li>
<li><code>/api/queue/stats</code>: Returns a JSON object containing the current queue stats.</li>
<li><code>/api/queue/packages</code>: Returns a JSON object containing information the currently scheduled packages.</li>
<li><code>/metrics</code>: Returns collected Prometheus metrics.</li>
</ul>
<h4 id="notifications"><a class="header" href="#notifications">Notifications</a></h4>
<p>Notifications about relevant events can be sent to a Telegram channel or chat via a Bot.
This requires a valid Bot token and the Chat ID to be set.
The following events are currently supported:</p>
<ul>
<li>
<p>Build failures: additionally contains links to full build logs and the originating commit.</p>
<pre><code class="language-text">ğŸš¨ Failed deploying to awesome-repo:
&gt; freecad-git - logs- commit
</code></pre>
</li>
<li>
<p>Build success:</p>
<pre><code class="language-text">ğŸ“£ New deployment to awesome-repo:
&gt; freecad-git
</code></pre>
</li>
<li>
<p>Timed out build: Contains links to full build logs and the originating commit.</p>
<pre><code class="language-text">â³ Build for awesome-repo failed due to a timeout:
&gt; freecad-git - logs - commit
</code></pre>
</li>
<li>
<p>Successful repo-remove jobs:</p>
<pre><code class="language-text">âœ… Repo-remove job for awesome-repo finished successfully
</code></pre>
</li>
<li>
<p>Failed repo-remove jobs:</p>
<pre><code class="language-text">ğŸš« Repo-remove job for awesome-repo failed
</code></pre>
</li>
</ul>
<h4 id="build-order"><a class="header" href="#build-order">Build order</a></h4>
<p>The build order is determined by the dependency tree built by the CI pipeline.
This tree is passed to the manager and is then used to determine the correct build order automatically.
No further intervention is needed to achieve this.</p>
<h4 id="live-updating-logs"><a class="header" href="#live-updating-logs">Live-updating logs</a></h4>
<p>Logs are live-updating and can be viewed in real-time via the web server.
In case GitLab is used and <code>PACKAGE_REPOS_NOTIFIERS</code> is set,
an external CI stage will be created for every package scheduled during the CI run, linking to the log.</p>
<h4 id="prometheus-metrics"><a class="header" href="#prometheus-metrics">Prometheus metrics</a></h4>
<p>Prometheus metrics are available at the <code>/metrics</code> endpoint of the web server.
Currently, we collect default <code>prom-client</code> metrics as well as statistics about total event count of each build status
(failed, successful, already-built, timed out) as well as metrics about overall build times.
These can be collected via a Prometheus instance and then be visualized using Grafana.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="discourse"><a class="header" href="#discourse">Discourse</a></h1>
<p>Discourse is the application we use to host our forum.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="documentation"><a class="header" href="#documentation">Documentation</a></h1>
<h2 id="building-it"><a class="header" href="#building-it">Building it</a></h2>
<p>The documentation is created by using <a href="https://rust-lang.github.io/mdBook/index.html">mdBook</a>, which generates Markdown
files and generates HTML pages for them. The documentation can be build by running:</p>
<pre><code class="language-sh">nix build .#docs # plain simple
</code></pre>
<p>The files can then be found at <code>./result/</code>, which is a symlink to the corresponding path in <code>/nix/store</code>.
mdBook is also able to automatically serve the current content and update it automatically whenever a change is
detected.
This makes testing and previewing content easy.</p>
<pre><code class="language-sh">mdbook serve --open # the latter additionally opens the website in a browser
</code></pre>
<h2 id="useful-information"><a class="header" href="#useful-information">Useful information</a></h2>
<h3 id="mdbook-syntax"><a class="header" href="#mdbook-syntax">mdBook syntax</a></h3>
<p>While the general syntax for writing Markdown applies to mdBook, it has several extensions beyond the standard
CommonMark specification.</p>
<ul>
<li><a href="https://rust-lang.github.io/mdBook/format/markdown.html">Markdown syntax</a></li>
<li><a href="https://rust-lang.github.io/mdBook/format/mdbook.html">mdBook specific features</a></li>
</ul>
<p>Especially importing code blocks as Markdown is really handy to keep content always up-to-date and helps providing a
full text searchable code documentation.</p>
<h3 id="updating-mdbook-plugins-contents"><a class="header" href="#updating-mdbook-plugins-contents">Updating mdBook plugins contents</a></h3>
<p>Some of the mdBook parts are plugins that need their content to be updated from time to time. Namely, thats:</p>
<ul>
<li>mdbook-admonish: run <code>mdbook-admonish</code> inside the <code>docs</code> folder</li>
<li>mdbook-emojicodes: works without CSS, so no updates needed</li>
<li>mdbook-catppuccin: follow instructions in the <a href="https://github.com/catppuccin/mdbook">mdbook-catppuccin repository</a></li>
</ul>
<h2 id="deployment"><a class="header" href="#deployment">Deployment</a></h2>
<p>Deployment to Cloudflare pages automated and happens whenever a commit to main occurs.
A <a href="https://github.com/garuda-linux/infrastructure-nix/blob/main/.github/workflows/pages.yml">GitHub actions workflow</a>
builds and pushes it to the <code>cf-pages</code> branch, which will then be used by the Cloudflare pages app to deploy the new
version from.</p>
<pre><code class="language-yaml">{ {#include ../../../.github/workflows/pages.yml}}
</code></pre>
<h2 id="issues-and-their-solution"><a class="header" href="#issues-and-their-solution">Issues and their solution</a></h2>
<h3 id="sidebar-or-something-else-on-the-documentation-doesnt-work-as-expected"><a class="header" href="#sidebar-or-something-else-on-the-documentation-doesnt-work-as-expected">Sidebar or something else on the documentation doesn't work as expected</a></h3>
<p>Chances are that the custom CSS parts need to be rebased to a newer version.
They can be found in <code>./docs/theme/css</code> and the only addition we made here is to use the Fira Sans font instead of the
default one.
To rebase against a newer version comment out <code>dditional-css</code> in <code>./docs/book.toml</code> and move the <code>css</code> folder somewhere
else temporarily.
After that, run <code>mdbook build</code> inside the <code>docs</code> folder. The new CSS files can now be found inside the <code>./docs/book/css</code>
folder.
Copy those to the <code>./docs/theme/css</code> folder and alter the occurrences of font settings to include Fira Sans (or run a
diff to find out where).
After uncommenting <code>additional-css</code> in <code>book.toml</code>, run <code>mdbook build</code> again to verify nothing got broken along the way.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tailscale"><a class="header" href="#tailscale">Tailscale</a></h1>
<p>Our current access policies look as follows:</p>
<pre><code class="language-json">// This tailnet's ACLs are maintained in https://gitlab.com/garuda-linux/infra-nix
{
	// Define access control lists for users, groups, autogroups, tags,
	// Tailscale IP addresses, and subnet ranges
	"acls": [
		// All servers can connect to each other, use exit nodes and oracle-dragon as DNS
		{
			"action": "accept",
			"src":    ["tag:infra"],
			"dst":    ["tag:infra:*", "autogroup:internet:*", "100.86.102.115:*"],
		},
		// Tailscale admins can access every device
		{
			"action": "accept",
			"src":    ["autogroup:admin"],
			"dst":    ["*:*"],
		},
		// Shared out nodes can be accessed on SSH / Mosh ports
		{
			"action": "accept",
			"src":    ["autogroup:shared"],
			"dst":    ["*:22,222-230,666,60000-61000"],
		},
		// Let the chaotic nodes connect to chaotic-v4's Redis (build distribution)
		{
			"action": "accept",
			"src":    ["tag:chaotic-node"],
			"dst":    ["100.75.227.149:22,6379"],
		},
	],
	// Current infra maintainers
	"groups": {
		"group:admins": ["dr460nf1r3@github", "JustTNE@github"],
	},
	// Define a tag to use as destinations
	"tagOwners": {
		// Admins may apply the "infra" tag
		"tag:infra":        ["group:admins"],
		"tag:chaotic-node": ["group:admins"],
	},
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="garuda-linux-code-of-conduct"><a class="header" href="#garuda-linux-code-of-conduct">Garuda Linux Code of Conduct</a></h1>
<p>Thank you for being a part of the Garuda Linux community. We value your participation and want everyone to have an
enjoyable and fulfilling experience. Accordingly, all participants are expected to follow this Code of Conduct, and to
show respect, understanding, and consideration to one another. Thank you for helping make this a welcoming, friendly
community for everyone.</p>
<h2 id="scope"><a class="header" href="#scope">Scope</a></h2>
<p>This Code of Conduct applies to all Garuda Linux community spaces, including, but not limited to:</p>
<ul>
<li>Code repositories - <code>gitlab.com/garuda-linux</code> and <code>github.com/garuda-linux</code></li>
<li>Garuda Linux's Telegram channels and groups (including bridges to Matrix)</li>
<li>Mailing <code>*@garudalinux.org</code></li>
<li>Community spaces hosted on <code>garudalinux.org</code> infrastructure</li>
</ul>
<p>Communication channels and private conversations that are normally out of scope may be considered in scope if a Garuda
Linux participant is being stalked or harassed. Social media conversations may be considered in-scope if the incident
occurred under a Garuda Linux related hashtag, or when an official Garuda Linux account on social media is tagged, or
within any other discussion about Garuda Linux. The Garuda Linux's staff reserves the right to take actions against
behaviors that happen in any context, if they are deemed to be relevant to the Garuda Linux project and its
participants.</p>
<p>All participants in Garuda Linux community spaces are subject to the Code of Conduct. This includes founding members,
staff members, corporate sponsors, and paid employees. This also includes volunteers, maintainers, leaders,
contributors, contribution reviewers, issue reporters, Garuda Linux users, and anyone participating in discussion in
Garuda Linux community spaces.</p>
<h2 id="reporting-an-incident"><a class="header" href="#reporting-an-incident">Reporting an Incident</a></h2>
<p>If you believe that someone is violating the Code of Conduct, or have any other concerns, please
contact <a href="mailto:team@garudalinux.org">team@garudalinux.org</a>.</p>
<h2 id="our-standards"><a class="header" href="#our-standards">Our Standards</a></h2>
<p>The Garuda Linux community is dedicated to providing a positive experience for everyone, regardless of:</p>
<ul>
<li>age</li>
<li>body size</li>
<li>caste</li>
<li>citizenship</li>
<li>disability</li>
<li>education</li>
<li>ethnicity</li>
<li>familial status</li>
<li>gender expression</li>
<li>gender identity</li>
<li>genetic information</li>
<li>immigration status</li>
<li>level of experience</li>
<li>nationality</li>
<li>personal appearance</li>
<li>pregnancy</li>
<li>race</li>
<li>religion</li>
<li>sex characteristics</li>
<li>sexual orientation</li>
<li>sexual identity</li>
<li>socio-economic status</li>
<li>tribe</li>
<li>veteran status</li>
</ul>
<h2 id="community-guidelines"><a class="header" href="#community-guidelines">Community Guidelines</a></h2>
<p>Behaviors that contribute to creating a positive environment include:</p>
<ul>
<li><strong>Be friendly.</strong> Use welcoming and inclusive language.</li>
<li><strong>Be empathetic.</strong> Be respectful of others' viewpoints and experiences.</li>
<li><strong>Be respectful.</strong> Express disagreements in a polite and constructive manner.</li>
<li><strong>Be considerate.</strong> Focus on what is best for the community. Keep discussions around technology choices constructive
and respectful. Remember that decisions are often a difficult choice between competing priorities.</li>
<li><strong>Be patient and generous.</strong> If someone asks for help, it is because they need it. When documentation is available
that answers the question, politely point them to it. If the question is off-topic, suggest a more appropriate online
space to seek help.</li>
<li><strong>Try to be concise.</strong> Read the discussion before commenting in order to not repeat a point that has been made.</li>
</ul>
<h2 id="inappropriate-behavior"><a class="header" href="#inappropriate-behavior">Inappropriate Behavior</a></h2>
<p>We want all participants in the Garuda Linux community have the best possible experience they can. Community members
asked to stop any inappropriate behavior are expected to comply immediately.</p>
<p>Inappropriate behaviors include, but are not limited to:</p>
<ul>
<li><strong>Deliberate intimidation, stalking, or following.</strong></li>
<li><strong>Sustained disruption of online discussion, talks, or other events.</strong> Sustained disruption of events, online
discussions, or meetings, including talks and presentations, will not be tolerated. This includes 'Talking over' or '
heckling' event speakers or influencing crowd actions that cause hostility in event sessions. Sustained disruption
also includes drinking alcohol to excess or using recreational drugs to excess, or pushing others to do so.</li>
<li><strong>Harassment of people who don't drink alcohol or other legal substances.</strong> We do not tolerate derogatory comments
about those who abstain from alcohol or other legal substances. We do not tolerate pushing people to drink, talking
about their abstinence or preferences to others, or pressuring them to drink - physically or through jeering.</li>
<li><strong>Sexist, racist, homophobic, transphobic, ableist language or otherwise exclusionary language.</strong> This includes
deliberately referring to someone by a gender that they do not identify with, and/or questioning the legitimacy of an
individual's gender identity. If you're unsure if a word is derogatory, don't use it. This also includes repeated
subtle and/or indirect discrimination.</li>
<li><strong>Unwelcome sexual attention or behavior that contributes to a sexualized environment.</strong> This includes sexualized
comments, jokes or imagery in interactions, communications or presentation materials, as well as inappropriate
touching, groping, or sexual advances. Sponsors should not use sexualized images, activities, or other material.
Meetup organizing staff and other volunteer organizers should not use sexualized clothing/uniforms/costumes, or
otherwise create a sexualized environment.</li>
<li><strong>Unwelcome physical contact.</strong> This includes touching a person without permission, including sensitive areas such as
their hair, pregnant stomach, mobility device (wheelchair, scooter, etc) or tattoos. This also includes physically
blocking or intimidating another person. Physical contact without affirmative consent is not acceptable. This includes
sharing or distribution of sexualized images or text.</li>
<li><strong>Violence or threats of violence.</strong> Violence and threats of violence are not acceptable - online or offline. This
includes incitement of violence toward any individual, including encouraging a person to commit self-harm. This also
includes posting or threatening to post other people's personally identifying information ("doxxing") online.</li>
<li><strong>Influencing or encouraging inappropriate behavior.</strong> If you influence or encourage another person to violate the
Code of Conduct, you may face the same consequences as if you had violated the Code of Conduct.</li>
</ul>
<h3 id="safety-versus-comfort"><a class="header" href="#safety-versus-comfort">Safety versus Comfort</a></h3>
<p>The Garuda Linux community prioritizes marginalized people's safety over privileged people's comfort. The following are
not against the Code of Conduct.</p>
<ul>
<li>"Reverse"-isms, including "reverse racism," "reverse sexism," and "cisphobia"</li>
<li>Reasonable communication of boundaries, such as "leave me alone," "go away," or "I'm not discussing this with you."</li>
<li>Criticizing racist, sexist, cissexist, or otherwise oppressive behavior or assumptions</li>
<li>Communicating boundaries or criticizing oppressive behavior in a "tone" you don't find congenial</li>
</ul>
<p>If you have questions about the above statements, please
read <a href="https://wiki.gnome.org/Foundation/CodeOfConduct/SupportingDiversity">GNOME Foundation's document on Supporting Diversity</a>.</p>
<p>Outreach and diversity efforts directed at under-represented groups are permitted under the code of conduct. For
example, a social event for women would not be classified as being outside the Code of Conduct under this provision.</p>
<p>Basic expectations for conduct are not covered by the "reverse-ism clause" and would be enforced irrespective of the
demographics of those involved. For example, racial discrimination will not be tolerated, irrespective of the race of
those involved. Nor would unwanted sexual attention be tolerated, whatever someone's gender or sexual orientation.
Members of our community have the right to expect that participants in the project will uphold these standards.</p>
<p>If a participant engages in behavior that violates this code of conduct, the Garuda Linux's staff may take any action
they deem appropriate. In cases involving the staff or founding members the immediate action is expelishment.</p>
<h2 id="procedure-for-handling-incidents"><a class="header" href="#procedure-for-handling-incidents">Procedure for Handling Incidents</a></h2>
<p>You can make a report by emailing <a href="mailto:team@garudalinux.org">team@garudalinux.org</a>.</p>
<p>If you make a report via email, we hope you can provide us with some information that will help us identify the reported
person. If you donâ€™t remember all the details, we still encourage you to make a report.</p>
<p>We encourage you to include the following information in your report:</p>
<ul>
<li>Your contact info (so we can get in touch with you if we need to follow up)</li>
<li>Date and time of the incident</li>
<li>Whether the incident is ongoing</li>
<li>Which online community and which part of the online community space it occurred in</li>
<li>Description of the incident</li>
<li>Identifying information of the reported person such as name, online username, handle, email address, or IP address</li>
<li>A link to the conversation</li>
<li>Any logs or screenshots of the conversation</li>
<li>Additional circumstances surrounding the incident</li>
<li>Other people involved in or witnesses to the incident and their contact information or # Garuda Linux Code of Conduct</li>
</ul>
<p>Thank you for being a part of the Garuda Linux community. We value your participation and want everyone to have an
enjoyable and fulfilling experience.
Accordingly, all participants are expected to follow this Code of Conduct, and to show respect, understanding, and
consideration to one another.
Thank you for helping make this a welcoming, friendly community for everyone.</p>
<h2 id="scope-1"><a class="header" href="#scope-1">Scope</a></h2>
<p>This Code of Conduct applies to all Garuda Linux community spaces, including, but not limited to:</p>
<ul>
<li>Code repositories - <code>gitlab.com/garuda-linux</code> and <code>github.com/garuda-linux</code></li>
<li>Garuda Linux's Telegram channels and groups (including bridges to Matrix)</li>
<li>Mailing <code>*@garudalinux.org</code></li>
<li>Community spaces hosted on <code>garudalinux.org</code> infrastructure</li>
</ul>
<p>Communication channels and private conversations that are normally out of scope may be considered in scope if a Garuda
Linux participant is being stalked or harassed.
Social media conversations may be considered in-scope if the incident occurred under a Garuda Linux related hashtag, or
when an official Garuda Linux account on social media is tagged, or within any other discussion about Garuda Linux.
The Garuda Linux's staff reserves the right to take actions against behaviors that happen in any context, if they are
deemed to be relevant to the Garuda Linux project and its participants.</p>
<p>All participants in Garuda Linux community spaces are subject to the Code of Conduct. This includes founding members,
staff members, corporate sponsors, and paid employees.
This also includes volunteers, maintainers, leaders, contributors, contribution reviewers, issue reporters, Garuda Linux
users, and anyone participating in discussion in Garuda Linux community spaces.</p>
<h2 id="reporting-an-incident-1"><a class="header" href="#reporting-an-incident-1">Reporting an Incident</a></h2>
<p>If you believe that someone is violating the Code of Conduct, or have any other concerns, please
contact <a href="mailto:team@garudalinux.org">team@garudalinux.org</a>.</p>
<h2 id="our-standards-1"><a class="header" href="#our-standards-1">Our Standards</a></h2>
<p>The Garuda Linux community is dedicated to providing a positive experience for everyone, regardless of:</p>
<ul>
<li>age</li>
<li>body size</li>
<li>caste</li>
<li>citizenship</li>
<li>disability</li>
<li>education</li>
<li>ethnicity</li>
<li>familial status</li>
<li>gender expression</li>
<li>gender identity</li>
<li>genetic information</li>
<li>immigration status</li>
<li>level of experience</li>
<li>nationality</li>
<li>personal appearance</li>
<li>pregnancy</li>
<li>race</li>
<li>religion</li>
<li>sex characteristics</li>
<li>sexual orientation</li>
<li>sexual identity</li>
<li>socio-economic status</li>
<li>tribe</li>
<li>veteran status</li>
</ul>
<h2 id="community-guidelines-1"><a class="header" href="#community-guidelines-1">Community Guidelines</a></h2>
<p>Behaviors that contribute to creating a positive environment include:</p>
<ul>
<li><strong>Be friendly.</strong> Use welcoming and inclusive language.</li>
<li><strong>Be empathetic.</strong> Be respectful of others' viewpoints and experiences.</li>
<li><strong>Be respectful.</strong> Express disagreements in a polite and constructive manner.</li>
<li><strong>Be considerate.</strong> Focus on what is best for the community. Keep discussions around technology choices constructive
and respectful.<br />
Remember that decisions are often a difficult choice between competing priorities.</li>
<li><strong>Be patient and generous.</strong> If someone asks for help, it is because they need it.
When documentation is available that answers the question, politely point them to it. If the question is off-topic,
suggest a more appropriate online space to seek help.</li>
<li><strong>Try to be concise.</strong> Read the discussion before commenting in order to not repeat a point that has been made.</li>
</ul>
<h2 id="inappropriate-behavior-1"><a class="header" href="#inappropriate-behavior-1">Inappropriate Behavior</a></h2>
<p>We want all participants in the Garuda Linux community have the best possible experience they can. Community members
asked to stop any inappropriate behavior are expected to comply immediately.</p>
<p>Inappropriate behaviors include, but are not limited to:</p>
<ul>
<li><strong>Deliberate intimidation, stalking, or following.</strong></li>
<li><strong>Sustained disruption of online discussion, talks, or other events.</strong> Sustained disruption of events, online
discussions, or meetings, including talks and presentations, will not be tolerated.
This includes 'Talking over' or 'heckling' event speakers or influencing crowd actions that cause hostility in event
sessions.
Sustained disruption also includes drinking alcohol to excess or using recreational drugs to excess, or pushing others
to do so.</li>
<li><strong>Harassment of people who don't drink alcohol or other legal substances.</strong> We do not tolerate derogatory comments
about those who abstain from alcohol or other legal substances.
We do not tolerate pushing people to drink, talking about their abstinence or preferences to others, or pressuring
them to drink - physically or through jeering.</li>
<li><strong>Sexist, racist, homophobic, transphobic, ableist language or otherwise exclusionary language.</strong> This includes
deliberately referring to someone by a gender that they do not identify with, and/or
questioning the legitimacy of an individual's gender identity.
If you're unsure if a word is derogatory, don't use it. This also includes repeated subtle and/or indirect
discrimination.</li>
<li><strong>Unwelcome sexual attention or behavior that contributes to a sexualized environment.</strong> This includes sexualized
comments, jokes or imagery in interactions, communications or presentation materials, as well as inappropriate
touching, groping, or sexual advances. Sponsors should not use sexualized images, activities, or other material.
Meetup organizing staff and other volunteer organizers should not use sexualized clothing/uniforms/costumes, or
otherwise create a sexualized environment.</li>
<li><strong>Unwelcome physical contact.</strong> This includes touching a person without permission, including sensitive areas such as
their hair, pregnant stomach, mobility device (wheelchair, scooter, etc) or tattoos. This also includes physically
blocking or intimidating another person. Physical contact without affirmative consent is not acceptable. This includes
sharing or distribution of sexualized images or text.</li>
<li><strong>Violence or threats of violence.</strong> Violence and threats of violence are not acceptable - online or offline. This
includes incitement of violence toward any individual, including encouraging a person to commit self-harm. This also
includes posting or threatening to post other people's personally identifying information ("doxxing") online.</li>
<li><strong>Influencing or encouraging inappropriate behavior.</strong> If you influence or encourage another person to violate the
Code of Conduct, you may face the same consequences as if you had violated the Code of Conduct.</li>
</ul>
<h3 id="safety-versus-comfort-1"><a class="header" href="#safety-versus-comfort-1">Safety versus Comfort</a></h3>
<p>The Garuda Linux community prioritizes marginalized people's safety over privileged people's comfort. The following are
not against the Code of Conduct.</p>
<ul>
<li>"Reverse"-isms, including "reverse racism," "reverse sexism," and "cisphobia"</li>
<li>Reasonable communication of boundaries, such as "leave me alone," "go away," or "I'm not discussing this with you."</li>
<li>Criticizing racist, sexist, cissexist, or otherwise oppressive behavior or assumptions</li>
<li>Communicating boundaries or criticizing oppressive behavior in a "tone" you don't find congenial</li>
</ul>
<p>If you have questions about the above statements, please
read <a href="https://wiki.gnome.org/Foundation/CodeOfConduct/SupportingDiversity">GNOME Foundation's document on Supporting Diversity</a>.</p>
<p>Outreach and diversity efforts directed at under-represented groups are permitted under the code of conduct. For
example, a social event for women would not be classified as being outside the Code of Conduct under this provision.</p>
<p>Basic expectations for conduct are not covered by the "reverse-ism clause" and would be enforced irrespective of the
demographics of those involved. For example, racial discrimination will not be tolerated, irrespective of the race of
those involved. Nor would unwanted sexual attention be tolerated, whatever someone's gender or sexual orientation.
Members of our community have the right to expect that participants in the project will uphold these standards.</p>
<p>If a participant engages in behavior that violates this code of conduct, the Garuda Linux's staff may take any action
they deem appropriate. In cases involving the staff or founding members the immediate action is expelishment.</p>
<h2 id="procedure-for-handling-incidents-1"><a class="header" href="#procedure-for-handling-incidents-1">Procedure for Handling Incidents</a></h2>
<p>You can make a report by emailing <a href="mailto:team@garudalinux.org">team@garudalinux.org</a>.</p>
<p>If you make a report via email, we hope you can provide us with some information that will help us identify the reported
person. If you donâ€™t remember all the details, we still encourage you to make a report.</p>
<p>We encourage you to include the following information in your report:</p>
<ul>
<li>Your contact info (so we can get in touch with you if we need to follow up)</li>
<li>Date and time of the incident</li>
<li>Whether the incident is ongoing</li>
<li>Which online community and which part of the online community space it occurred in</li>
<li>Description of the incident</li>
<li>Identifying information of the reported person such as name, online username, handle, email address, or IP address</li>
<li>A link to the conversation</li>
<li>Any logs or screenshots of the conversation</li>
<li>Additional circumstances surrounding the incident</li>
<li>Other people involved in or witnesses to the incident and their contact information or description</li>
</ul>
<h2 id="license"><a class="header" href="#license">License</a></h2>
<p>The Garuda Linux Code of Conduct is licensed under
a <a href="http://creativecommons.org/licenses/by-sa/3.0/">Creative Commons Attribution Share-Alike 3.0 Unported License</a>.</p>
<p><img src="https://licensebuttons.net/l/by-sa/3.0/88x31.png" alt="Creative Commons License" /></p>
<h2 id="attribution"><a class="header" href="#attribution">Attribution</a></h2>
<p>The Garuda Linux Code of Conduct was forked from GNOME Foundation's Code of Conduct (last modified 2020-10-01), which is
under a Creative Commons license. See
the <a href="https://web.archive.org/web/20210813233606/https://wiki.gnome.org/Foundation/CodeOfConduct">original page</a> for the
original attributions.
description</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="privacy-policy-for-garuda-linux"><a class="header" href="#privacy-policy-for-garuda-linux">Privacy policy for Garuda Linux</a></h1>
<h2 id="about-this-document"><a class="header" href="#about-this-document">About this document</a></h2>
<p>This Privacy Policy governs the manner in which Garuda Linux collects, uses, maintains and discloses information
collected from users (each, a â€œUserâ€) of our website and web services..</p>
<h2 id="what-information-do-we-collect"><a class="header" href="#what-information-do-we-collect">What information do we collect?</a></h2>
<p>We collect information from you when you register on our site and gather data when you participate in the forum by
reading, writing, and evaluating the content shared here.</p>
<p>When registering on our site, you may be asked to enter your name and e-mail address. You may, however, visit our site
without registering. Your e-mail address will be verified by an email containing a unique link. If that link is visited,
we know that you control the e-mail address. Your IP address will be checked against a database of known spammers to
prevent such actions.</p>
<p>If you contact us directly, we may receive additional information about you such as your name, email address, the
contents of the message and/or attachments you may send us, and any other information you may choose to provide.</p>
<p>When registered and posting, we record the IP address that the post originated from. We also may retain server logs
which include the IP address of every request to our server, which will be purged after 30 days.</p>
<h2 id="what-do-we-use-your-information-for"><a class="header" href="#what-do-we-use-your-information-for">What do we use your information for?</a></h2>
<p>Any of the information we collect from you may be used in one of the following ways:</p>
<ul>
<li>To provide, operate, and maintain our infrastructure</li>
<li>To allow using our services that require a login, as well as to provide convenience features such as staying logged in
or keeping personally chosen settings.</li>
<li>To send periodic emails that are generated by our services such as the forum, which may however be turned off if
desired.</li>
</ul>
<p>We have no interest in your data and only store the minimum needed to operate the services we provide to our users.</p>
<h2 id="how-do-we-protect-your-information"><a class="header" href="#how-do-we-protect-your-information">How do we protect your information?</a></h2>
<p>We implement a variety of security measures to maintain the safety of your personal information when you enter, submit,
or access your personal information.</p>
<h2 id="what-is-your-data-retention-policy"><a class="header" href="#what-is-your-data-retention-policy">What is your data retention policy?</a></h2>
<p>We will make a good faith effort to:</p>
<ul>
<li>Retain server logs containing the IP address of all requests to this server no more than 90 days.</li>
<li>Retain the IP addresses associated with registered users and their posts no more than 5 years.</li>
</ul>
<h2 id="third-party-privacy-policies"><a class="header" href="#third-party-privacy-policies">Third Party Privacy Policies</a></h2>
<p>Garuda Linux's Privacy Policy does not apply to some of the services we utilize in our infrastructure. Thus, we are
advising you to consult the respective Privacy Policies of these third-party services for more detailed information.</p>
<p>This includes, but may not be limited to:</p>
<ul>
<li><a href="https://www.cloudflare.com/">Cloudflare</a> to protect against common threats and enhance our infrastructure</li>
<li><a href="www.hetzner.com/">Hetzner</a> as server and backup storage provider (located in Germany)</li>
<li><a href="https://translate.google.com/">Google Translate</a> to offer translations on our website</li>
<li><a href="https://opencollective.org/">OpenCollective</a>, <a href="https://liberapay.com/">Liberapay</a>
and <a href="https://www.paypal.com/">Paypal</a> to allow the collection of donations that sustain our infrastructure</li>
</ul>
<h2 id="cookies"><a class="header" href="#cookies">Cookies</a></h2>
<p>Our Site may use â€œcookiesâ€ to enhance User experience. Userâ€™s web browser places cookies on their hard drive for
record-keeping purposes and sometimes to track information about them. The user may choose to set their web browser to
refuse cookies or to alert you when cookies are being sent. If they do so, note that some parts of the Site may not
function properly.</p>
<h2 id="sharing-your-personal-information"><a class="header" href="#sharing-your-personal-information">Sharing your personal information</a></h2>
<p>We do not sell, trade, or rent Userâ€™s personal identification information to others.</p>
<h2 id="how-long-do-we-retain-your-data"><a class="header" href="#how-long-do-we-retain-your-data">How long do we retain your data</a></h2>
<p>If you leave a comment, the comment and its metadata are retained indefinitely. This is so we can recognize and approve
any follow-up comments automatically instead of holding them in a moderation queue.</p>
<p>For users that register on our website (if any), we also store the personal information they provide in their user
profile. All users can see, edit, or delete their personal information at any time (except they cannot change their
username). Website administrators can also see and edit that information.</p>
<h2 id="embedded-content-from-other-websites"><a class="header" href="#embedded-content-from-other-websites">Embedded content from other websites</a></h2>
<p>Articles on this site may include embedded content (e.g. videos, images, articles, etc.). Embedded content from other
websites behaves in the exact same way as if the visitor has visited the other website.</p>
<p>These websites may collect data about you, use cookies, embed additional third-party tracking, and monitor your
interaction with that embedded content, including tracing your interaction with the embedded content if you have an
account and are logged in to that website.</p>
<h2 id="free-software"><a class="header" href="#free-software">Free software</a></h2>
<p>Garuda Linux develops free software. All our tools are and will always be free software. Garuda Linux is part of OIN
since November 2020. The current license can be viewed here. Additional information about packages covered by this
license can be viewed here.</p>
<p>If you want to check the license of a package, you can do so with Pacman.</p>
<h2 id="what-rights-you-have-over-your-data"><a class="header" href="#what-rights-you-have-over-your-data">What rights you have over your data</a></h2>
<p>If you have an account on this site or have left comments, you can request to receive an exported file of the personal
data we hold about you, including any data you have provided to us. You can also request that we erase any personal data
we hold about you. This does not include any data we are obliged to keep for administrative, legal, or security
purposes.</p>
<h2 id="childrens-information"><a class="header" href="#childrens-information">Children's Information</a></h2>
<p>Another part of our priority is adding protection for children while using the internet. We encourage parents and
guardians to observe, participate in, and/or monitor and guide their online activity.</p>
<p>Garuda Linux does not knowingly collect any personal identifiable information from children under the age of 13. If you
think that your child provided this kind of information on our website, we strongly encourage you to contact us
immediately and we will do our best efforts to promptly remove such information from our records.</p>
<h2 id="changes-to-this-privacy-policy"><a class="header" href="#changes-to-this-privacy-policy">Changes to This Privacy Policy</a></h2>
<p>We may update our Privacy Policy from time to time. Thus, we advise you to review this page periodically for any
changes. We will notify you of any
changes by posting the new Privacy Policy on this page. These changes are effective immediately, after they are posted
on this page.</p>
<h2 id="your-acceptance-of-these-terms"><a class="header" href="#your-acceptance-of-these-terms">Your acceptance of these terms</a></h2>
<p>By using this Site, you signify your acceptance of this policy. If you do not agree to this policy, please do not use
our services. Your continued use of them following the posting of changes to this policy will be deemed your acceptance
of those changes.</p>
<h2 id="contact-us"><a class="header" href="#contact-us">Contact Us</a></h2>
<p>If you have any questions about this Privacy Policy, the practices of this site, or your dealings with this site, please
contact us via <a href="mailto:team@garudalinux.org">email</a>.</p>
<p><strong>This privacy policy has been updated in September 2023.</strong></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="security-policy"><a class="header" href="#security-policy">Security Policy</a></h1>
<p>If any vulnerability or security flaw is discovered, please contact us directly
via <a href="mailto:team@garudalinux.org">team@garudalinux.org</a>.</p>
<p>We will try to respond within 24â€“48 hours on a best-effort basis.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="credits"><a class="header" href="#credits">Credits</a></h1>
<ul>
<li><a href="https://github.com/mozilla">https://github.com/mozilla</a></li>
<li><a href="https://github.com/JetBrains/JetBrainsMono">https://github.com/JetBrains/JetBrainsMono</a></li>
<li><a href="https://github.com/nix-community/infra">https://github.com/nix-community/infra</a></li>
<li><a href="https://github.com/BackInBash/RPIPv6">https://github.com/BackInBash/RPIPv6</a></li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>