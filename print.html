<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js navy">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Garuda&#x27;s infra documentation</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="Contains the documentation for the Garuda Linux infrastructure.">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="theme/css/custom.css">

    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "navy";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><li class="part-title">Welcome</li><li class="chapter-item expanded "><a href="intro.html"><strong aria-hidden="true">1.</strong> Introduction</a></li><li class="chapter-item expanded "><a href="general.html"><strong aria-hidden="true">2.</strong> General information</a></li><li class="chapter-item expanded "><a href="common.html"><strong aria-hidden="true">3.</strong> Common tasks</a></li><li class="chapter-item expanded "><a href="important-links.html"><strong aria-hidden="true">4.</strong> Important links</a></li><li class="chapter-item expanded affix "><li class="part-title">Hosts</li><li class="chapter-item expanded "><a href="hosts/immortalis.html"><strong aria-hidden="true">5.</strong> immortalis</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="nixos-containers/chaotic-kde.html"><strong aria-hidden="true">5.1.</strong> chaotic-kde</a></li><li class="chapter-item expanded "><a href="nixos-containers/docker-proxied.html"><strong aria-hidden="true">5.2.</strong> docker-proxied</a></li><li class="chapter-item expanded "><a href="nixos-containers/docker.html"><strong aria-hidden="true">5.3.</strong> docker</a></li><li class="chapter-item expanded "><a href="nixos-containers/forum.html"><strong aria-hidden="true">5.4.</strong> forum</a></li><li class="chapter-item expanded "><a href="nixos-containers/github-runner.html"><strong aria-hidden="true">5.5.</strong> github-runner</a></li><li class="chapter-item expanded "><a href="nixos-containers/lemmy.html"><strong aria-hidden="true">5.6.</strong> lemmy</a></li><li class="chapter-item expanded "><a href="nixos-containers/mastodon.html"><strong aria-hidden="true">5.7.</strong> mastodon</a></li><li class="chapter-item expanded "><a href="nixos-containers/meshcentral.html"><strong aria-hidden="true">5.8.</strong> meshcentral</a></li><li class="chapter-item expanded "><a href="nixos-containers/postgres.html"><strong aria-hidden="true">5.9.</strong> postgres</a></li><li class="chapter-item expanded "><a href="nixos-containers/repo.html"><strong aria-hidden="true">5.10.</strong> repo</a></li><li class="chapter-item expanded "><a href="nixos-containers/temeraire.html"><strong aria-hidden="true">5.11.</strong> temeraire</a></li><li class="chapter-item expanded "><a href="nixos-containers/web-front.html"><strong aria-hidden="true">5.12.</strong> web-front</a></li></ol></li><li class="chapter-item expanded "><a href="hosts/garuda-mail.html"><strong aria-hidden="true">6.</strong> garuda-mail</a></li><li class="chapter-item expanded affix "><li class="part-title">Services</li><li class="chapter-item expanded "><div><strong aria-hidden="true">7.</strong> Bitwarden</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">8.</strong> Chaotic-AUR </div></li><li class="chapter-item expanded "><a href="services/discourse.html"><strong aria-hidden="true">9.</strong> Discourse</a></li><li class="chapter-item expanded "><a href="websites/documentation.html"><strong aria-hidden="true">10.</strong> Documentation</a></li><li class="chapter-item expanded "><div><strong aria-hidden="true">11.</strong> Firefox syncserver</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">12.</strong> Invidious (Youtube frontend)</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">13.</strong> Lemmy</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">14.</strong> Lingva</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">15.</strong> Mastodon</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">16.</strong> Matrix</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">17.</strong> Nextcloud</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">18.</strong> Piped</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">19.</strong> PrivateBin</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">20.</strong> Searx</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">21.</strong> TheLounge</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">22.</strong> Whoogle</div></li><li class="chapter-item expanded "><div><strong aria-hidden="true">23.</strong> WikiJs</div></li><li class="chapter-item expanded affix "><li class="part-title">Misc</li><li class="chapter-item expanded "><div><strong aria-hidden="true">24.</strong> Privacy policy</div></li><li class="chapter-item expanded "><a href="credits.html"><strong aria-hidden="true">25.</strong> Credits</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Garuda&#x27;s infra documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        <a href="https://github.com/garuda-linux/infrastructure-nix" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-code-fork"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="garuda-linux-server-configurations"><a class="header" href="#garuda-linux-server-configurations">Garuda Linux server configurations</a></h1>
<p><a href="https://builtwithnix.org"><img src="https://img.shields.io/static/v1?logo=nixos&amp;logoColor=white&amp;label=&amp;message=Built%20with%20Nix&amp;color=41439a" alt="built with nix" /></a> <a href="https://github.com/garuda-linux/infrastructure-nix/actions/workflows/flake_check.yml"><img src="https://github.com/garuda-linux/infrastructure-nix/actions/workflows/flake_check.yml/badge.svg?branch=main" alt="run nix flake check" /></a> <a href="https://github.com/garuda-linux/infrastructure-nix/actions/workflows/pages.yml"><img src="https://github.com/garuda-linux/infrastructure-nix/actions/workflows/pages.yml/badge.svg" alt="deploy docs" /></a></p>
<h2 id="general-information"><a class="header" href="#general-information">General information</a></h2>
<ul>
<li>Our current infrastructure is hosted in one of <a href="https://www.hetzner.com/dedicated-rootserver/ax102">these</a>.</li>
<li>The only other server not being contained in this dedicated server is our mail server.</li>
<li>Both servers are being backed up to Hetzner storage boxes via <a href="https://www.borgbackup.org/">Borg</a>.</li>
<li>After multiple different setups, we settled on <a href="https://nixos.org/">NixOS</a> as our main OS as it provides reproducible and atomically updated system states</li>
<li>Most (sub)domains are protected by Cloudflare while also making use of its caching feature. Exemptions are services such as our mail server and parts violating Cloudflares rules such as proxying Piped content.</li>
</ul>
<h2 id="quick-links"><a class="header" href="#quick-links">Quick links</a></h2>
<ul>
<li><a href="./hosts/common.html">Common maintenance tasks</a></li>
<li><a href="./hosts/garuda-mail.html">Host: garuda-mail</a></li>
<li><a href="./hosts/immortalis.html">Host: immortalis</a></li>
</ul>
<h2 id="devshell-and-how-to-enter-it"><a class="header" href="#devshell-and-how-to-enter-it">Devshell and how to enter it</a></h2>
<p>This NixOS flake provides a <a href="https://github.com/numtide/devshell">devshell</a> which contains all deployment tools as well as handy aliases for common tasks.
The only requirement for using it is having the Nix package manager available. It can be installed on various distributions via the package manager or the following script (<a href="https://zero-to-nix.com/start/install">click me for more information</a>):</p>
<pre><code class="language-sh">curl --proto '=https' --tlsv1.2 -sSf -L https://install.determinate.systems/nix -o nix-install.sh # Check its content afterwards
sh ./nix-install.sh install --diagnostic-endpoint=&quot;&quot;
</code></pre>
<p>This installs the Nix packages with flakes already pre-enabled. After that, the shell can be invoked as follows:</p>
<pre><code class="language-sh">nix develop # The intended way to use the devshell
nix-shell # Legacy, non-flakes way if flakes are not available for some reason
</code></pre>
<p>This also sets up pre-commit-hooks and shows the currently implemented tasks, which can be executed by running the command.</p>
<pre><code>[infra-nix]

ansible-core    - Radically simple IT automation
apply           - Applies the infra-nix configuration previously deployed to the servers
buildiso-local  - Spawns a local buildiso shell to build to ./buildiso (needs Docker)
buildiso-remote - Spawns a buildiso shell on the iso-runner builder
clean           - Runs the garbage collection on the servers
deploy          - Deploys the local NixOS configuration to the servers
update          - Performs a full system update on the servers by bumping flake lock
update-forum    - Updates the Discourse container of our forum
update-toolbox  - Updates the locked Chaotic toolbox commit and deploys the changes
update-website  - Updates the locked website commit and deploys the changes
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="general-structure"><a class="header" href="#general-structure">General structure</a></h2>
<p>A general overview of the folder structure can be found below:</p>
<pre><code class="language-sh">├── assets
├── docker-compose
│   ├── all-in-one
│   ├── github-runner
│   └── proxied
├── docs
│   ├── hosts
│   └── theme
├── home-manager
├── host_vars
│   ├── garuda-build
│   ├── garuda-mail
│   └── immortalis
├── nixos
│   ├── hosts
│   │   ├── garuda-build
│   │   ├── garuda-mail
│   │   └── immortalis
│   ├── modules
│   │   └── static
│   └── services
│       ├── chaotic
│       ├── docker-compose-runner
│       └── monitoring
├── playbooks
├── scripts
└── secrets
</code></pre>
<h2 id="secrets-in-this-repository"><a class="header" href="#secrets-in-this-repository">Secrets in this repository</a></h2>
<p>Secrets are managed via a custom Git submodule that contains <code>ansible-vault</code> encrypted files as well as a custom NixOS module <code>garuda-lib</code> which makes them available to our services. The submodule is available in the <code>secrets</code> directory once it has been set up for the first time. It can be initialized by running:</p>
<pre><code>git submodule init
git submodule update
</code></pre>
<p>To view or edit any of these files, one can use the following commands:</p>
<pre><code class="language-sh">ansible-vault decrypt secrets/pathtofile
ansible-vault edit secrets/pathtofile
ansible-vault encrypt secrets/pathtofile
</code></pre>
<p>Further information on <code>ansible-vault</code> can be found in its <a href="https://docs.ansible.com/ansible/latest/vault_guide/index.html">documentation</a>.
It is important to keep the <code>secrets</code> directory in the latest state before deploying a new configuration as misconfigurations might happen otherwise.</p>
<h2 id="passwords-in-general"><a class="header" href="#passwords-in-general">Passwords in general</a></h2>
<p>Our mission-critical passwords that maintainers and team members need to have access to are stored in our <a href="vault.garudalinux.org">Bitwarden instance</a>. After creating an account, maintainers need to be invited to the Garuda Linux organisation in order to access the stored credentials.</p>
<h2 id="linting-and-formatting"><a class="header" href="#linting-and-formatting">Linting and formatting</a></h2>
<p>We utilize <a href="https://github.com/cachix/pre-commit-hooks.nix">pre-commit-hooks</a> to automatically set up the pre-commit-hook with all the tools once <code>nix-shell</code> or <code>nix develop</code> is run for the first time. Checks can then be executed by running one of the following configs:</p>
<pre><code class="language-sh">nix flake check # checks flake outputs and runs pre-commit at the end
pre-commit run --all-files # only runs the pre-commit tools on all files
</code></pre>
<p>Its configuration can be found in the <code>flake.nix</code> file. (<a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/flake.nix">click me</a>). At the time of writing, the following tools are being run:</p>
<ul>
<li><a href="https://github.com/rhysd/actionlint">actionlint</a></li>
<li><a href="https://github.com/ansible/ansible-lint">ansible-lint</a></li>
<li><a href="https://github.com/commitizen-tools/commitizen">commitizen</a></li>
<li><a href="https://github.com/astro/deadnix">deadnix</a></li>
<li><a href="https://github.com/oxalica/nil">nil</a></li>
<li><a href="https://github.com/nix-community/nixpkgs-fmt">nixpkgs-fmt</a></li>
<li><a href="https://prettier.io/">prettier</a></li>
<li><a href="https://github.com/nerdypepper/statix">statix</a></li>
<li><a href="https://github.com/adrienverge/yamllint">yamllint</a></li>
</ul>
<p>It is recommended to run <code>pre-commit run --all-files</code> before trying to commit changes. Then use <code>cz commit</code> to generate a <code>commitizen</code> complying commit message.</p>
<h2 id="cicd"><a class="header" href="#cicd">CI/CD</a></h2>
<p>We have used pull-/push-based mirroring for this git repository, which allows easy access to Renovate without having to run a custom instance of it. The following tasks have been implemented as of now:</p>
<ul>
<li><code>nix flake check</code> runs for every labeled PR and commit on main.</li>
<li><a href="https://renovatebot.com/">Renovate</a> periodically checks <code>docker-compose.yml</code> and other supported files for version updates. It has a <a href="https://github.com/garuda-linux/infrastructure-nix/issues/5">dependency dashboard</a> as well as the <a href="https://developer.mend.io/github/garuda-linux/infrastructure-nix">developer interface</a> to check logs of individual runs. Minor updates appear as grouped PRs while major updates are separated from those. Note that this only applies to the GitHub side.</li>
<li>Deployment of our <a href="https://github.com/rust-lang/mdBook">mdBook-based</a> documentation to Cloudflare pages.</li>
</ul>
<p>Workflows will generally only be executed if a relevant file has been changed, eg. <code>nix flake check</code> won't run if only the README was changed.</p>
<h2 id="monitoring"><a class="header" href="#monitoring">Monitoring</a></h2>
<p>Our current monitoring stack mostly relies on Netdata to provide insight into current system loads and trends. The major reason for using it was that it provides the most vital metrics and alerts out of the box without having to create in-depth configurations. Might switch to the Prometheus/Grafana/Loki stack in the future. We used to set up children -&gt; parent streaming in the past, though after transitioning to one big host this didn't make sense anymore. Instead, up to 10GB of data gets stored on individual hosts. While Netdata agents do have their dashboard, the <a href="https://app.netdata.cloud/spaces/garuda-infra/rooms/all-nodes">Dashboard provided by Netdata</a> is far superior and allows a better insight, eg. by offering the functions feature. Additional services like Squid or Nginx have been configured to be monitored by Netdata plugins as well. Further information can be found in its <a href="https://learn.netdata.cloud/">documentation</a>. To access the previously linked dashboard, use <code>team@garudalinux.org</code> as login, the login will be completed after opening the link sent here.</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="common-maintenance-tasks"><a class="header" href="#common-maintenance-tasks">Common maintenance tasks</a></h2>
<h3 id="rebuilding--updating-the-forum-container"><a class="header" href="#rebuilding--updating-the-forum-container">Rebuilding / updating the forum container</a></h3>
<p>Sometimes Discourse needs its container to build rebuild via cli rather than the webinterface. This can be done with:</p>
<pre><code class="language-sh">ssh -p 224 $user@116.202.208.112
cd /var/discourse
sudo ./launcher rebuild app
</code></pre>
<h3 id="building-iso-files"><a class="header" href="#building-iso-files">Building ISO files</a></h3>
<p>To build Garuda ISO, one needs to connect to the <code>iso-runner</code> container and execute the <code>buildiso</code> command, which opens a shell containing the needed environment:</p>
<pre><code class="language-sh">ssh -p 227 $user@116.202.208.112 # if one ran nix develop before, this can be skipped
buildiso
buildiso -i # updates the iso-profiles repo
buildiso -p dr460nized
</code></pre>
<p>Further information on available commands can be found in the <a href="https://gitlab.com/garuda-linux/tools/garuda-tools">garuda-tools</a> repository.
After the build process is finished, builds can be found on <a href="https://iso.builds.garudalinux.org/iso/garuda/">iso.builds.garudalinux.org</a> - no automatic pushing to Sourceforge and Cloudflare R2 happens by default, see below for more information on how to achieve this.</p>
<h3 id="deploying-a-new-iso-release"><a class="header" href="#deploying-a-new-iso-release">Deploying a new ISO release</a></h3>
<p>We are assuming all ISOs have been tested for functionality before executing any of those commands.</p>
<pre><code class="language-sh">ssh -p 227 $user@116.202.208.112
build all # builds all ISO provided in the buildall command
deployiso -FS # sync to Cloudflare R2 and Sourceforge
deployiso -FSR # sync to Cloudflare R2 and Sourceforge while also updating the latest (stable, non-nightly) release
deployiso -Sd # to delete the old ISOs on Sourceforge once they aren't needed anymore
deployiso -FSRd # oneliner for the above-given commands
</code></pre>
<h3 id="updating-the-system"><a class="header" href="#updating-the-system">Updating the system</a></h3>
<p>One needs to have the <a href="https://gitlab.com/garuda-linux/infra-nix">infra-nix</a> repo cloned locally. Then proceed by updating the <code>flake.lock</code> file, pushing it to the server &amp; building the configurations:</p>
<pre><code class="language-sh">nix flake update
ansible-playbook garuda.yml -l $servername # Eg. immortalis for the Hetzner host
deploy # Skip using the above command and use this one in case nix develop was used
</code></pre>
<p>Then you can either apply it via Ansible or connect to the host to view more details about the process while it runs:</p>
<pre><code class="language-sh">ansible-playbook apply.yml -l $servername # Ansible

apply # Nix develop shell

ssh -p 666 $user@116.202.208.112 # Manually, exemplary on immortalis
sudo nixos-rebuild switch
</code></pre>
<p>Keep in mind that this will restart every service whose files changed since the last system update. On our Hetzner server, this includes a restart of every declarative <code>nixos-container</code> if needed, causing a small downtime.</p>
<h3 id="changing-system-configurations"><a class="header" href="#changing-system-configurations">Changing system configurations</a></h3>
<p>Most system configurations are contained in individual Nix files in the <code>nix</code> directory of this repo. This means changing anything must not be done manually but by editing the corresponding file and pushing/applying the configuration afterward.</p>
<pre><code class="language-sh">ansible-playbook garuda.yml -l $servername # Eg. immortalis for the Hetzner host
deploy # In case nix develop is used
</code></pre>
<p>As with the system update, one can either apply via Ansible or manually:</p>
<pre><code class="language-sh">ansible-playbook apply.yml -l $servername # Ansible

apply # Nix develop shell

ssh -p 666 $user@116.202.208.112 # Manually, exemplary on immortalis
sudo nixos-rebuild switch
</code></pre>
<h4 id="adding-a-user"><a class="header" href="#adding-a-user">Adding a user</a></h4>
<p>Adding users needs to be done in <code>users.nix</code>:</p>
<ul>
<li>Add a new user <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/modules/users.nix?ref_type=heads#L14">here</a></li>
<li>Add the SSH public key to <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/flake.nix?ref_type=heads#L43">flake inputs</a></li>
<li>Add the specialArgs <code>keys.user</code> as seen <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/flake-module.nix?ref_type=heads#L38">here</a></li>
<li>Deploy &amp; apply the configuration</li>
</ul>
<h3 id="changing-docker-configurations"><a class="header" href="#changing-docker-configurations">Changing Docker configurations</a></h3>
<p>If configurations of services running in Docker containers need to be altered, one needs to edit the corresponding <code>docker-compose.yml</code> (<code>./nix/docker-compose/$name</code>) file or <code>.env</code> file in the <code>secrets</code> directory (see the secrets section for details on that topic). The deployment is done the same way as with normal system configuration.</p>
<h3 id="updating-docker-containers"><a class="header" href="#updating-docker-containers">Updating Docker containers</a></h3>
<p>Docker containers sometimes use the <code>latest</code> tag in case no current tag is available or in the case of services like Piped and Searx, where it is often crucial to have the latest build to bypass Google's restrictions. Containers using the <code>latest</code> tag are automatically updated via <a href="https://containrrr.dev/watchtower/">watchtower</a> daily. The remaining ones can be updated by changing their version in the corresponding <code>docker-compose.yml</code> and then running <code>deploy</code> &amp; <code>apply</code>. If containers are to be updated manually, this can be achieved by connecting to the host, running <code>nixos-container root-login $containername</code>, and executing:</p>
<pre><code class="language-sh">cd /var/garuda/docker-compose-runner/$name/ # replace $name with the actual docker-compose.yml or autocomplete via tab
sudo docker compose pull
sudo docker compose up -d
</code></pre>
<p>The updated containers will be pulled and automatically recreated using the new images.</p>
<h3 id="rotating-ipv6"><a class="header" href="#rotating-ipv6">Rotating IPv6</a></h3>
<p>Sometimes it is needed to rotate the available IPv6 addresses to solve the current ones being rate-limited for outgoing requests of Piped, Searx, etc. This can be achieved by editing the hosts Nix file <code>immortalis.nix</code>, replacing the existing values of the <code>networking.interfaces.&quot;eth0&quot;.ipv6.addresses</code> keys seen <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/hosts/immortalis.nix?ref_type=heads#L30">here</a>. Then, proceed doing the same with the <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/hosts/immortalis.nix?ref_type=heads#L219">squid configuration</a>:</p>
<p>. Possible IPv6 addresses need to be generated from our available /64 subnet space and can't be chosen completely random.</p>
<h3 id="checking-whether-backups-were-successful"><a class="header" href="#checking-whether-backups-were-successful">Checking whether backups were successful</a></h3>
<p>To check whether backups to Hetzner are still working as expected, connect to the server and execute the following:</p>
<pre><code class="language-sh">systemctl status borgbackup-job-backupToHetzner
</code></pre>
<p>This should yield a successful unit state. The only exception is having an exit code != <code>0</code> due to files having changed during the run.</p>
<h3 id="updating-the-website-content-or-chaotic-aur-toolbox"><a class="header" href="#updating-the-website-content-or-chaotic-aur-toolbox">Updating the website content or Chaotic-AUR toolbox</a></h3>
<p>This needs to be done by updating the flake input (git repo URL of the website) <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nix/flake.nix?ref_type=heads#L60">src-garuda-website</a> or <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nix/flake.nix?ref_type=heads#L44">src-chaotic-toolbox</a>:</p>
<pre><code class="language-sh">cd nix
nix flake lock --update-input src-garuda-website # website
nix flake lock --update-input src-chaotic-toolbox # toolbox
</code></pre>
<p>After that deploy as usual by running <code>deploy</code> and <code>apply</code>. The commit and corresponding hash will be updated and NixOS will use it to build the website or toolbox using the new revision automatically.</p>
<h3 id="updating-the-garuda-startpage-content"><a class="header" href="#updating-the-garuda-startpage-content">Updating the Garuda startpage content</a></h3>
<p>Our startpage consists of a simple <a href="https://github.com/bastienwirtz/homer">homer</a> deployment. Its configuration is stored in the <a href="https://gitlab.com/garuda-linux/website/startpage">startpage</a> repo, which gets cloned to the docker-compose.yml's directory to serve the files. In order, updating is currently done manually after pushing the changes to the repo (might automate this soon via systemd timer!):</p>
<pre><code class="language-sh">ssh -p 225 $user@116.202.208.112
cd /var/garuda/docker-compose-runner/all-in-one/startpage
git pull
sudo docker restart homer
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="important-links"><a class="header" href="#important-links">Important links</a></h1>
<p>This is a collection of important links when working with the infrastructure:</p>
<h2 id="most-important"><a class="header" href="#most-important">Most important</a></h2>
<ul>
<li><a href="https://github.com/garuda-linux/infrastructure-nix">The infrastructure-nix repository</a></li>
</ul>
<h2 id="nix-related"><a class="header" href="#nix-related">Nix-related</a></h2>
<ul>
<li><a href="https://numtide.github.io/devshell/">Devshell documentation</a></li>
<li><a href="https://flake.parts">Flake-parts documentation</a>
<ul>
<li><a href="https://flake.parts/options/pre-commit-hooks-nix">Pre-commit-hooks flake-module</a></li>
</ul>
</li>
<li><a href="https://mipmip.github.io/home-manager-option-search/">Home Manager options search</a></li>
<li><a href="https://nixos-mailserver.readthedocs.io/en/latest/setup-guide.html">NixOS mailserver documentation</a></li>
<li><a href="https://nixos.org/manual/nixos/stable/">The Nix documentation</a></li>
<li><a href="https://search.nixos.org">The Nix package and option search</a></li>
</ul>
<h2 id="tools-documentation"><a class="header" href="#tools-documentation">Tools documentation</a></h2>
<ul>
<li><a href="https://github.com/chaotic-aur/toolbox">Chaotic toolbox</a></li>
<li><a href="https://github.com/rust-lang/mdBook">mdBook</a></li>
</ul>
<h2 id="web-interfaces"><a class="header" href="#web-interfaces">Web interfaces</a></h2>
<ul>
<li><a href="https://syncthing-build.garudalinux.net/">Chaotic-AUR Syncthing</a></li>
<li><a href="https://dash.cloudflare.com">Cloudflare Dashboard</a></li>
<li><a href="https://garudalinux.freshping.io/">Freshping</a></li>
<li><a href="https://garudalinux.freshstatus.io/admin/incidents/public">Freshstatus</a></li>
<li><a href="https://accounts.hetzner.com/">Hetzner Robot</a></li>
<li><a href="https://matrixadmin.garudalinux.net">Matrix Admin</a></li>
<li><a href="https://mesh.garudalinux.net">Meshcentral</a></li>
<li><a href="https://app.netdata.cloud">Netdata</a></li>
<li><a href="https://developer.mend.io/github/garuda-linux">Renovate Dashboard</a></li>
<li><a href="https://login.tailscale.com/">Tailscale</a></li>
</ul>
<h2 id="services-to-be-administrated"><a class="header" href="#services-to-be-administrated">Services to be administrated</a></h2>
<ul>
<li><a href="https://vault.garudalinux.org">Bitwarden</a></li>
<li><a href="https://forum.garudalinux.org">Discourse</a></li>
<li><a href="https://aur.chaotic.cx">Chaotic-AUR</a></li>
<li><a href="https://element.garudalinux.org">Element</a></li>
<li><a href="https://ffsync.garudalinux.org">Firefox syncserver</a></li>
<li><a href="https://invidious.garudalinux.org">Invidious</a></li>
<li><a href="https://lemmy.garudalinux.org">Lemmy</a></li>
<li><a href="https://lingva.garudalinux.org">Lingva</a></li>
<li><a href="https://social.garudalinux.org">Mastodon</a></li>
<li><a href="https://matrix.garudalinux.org">Matrix</a></li>
<li>Matrix Discord bridge (internal only)</li>
<li>Matrix IRC bridge (internal only)</li>
<li>Matrix Telegram bridge (internal only)</li>
<li><a href="https://cloud.garudalinux.org">Nextcloud</a></li>
<li><a href="https://piped.garudalinux.org">Piped</a></li>
<li><a href="https://bin.garudalinux.org">PrivateBin</a></li>
<li><a href="https://searx.garudalinux.org">Searx</a></li>
<li><a href="https://irc.garudalinux.org">TheLounge</a></li>
<li><a href="https://search.garudalinux.org">Whoogle</a></li>
<li><a href="https://wiki.garudalinux.org">WikiJs</a></li>
</ul>
<h2 id="additional-pages"><a class="header" href="#additional-pages">Additional pages</a></h2>
<ul>
<li><a href="https://start.garudalinux.org">Startpage</a></li>
<li><a href="https://garudalinux.org">Website</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h2 id="immortalis-hetzner-dedicated"><a class="header" href="#immortalis-hetzner-dedicated">immortalis (Hetzner dedicated)</a></h2>
<h3 id="general"><a class="header" href="#general">General</a></h3>
<p>This system utilizes a NixOS host which uses <a href="https://nixos.wiki/wiki/NixOS_Containers">nixos-containers</a> to build declarative <code>systemd-nspawn</code> machines for different purposes. To make the best use of the available resources, common directories are shared between containers. This includes <code>/home</code> (home-manager / NixOS configurations writing to home are generated by the host and disabled for the containers), Pacman and Chaotic cache, the <code>/nix</code> directory, and a few others. Further details can be found in the <a href="hhttps://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/hosts/immortalis/containers.nix">Nix expression</a> of the host.</p>
<p>All directories containing important data were mapped to <code>/data_1</code> and <code>/data_2</code> to have them all in one place. The first mostly contains web services' files, the latter only builds related directories such as the Pacman cache.</p>
<p>The current line-up looks as follows:</p>
<pre><code class="language-sh">nico@immortalis ~ (main)&gt; machinectl
MACHINE        CLASS     SERVICE        OS    VERSION ADDRESSES
chaotic-kde    container systemd-nspawn nixos 23.11   10.0.5.90
docker         container systemd-nspawn nixos 23.11   10.0.5.100
docker-proxied container systemd-nspawn nixos 23.11   10.0.5.110
forum          container systemd-nspawn nixos 23.11   10.0.5.70
github-runner  container systemd-nspawn nixos 23.11   10.0.5.130
iso-runner     container systemd-nspawn nixos 23.11   10.0.5.40
lemmy          container systemd-nspawn nixos 23.11   10.0.5.120
mastodon       container systemd-nspawn nixos 23.11   10.0.5.80
meshcentral    container systemd-nspawn nixos 23.11   10.0.5.60
postgres       container systemd-nspawn nixos 23.11   10.0.5.50
repo           container systemd-nspawn nixos 23.11   10.0.5.30
temeraire      container systemd-nspawn nixos 23.11   10.0.5.20
web-front      container systemd-nspawn nixos 23.11   10.0.5.10
</code></pre>
<p>We are seeing:</p>
<ul>
<li>1 ISO builder (<code>iso-runner</code>)</li>
<li>1 reverse proxy serving all the websites and services (<code>web-front</code>)</li>
<li>2 Docker dedicated nspawn containers (<code>docker</code> &amp; <code>docker-proxied</code>)</li>
<li>4 Chaotic-AUR builders (<code>chaotic-kde</code>, <code>github-runner</code>, <code>repo</code> &amp; <code>temeraire</code>)</li>
<li>5 app dedicated containers (<code>forum</code>, <code>lemmy</code>, <code>mastodon</code>, <code>meshcentral</code> &amp; <code>postgres</code>)</li>
</ul>
<h3 id="connecting-to-the-server"><a class="header" href="#connecting-to-the-server">Connecting to the server</a></h3>
<p>After connecting to the host via <code>ssh -p 666 $user@116.202.208.112</code>, containers can generally be entered by running <code>nixos-container login $containername</code>, eg. <code>nixos-container login web-front</code>. Some containers may also be connected via SSH using the following ports:</p>
<ul>
<li>22: <code>temeraire</code> (needs to be 22 to allow pushing packages to the main Chaotic-AUR node via rsync)</li>
<li>223: <code>repo</code></li>
<li>224: <code>forum</code></li>
<li>225: <code>docker</code></li>
<li>226: <code>chaotic-kde</code></li>
<li>227: <code>iso-runner</code></li>
<li>228: <code>web-front</code></li>
<li>229: <code>postgres</code> (access the database in <code>127.0.0.1</code> via <code>ssh -p 229 nico@116.202.208.112 -L 5432:127.0.0.1:5432</code>)</li>
</ul>
<h3 id="docker-containers"><a class="header" href="#docker-containers">Docker containers</a></h3>
<p>Some services not packaged in NixOS or are easier to deploy this way are serviced via the Docker engine. This contains services like Piped, Whoogle, and Matrix. We use a custom <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nix/garuda/services/docker-compose-runner/docker-compose-runner.nix?ref_type=heads">NixOS module</a> to deploy those with the rest of the system. Secrets are handled via our secret management which consists of a git submodule <code>secret</code> (private repo with <code>ansible-vault</code> encrypted files) and <code>garuda-lib</code> (see secrets section). Those contain a <code>docker-compose</code> directory in which the <code>.env</code> files for the <code>docker-compose.yml</code> are stored.</p>
<h3 id="chaotic-aur--repository"><a class="header" href="#chaotic-aur--repository">Chaotic-AUR / repository</a></h3>
<p>Our repository leverages <a href="https://aur.chaotic.cx">Chaotic-AUR's</a> <a href="https://github.com/chaotic-aur/toolbox">toolbox</a> to provide the main node for the <code>[chaotic-aur]</code> repository as well as two more instances building the <code>[garuda]</code> and <code>[chaotic-kde]</code> repositories. Users of the <code>chaotic_op</code> group may build packages on the corresponding nixos-container via the <a href="https://github.com/chaotic-aur/toolbox/blob/main/README.md">chaotic</a> command:</p>
<pre><code class="language-sh">chaotic get $package # pull PKGBUILD
chaotic mkd $package # build package in the previously cloned directory
chaotic bump $package # increment pkgver of $package by 0.1 to allow a rebuild
chaotic rm $package # remove the package from the repository
</code></pre>
<p>Further information may be obtained by clicking <code>chaotic</code> seen above. The corresponding builders are:</p>
<ul>
<li><code>[chaotic-aur]</code>: <code>temeraire</code></li>
<li><code>[garuda]</code>: <code>repo</code></li>
<li><code>[chaotic-kde]</code>: <code>chaotic-kde</code></li>
</ul>
<h3 id="squid-proxy"><a class="header" href="#squid-proxy">Squid proxy</a></h3>
<p>Squid is being installed on the host machine to proxy outgoing requests via random IPv6 addresses of the /64 subnet Hetzner provides for services that need it, eg. Piped, the Chaotic-AUR builders, and other services that are getting rate limited quickly. The process is not entirely automated, which means that we currently have a pool of IPv6 addresses active and need to switch them whenever those are getting rate-limited again.
Since we supplied an invalid IPv4 to force outgoing IPv6, the log files were somewhat cluttered by (expected) errors. Systemd-unit logging has been set to <code>LogLevelMax=1</code> to un-clutter the journal and needs to be increased again if debugging needs to be done.</p>
<h3 id="backups"><a class="header" href="#backups">Backups</a></h3>
<p>Backups are provided by daily Borg runs. Only the <code>/data_1</code> directory is backed up (minus <code>/data_1/{dockercache,dockerdata}</code>) as the rest are either Nix-generated or build-related files that can easily recovered from another repository mirror. The corresponding systemd-unit is named <code>borgbackup-job-backupToHetzner</code>.</p>
<h3 id="tailscale--mesh-network"><a class="header" href="#tailscale--mesh-network">Tailscale / mesh network</a></h3>
<p>While Tailscale was commonly used to connect multiple VMs before, this server only has it active on the host. However, we are leveraging Tailscale's <a href="https://tailscale.com/kb/1019/subnets/">subnet router</a> feature to serve the <code>10.0.5.0/24</code> subnet via Tailscale, which means that other Tailscale clients may access the <code>nixos-containers</code> via their IP if <code>tailscale up --accept-routes</code> was used to set up the service.</p>
<h3 id="nix-expression"><a class="header" href="#nix-expression">Nix expression</a></h3>
<pre><code class="language-nix">{ garuda-lib
, pkgs
, ...
}: {
  imports = [
    ../modules
    ./immortalis/containers.nix
    ./immortalis/hardware-configuration.nix
  ];

  # Increase /tmp &amp; /run size to make better use of RAM
  boot = {
    kernelPackages = pkgs.linuxPackages_latest;
    loader.systemd-boot.enable = true;
    runSize = &quot;50%&quot;;
    tmp = {
      tmpfsSize = &quot;95%&quot;;
      useTmpfs = true;
    };
  };

  # Network configuration with a bridge interface
  networking = {
    defaultGateway = &quot;116.202.208.65&quot;;
    defaultGateway6 = {
      address = &quot;fe80::1&quot;;
      interface = &quot;eth0&quot;;
    };
    hostName = &quot;immortalis&quot;;
    interfaces = {
      &quot;eth0&quot; = {
        ipv4.addresses = [{
          address = &quot;116.202.208.112&quot;;
          prefixLength = 26;
        }];
        ipv6.addresses = [
          # Random outgoing
          {
            address = &quot;2a01:4f8:2200:30ac:8bc3:87ca:7eb3:1445&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:b3e8:3e97:b9ea:4f4c&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:3139:1040:65d2:f055&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:1c69:9c53:0801:c089&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:43ca:4c70:b3af:0713&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:c164:d4da:d822:b5c0&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:33ab:784a:d947:6fe1&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:370c:1719:6265:3137&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:c9c3:b7f6:fcc3:304e&quot;;
            prefixLength = 64;
          }
          {
            address = &quot;2a01:4f8:2200:30ac:5c1b:cfd5:7c0e:f2e5&quot;;
            prefixLength = 64;
          }
        ];
      };
    };
    # Specify these here to allow containers to access
    # our services from the internal network via NAT reflection
    nat.forwardPorts = [
      {
        destination = &quot;10.0.5.10:80&quot;;
        loopbackIPs = [ &quot;116.202.208.112&quot; ];
        proto = &quot;tcp&quot;;
        sourcePort = 80;
      }
      {
        destination = &quot;10.0.5.10:443&quot;;
        loopbackIPs = [ &quot;116.202.208.112&quot; ];
        proto = &quot;tcp&quot;;
        sourcePort = 443;
      }
      {
        destination = &quot;10.0.5.10:443&quot;;
        loopbackIPs = [ &quot;116.202.208.112&quot; ];
        proto = &quot;udp&quot;;
        sourcePort = 443;
      }
      {
        destination = &quot;10.0.5.10:8448&quot;;
        loopbackIPs = [ &quot;116.202.208.112&quot; ];
        proto = &quot;tcp&quot;;
        sourcePort = 8448;
      }
    ];
    firewall.trustedInterfaces = [ &quot;br0&quot; ];
  };

  # OpenSSH on another port to keep Chaotic's main node working
  services.openssh.ports = [ 666 ];

  # Make use of all threads!
  security.allowSimultaneousMultithreading = true;

  # Raise limits to support many containers 
  # (from LXC's recommendedSysctlSettings)
  boot.kernel.sysctl = {
    &quot;fs.inotify.max_user_instances&quot; = 1048576;
    &quot;fs.inotify.max_user_watches&quot; = 1048576;
    &quot;kernel.dmesg_restrict&quot; = 1;
    &quot;kernel.keys.maxkeys&quot; = 2000;
    &quot;kernel.pid_max&quot; = 4194303;
    &quot;net.ipv4.neigh.default.gc_thresh3&quot; = 8192;
    &quot;net.ipv6.neigh.default.gc_thresh3&quot; = 8192;
  };

  # Improve nspawn container performance since we grant all capabilities anyway
  # https://github.com/systemd/systemd/issues/18370#issuecomment-768645418
  environment.variables.SYSTEMD_SECCOMP = &quot;0&quot;;

  # Custom tailscale configuration to advertise our bridge's subnet route
  systemd.services.tailscale-autoconnect.script = with pkgs; ''
    sleep 2
    status=&quot;$(${tailscale}/bin/tailscale status -json | ${jq}/bin/jq -r .BackendState)&quot;
    if [ $status = &quot;Running&quot; ]; then
      exit 0
    fi
    ${tailscale}/bin/tailscale up --authkey ${garuda-lib.secrets.tailscale.authkey} \
      --advertise-routes=10.0.5.0/24
  '';

  # We want to have same UID's in all containers to allow sharing home directories
  garuda-lib.unifiedUID = true;

  # Monitor a few services of the containers
  services = {
    netdata.configDir = {
      &quot;go.d/postgres.conf&quot; = pkgs.writeText &quot;postgres.conf&quot; ''
        jobs:
          - name: postgres
            dsn: 'postgres://netdata:netdata@10.0.5.50:5432/'
      '';
      &quot;go.d/squidlog.conf&quot; = pkgs.writeText &quot;squidlog.conf&quot; ''
        jobs:
          - name: squid
            path: /var/log/squid/access.log
            log_type: csv
            csv_config:
              format: '- resp_time client_address result_code resp_size req_method - - hierarchy mime_type'
      '';
      &quot;go.d/web_log.conf&quot; = pkgs.writeText &quot;web_log.conf&quot; ''
        jobs:
          - name: nginx
            path: /var/log/nginx/access.log
      '';
    };
    smartd = {
      enable = true;
      extraOptions = [ &quot;-A /var/log/smartd/&quot; &quot;--interval=600&quot; ];
    };
  };

  # Backup configurations to Hetzner storage box
  programs.ssh.macs = [ &quot;hmac-sha2-512&quot; ];
  services.borgbackup.jobs = {
    backupToHetzner = {
      compression = &quot;auto,zstd&quot;;
      doInit = true;
      encryption = {
        mode = &quot;repokey-blake2&quot;;
        passCommand = &quot;cat /var/garuda/secrets/backup/repo_key&quot;;
      };
      environment = {
        BORG_RSH = &quot;ssh -i /var/garuda/secrets/backup/ssh_immortalis -p 23&quot;;
      };
      exclude = [ &quot;/data_1/dockercache&quot; &quot;/data_1/dockerdata&quot; ];
      paths = [ &quot;/data_1&quot; ];
      prune.keep = {
        within = &quot;1d&quot;;
        daily = 3;
        weekly = 2;
        monthly = 2;
      };
      repo = &quot;u342919@u342919.your-storagebox.de:./immortalis&quot;;
      startAt = &quot;daily&quot;;
    };
  };

  # A proxy server making use of our IPv6 IP addresses
  # traffic sent through the proxy is only allowing IPv6 connections
  services.squid = {
    enable = true;
    extraConfig = ''
      forwarded_for delete
      dns_nameservers 2606:4700:4700::1111

      acl tenth random 1/10
      acl ninth random 1/9
      acl eighth random 1/8
      acl seventh random 1/7
      acl sixth random 1/6
      acl fifth random 1/5
      acl fourth random 1/4
      acl third random 1/3
      acl half random 1/2

      # Invalid IP
      tcp_outgoing_address 10.254.254.254
      tcp_outgoing_address 2a01:4f8:2200:30ac:8bc3:87ca:7eb3:1445 tenth
      tcp_outgoing_address 2a01:4f8:2200:30ac:b3e8:3e97:b9ea:4f4c ninth
      tcp_outgoing_address 2a01:4f8:2200:30ac:3139:1040:65d2:f055 eighth
      tcp_outgoing_address 2a01:4f8:2200:30ac:1c69:9c53:0801:c089 seventh
      tcp_outgoing_address 2a01:4f8:2200:30ac:43ca:4c70:b3af:0713 sixth
      tcp_outgoing_address 2a01:4f8:2200:30ac:c164:d4da:d822:b5c0 fifth
      tcp_outgoing_address 2a01:4f8:2200:30ac:33ab:784a:d947:6fe1 fourth
      tcp_outgoing_address 2a01:4f8:2200:30ac:370c:1719:6265:3137 third
      tcp_outgoing_address 2a01:4f8:2200:30ac:c9c3:b7f6:fcc3:304e half
      tcp_outgoing_address 2a01:4f8:2200:30ac:5c1b:cfd5:7c0e:f2e5

      # Invalid IP
      udp_outgoing_address 10.254.254.254
      udp_outgoing_address 2a01:4f8:2200:30ac:8bc3:87ca:7eb3:1445 tenth
      udp_outgoing_address 2a01:4f8:2200:30ac:b3e8:3e97:b9ea:4f4c ninth
      udp_outgoing_address 2a01:4f8:2200:30ac:3139:1040:65d2:f055 eighth
      udp_outgoing_address 2a01:4f8:2200:30ac:1c69:9c53:0801:c089 seventh
      udp_outgoing_address 2a01:4f8:2200:30ac:43ca:4c70:b3af:0713 sixth
      udp_outgoing_address 2a01:4f8:2200:30ac:c164:d4da:d822:b5c0 fifth
      udp_outgoing_address 2a01:4f8:2200:30ac:33ab:784a:d947:6fe1 fourth
      udp_outgoing_address 2a01:4f8:2200:30ac:370c:1719:6265:3137 third
      udp_outgoing_address 2a01:4f8:2200:30ac:c9c3:b7f6:fcc3:304e half
      udp_outgoing_address 2a01:4f8:2200:30ac:5c1b:cfd5:7c0e:f2e5
    '';
    proxyAddress = &quot;10.0.5.1&quot;;
  };
  # Shut off all logging but level 1 errors as we get spamming a lot due to
  # not being able to use our invalid address 10.254.254.254
  systemd.services.squid.serviceConfig.LogLevelMax = 1;

  # Adapt Nix to our core-count
  nix.settings.max-jobs = 8;

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="chaotic-kde"><a class="header" href="#chaotic-kde">chaotic-kde</a></h1>
<h2 id="general-1"><a class="header" href="#general-1">General</a></h2>
<p>This is a package builder, that is supposed to build a KDE stack from master branch. It is still unused while packages are waiting to be fixed.</p>
<h2 id="nix-expression-1"><a class="header" href="#nix-expression-1">Nix expression</a></h2>
<pre><code class="language-nix">{ pkgs
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # Enable Chaotic-AUR building
  services.chaotic.enable = true;
  services.chaotic.cluster-name = &quot;kde-git&quot;;
  services.chaotic.host = &quot;kde-git.chaotic.cx&quot;;
  services.chaotic.extraConfig = ''
    export CAUR_DEPLOY_LABEL=&quot;KDE Dragon 🐉&quot;
    export CAUR_LOWER_PKGS+=(chaotic-mirrorlist chaotic-keyring git qt6-declarative qt6-tools qt6-doc clang doxygen qt6-declarative)
    export CAUR_PACKAGER=&quot;Garuda Builder &lt;team@garudalinux.org&gt;&quot;
    export CAUR_ROUTINES=/tmp/chaotic/routines
    export CAUR_SIGN_KEY=D6C9442437365605
    export CAUR_SIGN_USER=root
    export CAUR_TELEGRAM_TAG=&quot;@dr460nf1r3&quot;

    export GIT_SSH_COMMAND=&quot;ssh -i /var/garuda/secrets/chaotic/interfere_ed25519&quot;
    export HTTP_PROXY=http://10.0.5.1:3128/
    export HTTPS_PROXY=http://10.0.5.1:3128/
    export NO_PROXY=mirror.rackspace.com,cloudflaremirrors.com,github.com,downloads.sentry-cdn.com
  '';
  services.chaotic.db-name = &quot;chaotic-aur-kde&quot;;
  services.chaotic.routines = [ &quot;hourly&quot; &quot;nightly&quot; &quot;afternoon&quot; ];
  services.chaotic.patches = [ ../services/chaotic/add-chaotic-repo.diff ../services/chaotic/prepend-repo.diff ];
  services.chaotic.useACMEHost = &quot;garudalinux.org&quot;;

  # Allow systemd-nspawn to create subcgroups (for Chaotic-AUR builders)
  systemd.services.remount-sysfscgroup = {
    description = &quot;Remount cgroup2 to allow systemd-nspawn to create subcgroups&quot;;
    wantedBy = [ &quot;multi-user.target&quot; ];
    serviceConfig.Type = &quot;oneshot&quot;;
    script = ''
      ${pkgs.mount}/bin/mount -t cgroup2 -o rw,nosuid,nodev,noexec,relatime none /sys/fs/cgroup
    '';
  };

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker-proxied"><a class="header" href="#docker-proxied">docker-proxied</a></h1>
<h2 id="general-2"><a class="header" href="#general-2">General</a></h2>
<p>Here, all of the Docker containers that need to have proxied outgoing requests are being deployed.</p>
<h2 id="nix-expression-2"><a class="header" href="#nix-expression-2">Nix expression</a></h2>
<pre><code class="language-nix">{ garuda-lib
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # This container runs proxied docker containers
  services.docker-compose-runner.proxied = {
    envfile = garuda-lib.secrets.docker-compose.proxied;
    source = ../../docker-compose/proxied;
  };

  # Let Docker use squid as outgoig proxy
  # Fails to pull images if *.docker.io is not excluded from proxy
  systemd.services.docker = {
    environment = {
      HTTPS_PROXY = &quot;http://10.0.5.1:3128&quot;;
      HTTP_PROXY = &quot;http://10.0.5.1:3128&quot;;
      NO_PROXY = &quot;localhost,127.0.0.1,*.docker.io&quot;;
    };
  };

  system.stateVersion = &quot;23.05&quot;;
}
</code></pre>
<h2 id="docker-compose"><a class="header" href="#docker-compose">Docker compose</a></h2>
<pre><code class="language-yaml">---
version: &quot;3.9&quot;
services:
  # Whoogle search engine
  whoogle:
    image: benbusby/whoogle-search:latest # It tends do be important to stay current
    container_name: whoogle
    user: whoogle
    security_opt: [no-new-privileges]
    cap_drop: [ALL]
    tmpfs:
      - /var/lib/tor/:size=10M,uid=927,gid=927,mode=1700
      - /run/tor/:size=1M,uid=927,gid=927,mode=1700
    volumes: [./whoogle:/config]
    ports: [5000:5000]
    environment:
      WHOOGLE_AUTOCOMPLETE: 1
      WHOOGLE_CONFIG_LANGUAGE: lang_en
      WHOOGLE_CONFIG_NEW_TAB: 1
      WHOOGLE_CONFIG_SEARCH_LANGUAGE: lang_en
      WHOOGLE_CONFIG_STYLE: :root{--whoogle-logo:#c4a7e7;--whoogle-page-bg:#faf4ed;--whoogle-element-bg:#f2e9e1;--whoogle-text:#575279;--whoogle-contrast-text:#1f1d2e;--whoogle-secondary-text:#797593;--whoogle-result-bg:#faf4ed;--whoogle-result-title:#d7827e;--whoogle-result-url:#286983;--whoogle-result-visited:#907aa9;--whoogle-dark-logo:#c4a7e7;--whoogle-dark-page-bg:#191724;--whoogle-dark-element-bg:#1f1d2e;--whoogle-dark-text:#e0def4;--whoogle-dark-contrast-text:#e0def4;--whoogle-dark-secondary-text:#908caa;--whoogle-dark-result-bg:#393552;--whoogle-dark-result-title:#9ccfd8;--whoogle-dark-result-url:#3e8fb0;--whoogle-dark-result-visited:#c4a7e7}#whoogle-w{fill:#eb6f92}#whoogle-h{fill:#f6c177}#whoogle-o-1{fill:#ebbcba}#whoogle-o-2{fill:#31748f}#whoogle-g{fill:#9ccfd8}#whoogle-l{fill:#c4a7e7}#whoogle-e{fill:#908caa}
      WHOOGLE_CONFIG_THEME: dark
      WHOOGLE_CONFIG_URL: https://search.garudalinux.org
      WHOOGLE_CONFIG_VIEW_IMAGE: 1
      WHOOGLE_RESULTS_PER_PAGE: 15
    pids_limit: 50
    restart: always

  # Searxng search engine
  searx:
    image: searxng/searxng:latest # It tends do be important to stay current
    container_name: searx
    volumes: [./searxng:/etc/searxng]
    ports: [8080:8080]
    environment:
      BASE_URL: https://searx.garudalinux.org/
      BIND_ADDRESS: 0.0.0.0:8080
      HTTPS_PROXY: http://10.0.5.1:3128
      HTTP_PROXY: http://10.0.5.1:3128
      INSTANCE_NAME: Garuda's SearxNG
      NO_PROXY: &quot;*.garudalinux.org&quot;
    cap_drop: [ALL]
    cap_add: [CHOWN, SETGID, SETUID, DAC_OVERRIDE]
    restart: always

  # Lingva
  lingva:
    image: thedaviddelta/lingva-translate:latest # Only latest tag is available
    container_name: lingva
    environment:
      DARK_THEME: &quot;true&quot;
      DEFAULT_SOURCE_LANG: auto
      DEFAULT_TARGET_LANG: en
      HTTP_PROXY: http://10.0.5.1:3128
      HTTPS_PROXY: http://10.0.5.1:3128
      SITE_DOMAIN: lingva.garudalinux.org
    ports: [3002:3000]
    restart: always

  # Invious YouTube frontend
  invidious:
    image: quay.io/invidious/invidious:latest # It tends do be important to stay current
    container_name: invidious
    depends_on: [invidious_db]
    environment:
      HTTP_PROXY: http://10.0.5.1:3128
      HTTPS_PROXY: http://10.0.5.1:3128
      INVIDIOUS_CONFIG: |
        db:
          dbname: invidious
          user: kemal
          password: ${INVIDIOUS_DB_PASSWORD:?err}
          host: invidious_db
          port: 5432
        check_tables: true
        default_user_preferences:
          local: true
          quality: dash
        admins: [&quot;nico&quot;]
        captcha_key: ${INVIDIOUS_CAPTCHA_KEY:?err}
        disable_proxy: [&quot;livestreams&quot;,&quot;downloads&quot;]
        domain: invidious.garudalinux.org
        external_port: 443
        hmac_key: ${INVIDIOUS_HMAC_KEY:?err}
        https_only: true
        popular_enabled: true
        statistics_enabled: true
        use_pubsub_feeds: true
        use_quic: true
      NO_PROXY: &quot;*.lbry.com&quot;
    ports: [3003:3000]
    healthcheck:
      test:
        wget -nv --tries=1 --spider http://10.0.5.20:3003/api/v1/comments/jNQXAC9IVRw
        || exit 1
      interval: 30s
      timeout: 5s
      retries: 2
    restart: always
  invidious_db:
    image: docker.io/library/postgres:14.9
    container_name: invidious_db
    volumes:
      - ./invidious/db:/var/lib/postgresql/data
      - ./invidious/config:/config/sql
      - ./invidious/init-invidious-db.sh:/docker-entrypoint-initdb.d/init-invidious-db.sh
    environment:
      POSTGRES_DB: invidious
      POSTGRES_USER: kemal
      POSTGRES_PASSWORD: ${INVIDIOUS_DB_PASSWORD:?err}
    healthcheck:
      test: [CMD-SHELL, pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB]
    restart: always

  # Piped
  piped_backend:
    image: 1337kavin/piped:latest # It tends do be important to stay current
    container_name: piped_backend
    depends_on: [piped_postgres]
    volumes: [./piped/config.properties:/app/config.properties:ro]
    environment:
      HTTP_PROXY: http://10.0.5.1:3128
      HTTPS_PROXY: http://10.0.5.1:3128
      NO_PROXY: garudalinux.org,piped-api.garudalinux.org,piped.garudalinux.org,piped-proxy.garudalinux.org,lbry.com,api.lbry.com
    restart: always
  piped_frontend:
    image: 1337kavin/piped-frontend:latest
    container_name: piped_frontend
    entrypoint:
      ash -c 'sed -i s/pipedapi.kavin.rocks/piped-api.garudalinux.org/g
      /usr/share/nginx/html/assets/* &amp;&amp; /docker-entrypoint.sh &amp;&amp; nginx -g &quot;daemon
      off;&quot;'
    environment:
      HTTP_PROXY: http://10.0.5.1:3128
      HTTPS_PROXY: http://10.0.5.1:3128
      NO_PROXY: garudalinux.org,piped-api.garudalinux.org,piped.garudalinux.org,piped-proxy.garudalinux.org,lbry.com,api.lbry.com
    depends_on: [piped_backend]
    restart: always
  piped_nginx:
    image: nginx:1.25.2-alpine
    container_name: piped_nginx
    depends_on: [piped_backend, piped_frontend, piped_proxy]
    volumes:
      - ./piped/config/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./piped/config/pipedapi.conf:/etc/nginx/conf.d/pipedapi.conf:ro
      - ./piped/config/pipedfrontend.conf:/etc/nginx/conf.d/pipedfrontend.conf:ro
      - ./piped/config/pipedproxy.conf:/etc/nginx/conf.d/pipedproxy.conf:ro
      - ./piped/config/ytproxy.conf:/etc/nginx/snippets/ytproxy.conf:ro
      - piped_proxy:/var/run/ytproxy
    ports: [8088:80]
    environment:
      HTTP_PROXY: http://10.0.5.1:3128
      HTTPS_PROXY: http://10.0.5.1:3128
      NO_PROXY: garudalinux.org,piped-api.garudalinux.org,piped.garudalinux.org,piped-proxy.garudalinux.org,lbry.com,api.lbry.com
    restart: always
  piped_postgres:
    image: postgres:13.12-alpine
    container_name: piped_postgres
    volumes: [./piped/db:/var/lib/postgresql/data]
    environment:
      POSTGRES_DB: piped
      POSTGRES_PASSWORD: ${INVIDIOUS_DB_PASSWORD:?err}
      POSTGRES_USER: piped
    restart: always
  piped_proxy:
    image: 1337kavin/piped-proxy:latest # It tends do be important to stay current
    container_name: piped_proxy
    environment:
      HTTP_PROXY: http://10.0.5.1:3128
      HTTPS_PROXY: http://10.0.5.1:3128
      NO_PROXY: garudalinux.org,piped-api.garudalinux.org,piped.garudalinux.org,piped-proxy.garudalinux.org,lbry.com,api.lbry.com
      UDS: 1
    volumes: [piped_proxy:/app/socket]
    restart: always

  # Automated container updates
  watchtower:
    image: containrrr/watchtower:1.5.3
    container_name: watchtower
    command:
      --cleanup piped_backend piped_frontend piped_proxy invidious searx lingva
      whoogle
    volumes: [/var/run/docker.sock:/var/run/docker.sock]
    restart: always
volumes:
  piped_proxy:
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="docker"><a class="header" href="#docker">docker</a></h1>
<h2 id="general-3"><a class="header" href="#general-3">General</a></h2>
<p>This container consists of our <code>docker-compose-runner</code> module, which deploys all Docker-based services that don't need to proxied outgoing requests. For the other ones, have a look <a href="nixos-containers/./docker-proxied.html">here</a>.</p>
<h2 id="nix-expression-3"><a class="header" href="#nix-expression-3">Nix expression</a></h2>
<pre><code class="language-nix">{ garuda-lib
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # This container is just for docker-compose stuff
  services.docker-compose-runner.all-in-one = {
    envfile = garuda-lib.secrets.docker-compose.all-in-one;
    source = ../../docker-compose/all-in-one;
  };

  # MongoDB port is being forwarded to this container
  networking.firewall = { allowedTCPPorts = [ 27017 ]; };

  system.stateVersion = &quot;23.05&quot;;
}
</code></pre>
<h2 id="docker-compose-1"><a class="header" href="#docker-compose-1">Docker compose</a></h2>
<pre><code class="language-yaml">---
version: &quot;3.9&quot;
services:
  # Garuda Cloud
  nextcloud_app:
    image: linuxserver/nextcloud:27.0.2
    container_name: nextcloud
    depends_on: [nextcloud_db, nextcloud_redis]
    environment:
      PUID: 1000
      PGID: 1000
      TZ: Europe/Berlin
    ports: [443:443]
    volumes: [./nextcloud/config:/config, ./nextcloud/data:/data]
    restart: always
  nextcloud_db:
    image: mariadb:11.1.2
    container_name: nextcloud_db
    command: --transaction-isolation=READ-COMMITTED --binlog-format=ROW
    environment:
      MYSQL_ROOT_PASSWORD: ${NC_ROOT_PASSWORD:-?err}
      MYSQL_PASSWORD: ${NC_PASSWORD:-?err}
      MYSQL_DATABASE: ${NC_DATABASE:-?err}
      MYSQL_USER: ${NC_USER:-?err}
    volumes: [./nextcloud/db:/var/lib/mysql]
    restart: always
  nextcloud_redis:
    image: redis:7.2.1
    container_name: nextcloud_redis
    environment:
      ALLOW_EMPTY_PASSWORD: true
    restart: always

  # Firefox syncserver
  syncserver:
    container_name: syncserver
    image: crazymax/firefox-syncserver:edge # newest, versioned one 3 years old
    volumes: [./syncserver:/data]
    ports: [5001:5000]
    environment:
      FF_SYNCSERVER_ACCESSLOG: true
      FF_SYNCSERVER_FORCE_WSGI_ENVIRON: true
      FF_SYNCSERVER_FORWARDED_ALLOW_IPS: &quot;*&quot;
      FF_SYNCSERVER_PUBLIC_URL: https://ffsync.garudalinux.org
      FF_SYNCSERVER_SECRET: ${FF_SYNCSERVER_SECRET:-?err}
      FF_SYNCSERVER_SQLURI: sqlite:////data/syncserver.db
      TZ: Europe/Berlin
    restart: always

  # Web IRC access
  thelounge:
    image: thelounge/thelounge:4.4.1
    container_name: thelounge
    volumes: [./thelounge:/var/opt/thelounge]
    ports: [9000:9000]
    restart: always

  # Password vault
  bitwarden:
    image: vaultwarden/server:1.29.2
    container_name: bitwarden
    volumes: [./bitwarden:/data]
    ports: [8081:80]
    environment:
      ADMIN_TOKEN: ${BW_ADMIN_TOKEN:-?err}
      DOMAIN: https://bitwarden.garudalinux.org
      SIGNUPS_ALLOWED: true
      SMTP_FROM: noreply@garudalinux.org
      SMTP_HOST: mail.garudalinux.org
      SMTP_PASSWORD: ${BW_SMTP_PASSWORD:-?err}
      SMTP_PORT: 587
      SMTP_SSL: false
      SMTP_USERNAME: noreply@garudalinux.org
      WEBSOCKET_ENABLED: true
      YUBICO_CLIENT_ID: ${BW_YUBICO_CLIENT_ID:-?err}
      YUBICO_SECRET_KEY: ${BW_YUBICO_ADMIN_SECRET:-?err}
    restart: always

  # Secure pastebin
  privatebin:
    image: privatebin/nginx-fpm-alpine:1.6.0
    container_name: privatebin
    volumes:
      - ./privatebin:/srv/data
      - ./configs/privatebin.cfg.php:/srv/cfg/conf.php
    ports: [8082:8080]
    restart: always

  # Garuda startpage
  homer:
    image: b4bz/homer:v23.05.1
    container_name: homer
    volumes: [./startpage:/www/assets]
    ports: [8083:8080]
    restart: always

  # MongoDB instance
  mongodb:
    image: mongo:7.0.1
    container_name: mongodb
    volumes: [./mongo:/data/db]
    ports: [27017:27017]
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USERNAME:-?err}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASSWORD:-?err}
    restart: always

  # WikiJs
  wikijs:
    image: requarks/wiki:2.5
    container_name: wikijs
    volumes: [./wikijs/assets:/wiki/assets/favicons]
    ports: [3001:3000]
    environment:
      DB_TYPE: postgres
      DB_HOST: 10.0.5.50
      DB_PORT: 5432
      DB_USER: wikijs
      DB_PASS: ${WIKIJS_DB_PASS:-?err}
      DB_NAME: wikijs
    restart: always

  # Matrix homeserver
  matrix:
    image: matrixdotorg/synapse:v1.92.1
    container_name: matrix
    volumes: [./matrix/matrix:/data]
    ports: [8008:8008]
    restart: always
  mautrix-telegram:
    image: dock.mau.dev/mautrix/telegram
    container_name: mautrix-telegram
    volumes: [./matrix/mautrix-telegram:/data]
    restart: always
    healthcheck:
      test:
        - CMD-SHELL
        - &quot;! (grep -q 'System clock is wrong, set time offset to' /tmp/debug.log &amp;&amp;\
          \ rm /tmp/debug.log &amp;&amp; kill -SIGINT 1)&quot;
      interval: 1m
      timeout: 10s

  # Matrix Discord bridge
  matrix-appservice-discord:
    image: ghcr.io/matrix-org/matrix-appservice-discord:develop
    container_name: matrix-appservice-discord
    volumes: [./matrix/matrix-appservice-discord:/data]
    restart: always

  # Matrix web client
  matrix_web:
    image: vectorim/element-web:v1.11.41
    container_name: element_web
    depends_on: [matrix]
    volumes: [./matrix/element/config.json:/app/config.json]
    ports: [8084:80]
    restart: always

  # Admin interface for Matrix
  matrix_admin:
    image: awesometechnologies/synapse-admin:latest # Versioned lags behind 7 months
    container_name: matrix_admin
    depends_on: [matrix]
    ports: [8085:80]
    restart: always

  # Matrix to IRC/Discord/Telegram relay
  matterbridge:
    image: 42wim/matterbridge:1.26
    container_name: matterbridge
    depends_on: [matrix]
    volumes:
      - ./matterbridge/matterbridge.toml:/etc/matterbridge/matterbridge.toml:ro
    restart: always

  # Makes world content available for our Lemmy instance
  lemmy_seeder:
    image: nowsci/lcs:20230901035206
    container_name: lemmy_lcs
    environment:
      COMMUNITY_COUNT: 50
      COMMUNITY_SORT_METHODS: '[ &quot;TopAll&quot;, &quot;TopDay&quot; ]'
      COMMUNITY_TYPE: All
      LOCAL_URL: https://lemmy.garudalinux.org
      LOCAL_USERNAME: ${LOCAL_USERNAME:-?err}
      LOCAL_PASSWORD: ${LOCAL_PASSWORD:-?err}
      MINUTES_BETWEEN_RUNS: 240
      NSFW: false
      POST_COUNT: 50
      REMOTE_INSTANCES:
        '[ &quot;beehaw.org&quot;, &quot;lemmy.world&quot;, &quot;lemmy.ml&quot;, &quot;sh.itjust.works&quot;,
        &quot;lemmy.one&quot; ]'
      SECONDS_AFTER_COMMUNITY_ADD: 17
    restart: unless-stopped

  # Automated container updates
  watchtower:
    image: containrrr/watchtower:1.5.3
    container_name: watchtower
    command:
      --cleanup matrix_web matrix_admin wikijs mongodb homer privatebin bitwarden
      thelounge syncserver nextcloud_app lemmy_seeder
    volumes: [/var/run/docker.sock:/var/run/docker.sock]
    restart: always
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="forum"><a class="header" href="#forum">forum</a></h1>
<h2 id="general-4"><a class="header" href="#general-4">General</a></h2>
<p>In here, we only have Docker set up and use the traditional way of installing Discourse to <code>/var/discourse</code>. Since own scripts are provided to handle the container, not much is to be seen here.</p>
<h2 id="links"><a class="header" href="#links">Links</a></h2>
<ul>
<li><a href="https://github.com/discourse/discourse_docker">Discourse Docker</a></li>
</ul>
<h2 id="nix-expression-4"><a class="header" href="#nix-expression-4">Nix expression</a></h2>
<pre><code class="language-nix">{ sources, ... }: {
  imports = sources.defaultModules ++ [ ../modules ];

  # Enable Docker since we use the official Docker image in /var/discourse
  virtualisation.docker.enable = true;

  # Open required port
  networking.firewall.allowedTCPPorts = [ 80 ];

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="github-runner"><a class="header" href="#github-runner">github-runner</a></h1>
<h2 id="general-5"><a class="header" href="#general-5">General</a></h2>
<p>With this container, we provide a GitHub runner. This container does <strong>not</strong> have the regular Garuda configurations because it is considered untrusted. Access needs to happen by running <code>nixos-container root-login</code> on <code>immortalis</code> (<a href="http://docs.garudalinux.net/hosts/immortalis.html#connecting-to-the-server">click me</a>).</p>
<h2 id="nix-expression-5"><a class="header" href="#nix-expression-5">Nix expression</a></h2>
<pre><code class="language-nix">{ keys
, pkgs
, ...
}: {
  # No default modules, untrusted container!
  # imports = sources.defaultModules ++ [
  #   ./garuda/garuda.nix
  # ];

  imports = [
    ../modules/hardening.nix
    ../modules/motd.nix
    ../services/docker-compose-runner/docker-compose-runner.nix
  ];

  # Common Docker configurations
  virtualisation.docker = {
    autoPrune.enable = true;
    autoPrune.flags = [ &quot;-a&quot; ];
    package = pkgs.docker_24; # Until the man pages are fixed in pkgs.docker
  };

  # This container is just for docker-compose stuff
  services.docker-compose-runner.github-runner = {
    args = &quot;run github-runner&quot;;
    envfile = &quot;/var/garuda/secrets/github-runner.env&quot;;
    source = ../../docker-compose/github-runner;
  };

  # Enable SSH
  services.openssh.enable = true;

  # No custom users - oonly Pedro and root via nixos-container root-login
  users.allowNoPasswordLogin = true;
  users.mutableUsers = false;
  users.users.pedrohlc = {
    home = &quot;/home/pedrohlc&quot;;
    isNormalUser = true;
    openssh.authorizedKeys.keyFiles = [ keys.pedrohlc ];
  };

  # Make Pedro god here
  security.sudo.extraRules = [{
    users = [ &quot;pedrohlc&quot; ];
    commands = [{
      command = &quot;ALL&quot;;
      options = [ &quot;NOPASSWD&quot; ];
    }];
  }];

  # OOM prevention
  systemd.oomd = {
    enable = true; # This is actually the default, anyways...
    enableSystemSlice = true;
    enableUserServices = true;
  };

  system.stateVersion = &quot;23.05&quot;;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="lemmy"><a class="header" href="#lemmy">lemmy</a></h1>
<h2 id="general-6"><a class="header" href="#general-6">General</a></h2>
<p>This container provides our Lemmy instance</p>
<h2 id="nix-expression-6"><a class="header" href="#nix-expression-6">Nix expression</a></h2>
<pre><code class="language-nix">{ garuda-lib
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # Our Lemmy instance
  services.lemmy = {
    database.uri = &quot;postgresql://lemmy:${garuda-lib.secrets.lemmy.database}@10.0.5.50/lemmy&quot;;
    enable = true;
    settings = {
      hostname = &quot;lemmy.garudalinux.org&quot;;
      email = {
        smtp_server = &quot;mail.garudalinux.net:587&quot;;
        smtp_login = &quot;noreply@garudalinux.org&quot;;
        inherit (garuda-lib.secrets.lemmy) smtp_password;
        smtp_from_address = &quot;noreply@garudalinux.org&quot;;
        tls_type = &quot;starttls&quot;;
      };
    };
  };

  services.nginx = {
    enable = true;
    httpConfig = ''
      map &quot;$request_method:$http_accept&quot; $proxpass {
          # If no explicit matches exists below, send traffic to lemmy-ui
          default &quot;http://lemmy-ui&quot;;

          # GET/HEAD requests that accepts ActivityPub or Linked Data JSON should go to lemmy
          # &quot;~^(?:GET|HEAD):.*?application\/(?:activity|ld)\+json&quot; &quot;http://lemmy&quot;;

          # All non-GET/HEAD requests should go to lemmy
          &quot;~^(?!(GET|HEAD)).*:&quot; &quot;http://lemmy&quot;;
      }

      upstream lemmy {
        server &quot;127.0.0.1:8536&quot;;
      }
      upstream lemmy-ui {
        server &quot;127.0.0.1:1234&quot;;
      }
      
      server {
          listen 80;
          
          server_name lemmy.garudalinux.org;
          server_tokens off;

          gzip on;
          gzip_types text/css application/javascript image/svg+xml;
          gzip_vary on;

          client_max_body_size 25M;

          add_header X-Frame-Options SAMEORIGIN;
          add_header X-Content-Type-Options nosniff;
          add_header X-XSS-Protection &quot;1; mode=block&quot;;

          # frontend general requests
          location / {
              proxy_pass $proxpass;
              rewrite ^(.+)/+$ $1 permanent;
              proxy_set_header X-Real-IP $remote_addr;
              proxy_set_header Host $host;
          }

          # backend
          location ~ ^/(api|pictrs|feeds|nodeinfo|.well-known) {
              proxy_pass &quot;http://lemmy&quot;;
              proxy_http_version 1.1;
              proxy_set_header Upgrade $http_upgrade;
              proxy_set_header Connection &quot;upgrade&quot;;
              proxy_set_header X-Real-IP $remote_addr;
              proxy_set_header Host $host;
          }
      }
    '';
  };

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mastodon"><a class="header" href="#mastodon">mastodon</a></h1>
<h2 id="general-7"><a class="header" href="#general-7">General</a></h2>
<p>This container provides our Mastodon instance.</p>
<h2 id="nix-expression-7"><a class="header" href="#nix-expression-7">Nix expression</a></h2>
<pre><code class="language-nix">{ lib
, pkgs
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # Our Mastodon
  services.mastodon = {
    configureNginx = true;
    database = {
      createLocally = false;
      host = &quot;10.0.5.50&quot;;
      name = &quot;mastodon&quot;;
      passwordFile = &quot;/var/lib/mastodon/secrets/db-password&quot;;
      user = &quot;mastodon&quot;;
    };
    enable = true;
    extraConfig = {
      &quot;LOCAL_DOMAIN&quot; = &quot;garudalinux.org&quot;;
      &quot;SMTP_DOMAIN&quot; = &quot;social.garudalinux.org&quot;;
      &quot;WEB_DOMAIN&quot; = &quot;social.garudalinux.org&quot;;
    };
    localDomain = &quot;social.garudalinux.org&quot;;
    mediaAutoRemove.enable = false;
    smtp = {
      authenticate = true;
      fromAddress = &quot;noreply@garudalinux.org&quot;;
      host = &quot;mail.garudalinux.net&quot;;
      passwordFile = &quot;/var/lib/mastodon/secrets/smtp-password&quot;;
      port = 587;
      user = &quot;noreply@garudalinux.org&quot;;
    };
    trustedProxy = &quot;10.0.5.10&quot;;
  };

  # Run daily cleanup of statuses and media of Mastodon
  systemd.services.mastodon-media-cleanup = {
    description = &quot;Run daily cleanup of statuses and media of Mastodon&quot;;
    serviceConfig = {
      ExecStart = pkgs.writeShellScript &quot;execstart&quot; ''
        set -e
        /run/current-system/sw/bin/mastodon-tootctl media remove --days=30
        /run/current-system/sw/bin/mastodon-tootctl statuses remove --days=30
      '';
      Path = [ pkgs.mastodon ];
      Restart = &quot;on-failure&quot;;
      RestartSec = &quot;30&quot;;
    };
    wantedBy = [ &quot;multi-user.target&quot; ];
  };
  systemd.timers.mastodon-media-cleanup = {
    description = &quot;Monthly cleanup of statuses and media of Mastodon&quot;;
    timerConfig.OnCalendar = [ &quot;monthly&quot; ];
    wantedBy = [ &quot;timers.target&quot; ];
  };

  # Scan for orphaned media mo
  systemd.services.mastodon-orphan-cleanup = {
    description = &quot;Run weekly cleanup of orphaned media of Mastodon&quot;;
    serviceConfig = {
      ExecStart = pkgs.writeShellScript &quot;execstart&quot; ''
        set -e
        /run/current-system/sw/bin/mastodon-tootctl media remove --days=7
        /run/current-system/sw/bin/mastodon-tootctl statuses remove --days=7
      '';
      Path = [ pkgs.mastodon ];
      Restart = &quot;on-failure&quot;;
      RestartSec = &quot;30&quot;;
    };
    wantedBy = [ &quot;multi-user.target&quot; ];
  };
  systemd.timers.mastodon-orphan-cleanup = {
    description = &quot;Run weekly cleanup of orphaned media of Mastodon&quot;;
    timerConfig.OnCalendar = [ &quot;weekly&quot; ];
    wantedBy = [ &quot;timers.target&quot; ];
  };

  services.nginx.virtualHosts.&quot;social.garudalinux.org&quot; = {
    enableACME = lib.mkForce false;
    extraConfig = ''
      set_real_ip_from 10.0.5.10;
      real_ip_header X-Forwarded-For;
    '';
    useACMEHost = &quot;garudalinux.org&quot;;
  };

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="meshcentral"><a class="header" href="#meshcentral">meshcentral</a></h1>
<h2 id="general-8"><a class="header" href="#general-8">General</a></h2>
<p>The sole purpose of this container is to provide Meshcentral, which is being used for remote access to our servers.</p>
<h2 id="nix-expression-8"><a class="header" href="#nix-expression-8">Nix expression</a></h2>
<pre><code class="language-nix">{ pkgs
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # Meshcentral for easy remote access
  # manual installation as Nix version is outdated
  environment.systemPackages = with pkgs; [ nodejs ];
  systemd.services.meshcentral = {
    wantedBy = [ &quot;multi-user.target&quot; ];
    after = [ &quot;network-online.target&quot; ];
    environment = { &quot;NODE_ENV&quot; = &quot;production&quot;; };
    path = [ pkgs.nodejs ];
    serviceConfig = {
      ExecStart =
        ''&quot;${pkgs.nodejs}/bin/node&quot; /opt/meshcentral/node_modules/meshcentral'';
      Group = &quot;meshcentral&quot;;
      PrivateTmp = &quot;true&quot;;
      Restart = &quot;always&quot;;
      RestartSec = 10;
      User = &quot;meshcentral&quot;;
      WorkingDirectory = &quot;/opt/meshcentral&quot;;
    };
  };

  # Create Meshcentral user and group for the service to use
  users.groups.meshcentral = { };
  users.users.meshcentral = {
    home = &quot;/opt/meshcentral&quot;;
    group = &quot;meshcentral&quot;;
    isNormalUser = true;
  };

  # Open up ports for Meshcentral
  networking.firewall.allowedTCPPorts = [ 22260 22261 ];

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="postgres"><a class="header" href="#postgres">postgres</a></h1>
<h2 id="general-9"><a class="header" href="#general-9">General</a></h2>
<p>This container houses our Postgres database. Multiple servces access it:</p>
<ul>
<li>Lemmy</li>
<li>Mastodon</li>
<li>Matrix</li>
<li>Matrix bridges</li>
<li>MeshCentral</li>
<li>WikiJs</li>
</ul>
<h2 id="nix-expression-9"><a class="header" href="#nix-expression-9">Nix expression</a></h2>
<pre><code class="language-nix">{ garuda-lib
, pkgs
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # Our Postgres database
  services.postgresql = {
    enable = true;
    ensureDatabases = [
      &quot;lemmy&quot;
      &quot;matrix-discord&quot;
      &quot;matrix-irc&quot;
      &quot;matrix-telegram&quot;
      &quot;meshcentral&quot;
      &quot;synapse&quot;
      &quot;wikijs&quot;
    ];
    ensureUsers = [
      {
        name = &quot;lemmy&quot;;
        ensurePermissions = { &quot;DATABASE lemmy&quot; = &quot;ALL PRIVILEGES&quot;; };
      }
      {
        name = &quot;mastodon&quot;;
        ensurePermissions = { &quot;DATABASE mastodon&quot; = &quot;ALL PRIVILEGES&quot;; };
      }
      {
        name = &quot;matrix-bridges&quot;;
        ensurePermissions = {
          &quot;DATABASE \&quot;matrix-telegram\&quot;&quot; = &quot;ALL PRIVILEGES&quot;;
          &quot;DATABASE \&quot;matrix-discord\&quot;&quot; = &quot;ALL PRIVILEGES&quot;;
          &quot;DATABASE \&quot;matrix-irc\&quot;&quot; = &quot;ALL PRIVILEGES&quot;;
        };
      }
      {
        name = &quot;meshcentral&quot;;
        ensurePermissions = { &quot;DATABASE meshcentral&quot; = &quot;ALL PRIVILEGES&quot;; };
      }
      {
        name = &quot;synapse&quot;;
        ensurePermissions = { &quot;DATABASE synapse&quot; = &quot;ALL PRIVILEGES&quot;; };
      }
      {
        name = &quot;wikijs&quot;;
        ensurePermissions = { &quot;DATABASE wikijs&quot; = &quot;ALL PRIVILEGES&quot;; };
      }
    ];
    initialScript = pkgs.writeText &quot;backend-initScript&quot; ''
      CREATE USER netdata;
      GRANT pg_monitor TO netdata;
    '';
    authentication = &quot;host all all 10.0.5.0/24 md5&quot;;
    # We don't need to worry about different interfaces, because the only interface 
    # available is eth0, which is fully isolated
    enableTCPIP = true;
  };

  # Regular backups for our database (every 6h)
  services.postgresqlBackup = {
    compression = &quot;zstd&quot;;
    enable = true;
    location = &quot;/var/garuda/backups/postgres&quot;;
  };

  # Run daily synapse state compressor on Matrix database
  systemd.services.synapse_auto_compressor = {
    description = &quot;Run synapse state compressor on Matrix db&quot;;
    serviceConfig = {
      ExecStart = pkgs.writeShellScript &quot;execstart&quot; ''
        set -e
        ${pkgs.matrix-synapse-tools.rust-synapse-compress-state}/bin/synapse_auto_compressor \
          -p postgresql://${garuda-lib.secrets.matrix.db_string}@10.0.5.50/synapse -c 500 -n 100
      '';
      Restart = &quot;on-failure&quot;;
      RestartSec = &quot;30&quot;;
    };
    wantedBy = [ &quot;multi-user.target&quot; ];
  };
  systemd.timers.synapse_auto_compressor = {
    description = &quot;Run synapse state compressor on Matrix db&quot;;
    timerConfig.OnCalendar = [ &quot;daily&quot; ];
    wantedBy = [ &quot;timers.target&quot; ];
  };

  # Open up ports for Postgres
  networking.firewall.allowedTCPPorts = [ 5432 ];

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="repo"><a class="header" href="#repo">repo</a></h1>
<h2 id="general-10"><a class="header" href="#general-10">General</a></h2>
<p>This is another package builder, that builds packages for our <code>[garuda]</code> repository.</p>
<h2 id="nix-expression-10"><a class="header" href="#nix-expression-10">Nix expression</a></h2>
<pre><code class="language-nix">{ pkgs
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # Enable Chaotic-AUR building
  services.chaotic.enable = true;
  services.chaotic.cluster-name = &quot;garuda-repo&quot;;
  services.chaotic.host = &quot;repo.garudalinux.org&quot;;
  services.chaotic.extraConfig = ''
    export CAUR_DEPLOY_LABEL=&quot;Maximus 🐉&quot;
    export CAUR_LOWER_PKGS+=(chaotic-mirrorlist chaotic-keyring)
    export CAUR_PACKAGER=&quot;Garuda Builder &lt;team@garudalinux.org&gt;&quot;
    export CAUR_SIGN_KEY=D6C9442437365605
    export CAUR_ROUTINES=/tmp/chaotic/routines
    export CAUR_SIGN_USER=root
    export CAUR_TELEGRAM_TAG=&quot;@dr460nf1r3&quot;

    export GIT_SSH_COMMAND=&quot;ssh -i /var/garuda/secrets/chaotic/interfere_ed25519&quot;
    export HTTP_PROXY=http://10.0.5.1:3128/
    export HTTPS_PROXY=http://10.0.5.1:3128/
    export NO_PROXY=mirror.rackspace.com,cloudflaremirrors.com,github.com,downloads.sentry-cdn.com
  '';
  services.chaotic.db-name = &quot;garuda&quot;;
  services.chaotic.routines = [ &quot;hourly&quot; ];
  services.chaotic.patches = [ ../services/chaotic/add-chaotic-repo.diff ];
  services.chaotic.useACMEHost = &quot;garudalinux.org&quot;;

  # Allow systemd-nspawn to create subcgroups (for Chaotic-AUR builders)
  systemd.services.remount-sysfscgroup = {
    description = &quot;Remount cgroup2 to allow systemd-nspawn to create subcgroups&quot;;
    wantedBy = [ &quot;multi-user.target&quot; ];
    serviceConfig.Type = &quot;oneshot&quot;;
    script = ''
      ${pkgs.mount}/bin/mount -t cgroup2 -o rw,nosuid,nodev,noexec,relatime none /sys/fs/cgroup
    '';
  };

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="temeraire"><a class="header" href="#temeraire">temeraire</a></h1>
<h2 id="general-11"><a class="header" href="#general-11">General</a></h2>
<p>This is our package builder, which also serves as main node for Chaotic-AUR.</p>
<h2 id="nix-expression-11"><a class="header" href="#nix-expression-11">Nix expression</a></h2>
<pre><code class="language-nix">{ config
, garuda-lib
, pkgs
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # This disables HTTPS certificates and forced redirects
  garuda-lib.behind_proxy = true;

  # Enable Chaotic-AUR building
  services.chaotic.enable = true;
  services.chaotic.cluster-name = &quot;garuda-cluster&quot;;
  # Let nginx set itself up for this local domain
  services.chaotic.host = &quot;local.chaotic.invalid&quot;;
  services.chaotic.extraConfig = ''
    export CAUR_DEPLOY_LABEL=&quot;Temeraire 🐉&quot;
    export CAUR_PACKAGER=&quot;Garuda Builder &lt;team@garudalinux.org&gt;&quot;
    export CAUR_ROUTINES=/tmp/chaotic/routines
    export CAUR_SIGN_KEY=D6C9442437365605
    export CAUR_SIGN_USER=root
    export CAUR_TELEGRAM_TAG=&quot;@dr460nf1r3&quot;
    export CAUR_TYPE=primary
    export CAUR_URL=https://builds.garudalinux.org/repos/chaotic-aur/x86_64
    export REPOCTL_CONFIG=/usr/local/etc/chaotic-repoctl.toml

    export GIT_SSH_COMMAND=&quot;ssh -i /var/garuda/secrets/chaotic/interfere_ed25519&quot;
    export HTTPS_PROXY=http://10.0.5.1:3128/
    export HTTP_PROXY=http://10.0.5.1:3128/
    export NO_PROXY=mirror.rackspace.com,cloudflaremirrors.com,github.com,downloads.sentry-cdn.com
  '';
  services.chaotic.db-name = &quot;chaotic-aur&quot;;
  services.chaotic.routines = [ &quot;afternoon&quot; &quot;hourly.1&quot; &quot;hourly.2&quot; &quot;morning&quot; &quot;nightly&quot; &quot;tkg-wine&quot; ];

  # Special Syncthing configuration allowing to push to main node
  services.syncthing = {
    enable = true;
    openDefaultPorts = true;
    configDir = config.services.syncthing.dataDir;
    inherit (garuda-lib.secrets.syncthing.esxi-build) cert;
    inherit (garuda-lib.secrets.syncthing.esxi-build) key;
    overrideFolders = false;
    overrideDevices = false;
    user = &quot;root&quot;;
    group = &quot;chaotic_op&quot;;
    settings = {
      gui = {
        apikey = &quot;garudalinux&quot;;
        insecureSkipHostcheck = true;
      };
    };
  };

  # Cloudflared access to Syncthing webinterface
  services.garuda-cloudflared = {
    enable = true;
    ingress = { &quot;syncthing-build.garudalinux.net&quot; = &quot;http://localhost:8384&quot;; };
    tunnel-credentials =
      garuda-lib.secrets.cloudflare.cloudflared.esxi-build.cred;
  };

  # Allow systemd-nspawn to create subcgroups (for Chaotic-AUR builders)
  systemd.services.remount-sysfscgroup = {
    description = &quot;Remount cgroup2 to allow systemd-nspawn to create subcgroups&quot;;
    wantedBy = [ &quot;multi-user.target&quot; ];
    serviceConfig.Type = &quot;oneshot&quot;;
    script = ''
      ${pkgs.mount}/bin/mount -t cgroup2 -o rw,nosuid,nodev,noexec,relatime none /sys/fs/cgroup
    '';
  };

  # Auto reset syncthing stuff
  systemd.services.syncthing-reset = {
    serviceConfig.Type = &quot;oneshot&quot;;
    script = ''
      &quot;${pkgs.curl}/bin/curl&quot; -X POST -H &quot;X-API-Key: garudalinux&quot; http://localhost:8384/rest/db/override?folder=${garuda-lib.secrets.syncthing.folders.chaotic-aur}
    '';
  };
  systemd.timers.syncthing-reset = {
    wantedBy = [ &quot;timers.target&quot; ];
    timerConfig.OnCalendar = [ &quot;hourly&quot; ];
  };

  # Chaotic-AUR builders need to upload their packages
  users.users.ufscar_hpc = {
    extraGroups = [ &quot;chaotic_op&quot; ];
    isNormalUser = true;
    openssh.authorizedKeys.keys = [
      &quot;ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIFslN7a613H3hztK/yzHE4ZBOJ4448+EN867Y/IDpAfc u726578@c6.cluster.infra.ufscar.br&quot;
    ];
  };
  users.users.catbuilder = {
    extraGroups = [ &quot;chaotic_op&quot; ];
    isNormalUser = true;
    openssh.authorizedKeys.keys = [
      &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDHELhrMFNvxgAYMdzwerszypuvQc3uCFjkR6xCbcQnrcCrueJqTQ4y8WzddwxhRzKbSTQVhPdB5l95IYk7eOtmBmaMp4LAV2osMWDI/x3NyoY5s7YgpW815qNX9Io7VnrFUr0LK7hJ+Uw87nyxGp3zGddPVMUK7PIdJf2GxTxKPryycdLa9QWijfm3YBdN10yBMp6KrfPEnhtmNPMrc3wuBG4+xBoJxNOy0DJdIf2PRwU2CddP0zdDWwlMbGeHGcaJmlAx0u9e1jL8KWB/oyGT1D9q4l+fU8E9nZG+kAFMO1yG25je9bJnYNPMV1gdRT47G3J/B982XYO4G4AiOER0v0M0MN0qWTvIVBG6Vnly81ME91Qao34Lw2QOhZMVFwWz01u8KLLQy/Z2rX7jKyqeUyGXgs5NPmkeJ1vzpSRLXY+5GX5yva8A041Nft7sfKYPFjMsDaxAKVPz7LkKX1dYdiC4c3a/RcCzLKY+Uabjr0QAK4MKwmMW+SNF0QHr9mk= root@Chaotic&quot;
    ];
  };
  users.users.chaotic-dragon = {
    extraGroups = [ &quot;chaotic_op&quot; ];
    isNormalUser = true;
    openssh.authorizedKeys.keys = [
      &quot;ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQC0zLuPM4IE4xsxen2XBqWKSQz5CpHONgguOhVuR5rTxRqijiwGro0VR4gPhpmuZjLkms4CJ2YGyjTbjDkh48+wAoiPjdvVqF6kJ9TLkHZabMJfx5chKMCVFcHM+0/F768fF/nRsfusbRO7H2nLGMXJ1eObemiCGg0e8Ccs0XA4PF9bGaDm+4bblNasVyT6PsnaYziyBtwU3fzBVbdQmErw37sjXV9jNsEq3XF9wSaFf/Dfzh9xY1CR1KC7Af84lL1vOj7QL06tEmDO6W4JJCpRS4OonpuahwaaR4gn6wW09eDgrpXUI5DhxGizwGPLdwENRONpcXP0xnWetC9IaUADHb9yZwQKZhN9RCoO5ytqrt/NkGfn7Si+mWSfMQRGvfgJocC89peIhbchXalT+JS1XWD+Isvj2I+sqmAcoKgji09MTF0lMW+m83/+YA7Jdhn5CLVs9RxZ5cwz1TqveuUaq4i9P867iKCltrqZxxgXD4emZXhHGvGrw8cNQZOVAhc= root@chaotic-dragon&quot;
    ];
  };
  users.users.dragons-ryzen = {
    extraGroups = [ &quot;chaotic_op&quot; ];
    isNormalUser = true;
    openssh.authorizedKeys.keys = [
      &quot;ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIAd8nLLjysVefmk3I6BI/IkooUvnGSy7966T54gWNvgW nico@slim-lair&quot;
    ];
  };

  # Ufscar-HPC needs diffie-hellman-group-exchange-sha1
  services.openssh.settings = {
    KexAlgorithms = [
      &quot;curve25519-sha256&quot;
      &quot;curve25519-sha256@libssh.org&quot;
      &quot;diffie-hellman-group-exchange-sha1&quot;
      &quot;diffie-hellman-group16-sha512&quot;
      &quot;diffie-hellman-group18-sha512&quot;
      &quot;sntrup761x25519-sha512@openssh.com&quot;
    ];
  };

  # Our main webserver on this machine
  services.nginx = {
    enable = true;
    virtualHosts = {
      &quot;builds.garudalinux.org&quot; = {
        extraConfig = ''
          # Our beautiful autoindex theme
          autoindex on;
          autoindex_exact_size off;
          autoindex_format xml;
          xslt_string_param path $uri;
          xslt_string_param hostname &quot;Chaotic-AUR main node - Temeraire&quot;;

          # Security
          add_header X-XSS-Protection          &quot;1; mode=block&quot; always;
          add_header X-Content-Type-Options    &quot;nosniff&quot; always;
          add_header Referrer-Policy           &quot;no-referrer-when-downgrade&quot; always;
          add_header Content-Security-Policy   &quot;default-src 'self' http: https: data: blob: 'unsafe-inline'; frame-ancestors 'self';&quot; always;
          add_header Permissions-Policy        &quot;interest-cohort=()&quot; always;

          # Locations
          location ~* ^.+\.log {
              default_type text/plain;
          }
          location ~* /repos/(chaotic-aur|garuda)/x86_64/(?!.*(chaotic-aur|garuda)\.(db|files)).+\.tar.* {
              return 301 https://cf-builds.garudalinux.org$request_uri;
              expires 2d;
          }
          location / {
              xslt_string_param path $uri;
              xslt_string_param hostname &quot;Chaotic-AUR main node - Temeraire 🐉&quot;;
              xslt_stylesheet &quot;${garuda-lib.xslt_style}&quot;;
              location /iso {
                  expires 2d;
                  return 301 https://iso.builds.garudalinux.org$request_uri;
              }
          }
        '';
        http3 = true;
        root = &quot;/srv/http/&quot;;
      };
      &quot;cf-builds.garudalinux.org&quot; = {
        extraConfig = ''
          location ~* /repos/(chaotic-aur|garuda)/x86_64/(?!.*(chaotic-aur|garuda)\.(db|files)).+\.tar.* {
              add_header Cache-Control &quot;max-age=150, stale-while-revalidate=150, stale-if-error=86400&quot;;
          }
          location ~* /repos/(chaotic-aur|garuda)/x86_64/(chaotic-aur|garuda)\.db.* {
              add_header Cache-Control 'no-cache';
          }
          location /repos/chaotic-aur {
              expires 5m;
              error_page 403 =301 https://builds.garudalinux.org$request_uri;
              error_page 404 =301 https://builds.garudalinux.org$request_uri;
          }
          location /repos/garuda {
              expires 5m;
              error_page 403 =301 https://builds.garudalinux.org$request_uri;
              error_page 404 =301 https://builds.garudalinux.org$request_uri;
          }
          location / {
              expires 2d;
              return 301 https://builds.garudalinux.org$request_uri;
          }
        '';
        http3 = true;
        root = &quot;/srv/http/&quot;;
      };
      &quot;iso.builds.garudalinux.org&quot; = {
        extraConfig = ''
          autoindex on;
          autoindex_format xml;
          xslt_string_param path $uri;
          xslt_string_param hostname &quot;Garuda Linux ISO Builds&quot;;
        '';
        locations.&quot;/iso&quot; = {
          root = &quot;/var/garuda/buildiso&quot;;
          extraConfig = ''
            xslt_stylesheet &quot;${garuda-lib.xslt_style}&quot;;
            if ($symlink_target_rel != &quot;&quot;) {
              rewrite ^ https://$server_name/iso/$symlink_target_rel redirect;
            }
            if ($arg_usa) {
              rewrite ^/iso/(.*)$ https://us-ny-mirror.garudalinux.org/iso/$1? permanent;
            }
            if ($arg_sourceforge) {
              rewrite ^/iso/(.*)$ https://sourceforge.net/projects/garuda-linux/files/$1? permanent;
            }
            if ($arg_osdn) {
              rewrite ^/iso/(.*)$ https://osdn.net/projects/garuda-linux/storage/$1? permanent;
            }
            if ($arg_r2) {
              set $args &quot;&quot;;
              rewrite ^/iso/(.*)$ https://r2.garudalinux.org/iso/$1?r2request permanent;
            }
            break;
          '';
        };
      };
    };
  };

  # Explicitly open our firewall ports - HTTPS &amp; rsyncd
  networking.firewall.allowedTCPPorts = [ config.services.rsyncd.port ];

  # Our rsyncd server
  services.rsyncd = {
    enable = true;
    settings = {
      chaotic = {
        &quot;read only&quot; = &quot;yes&quot;;
        comment = &quot;Chaotic-AUR repository&quot;;
        exclude = &quot;/chaotic-aur/archive/*** /chaotic-aur/logs/***&quot;;
        path = &quot;/srv/http/repos/&quot;;
      };
      chaotic-minimal = {
        &quot;read only&quot; = &quot;yes&quot;;
        comment = &quot;Chaotic-AUR repository minus largest packages&quot;;
        exclude = &quot;/chaotic-aur/archive/*** /chaotic-aur/logs/*** /chaotic-aur/x86_64/quartus* /chaotic-aur/x86_64/unrealtournament4* /chaotic-aur/x86_64/urbanterror*&quot;;
        path = &quot;/srv/http/repos/&quot;;
      };
      iso = {
        path = &quot;/var/garuda/buildiso/iso/&quot;;
        comment = &quot;ISO downloads&quot;;
        &quot;read only&quot; = &quot;yes&quot;;
      };
      global = {
        &quot;max connections&quot; = 80;
        &quot;max verbosity&quot; = 3;
        &quot;transfer logging&quot; = true;
        &quot;use chroot&quot; = false;
        gid = &quot;nobody&quot;;
        uid = &quot;nobody&quot;;
      };
    };
  };

  # Push chaotic to r2 hourly automatically
  services.garuda-rclone.chaotic = {
    src = &quot;/srv/http/repos/&quot;;
    dest = &quot;r2:/mirror/repos&quot;;
    config = garuda-lib.secrets.cloudflare.r2.rclone;
    args = &quot;--s3-upload-cutoff 5G --s3-chunk-size 4G --fast-list --s3-no-head --s3-no-check-bucket --ignore-checksum --s3-disable-checksum -u --use-server-modtime --delete-during --delete-excluded --include /*/x86_64/*.pkg.tar.zst --include /*/lastupdate --order-by modtime,ascending --stats-log-level NOTICE&quot;;
    startAt = &quot;hourly&quot;;
  };
  systemd.services.chaotic-rclone-inotify = {
    wantedBy = [ &quot;multi-user.target&quot; ];
    after = [ &quot;network-online.target&quot; ];
    # Get all file changes, upload pkg.tar.zst. Not more than 5 per 5 seconds queued and only one uploaded at the same time. Queue dropped if uploading takes longer than 15 seconds.
    # This prevents the queue from getting overloaded with nonsense requests if that ever were to happen. The hourly sync should take care of this.
    script = ''
      upload() {
        operation=&quot;''${1%%|*}&quot;
        path=&quot;''${1#*|}&quot;
        relative=&quot;$(realpath --relative-to=&quot;.&quot; &quot;$path&quot;)&quot;
        relative=&quot;''${relative#./}&quot;
        destpath=&quot;r2:/mirror/$relative&quot;
        if [ &quot;$operation&quot; != &quot;MOVED_FROM&quot; ]; then
        ${pkgs.flock}/bin/flock -w 30 /tmp/chaotic-rclone-inotify.lock \
          ${pkgs.rclone}/bin/rclone copyto &quot;$path&quot; &quot;$destpath&quot; --s3-upload-cutoff 5G --s3-chunk-size 4G --s3-no-head --no-check-dest --s3-no-check-bucket --ignore-checksum --s3-disable-checksum --config &quot;${garuda-lib.secrets.cloudflare.r2.rclone}&quot; --stats-one-line -v
        else
          ${pkgs.flock}/bin/flock -w 30 /tmp/chaotic-rclone-inotify.lock ${pkgs.rclone}/bin/rclone deletefile &quot;$destpath&quot; --s3-no-head --no-check-dest --s3-no-check-bucket --config &quot;${garuda-lib.secrets.cloudflare.r2.rclone}&quot; --stats-one-line -v
          (
            ${pkgs.flock}/bin/flock -w 200 -s 200
            ${pkgs.curl}/bin/curl -s -X POST &quot;https://api.cloudflare.com/client/v4/zones/$CF_ZONE_GARUDALINUX_ORG/purge_cache&quot; -H &quot;Authorization: Bearer $CF_CACHE_API_TOKEN&quot; -H &quot;Content-Type:application/json&quot; --data &quot;{\&quot;files\&quot;:[\&quot;https://r2.garudalinux.org/''${relative}\&quot;]}&quot;
            sleep 0.5
          ) 200&gt;/tmp/chaotic-rclone-inotify-invalidate.lock
        fi
      }
      export -f upload
      ${pkgs.inotify-tools}/bin/inotifywait -m ./repos/*/x86_64 -e CLOSE_WRITE,MOVED_TO,MOVED_FROM --format &quot;%e|%w%f&quot; | \
        ${pkgs.gawk}/bin/awk '/\.pkg\.tar\.zst$/ { print $0; fflush(); }' | \
        xargs -rP 0 -I % ${pkgs.bash}/bin/bash -c 'upload &quot;%&quot;'
    '';
    serviceConfig = {
      EnvironmentFile = garuda-lib.secrets.cloudflare.apikeys;
      Restart = &quot;always&quot;;
      WorkingDirectory = &quot;/srv/http&quot;;
    };
  };

  system.stateVersion = &quot;23.05&quot;;
}

</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="web-front"><a class="header" href="#web-front">web-front</a></h1>
<h2 id="general-12"><a class="header" href="#general-12">General</a></h2>
<p>This container is used as reverse proxy for all of our public facing services.</p>
<h2 id="nix-expression-12"><a class="header" href="#nix-expression-12">Nix expression</a></h2>
<pre><code class="language-nix">{ garuda-lib
, sources
, ...
}: {
  imports = sources.defaultModules ++ [ ../modules ];

  # Reverse proxy for our docker-compose stack
  services.nginx = {
    enable = true;
    virtualHosts = {
      &quot;garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = {
            index = &quot;index.html&quot;;
            root = sources.garuda-website;
          };
          &quot;/discord&quot; = {
            extraConfig = &quot;expires 12h;&quot;;
            return = &quot;307 https://discord.gg/w5jbhq3juh&quot;;
          };
          &quot;/telegram&quot; = {
            extraConfig = &quot;expires 12h;&quot;;
            return = &quot;307 https://t.me/garudalinux&quot;;
          };
          &quot;/os/garuda-update/backuprepo&quot; = {
            extraConfig = ''
              rewrite ^/os/garuda-update/backuprepo/(.*)$ https://geo-mirror.chaotic.cx/chaotic-aur/$1 redirect;
            '';
          };
          &quot;/os/garuda-update/remote-update&quot; = {
            extraConfig = &quot;expires 12h;&quot;;
            return =
              &quot;301 https://gitlab.com/garuda-linux/themes-and-settings/settings/garuda-common-settings/-/snippets/2147440/raw/main/remote-update&quot;;
          };
          &quot;/os/garuda-update/garuda-hotfixes-version&quot; = {
            extraConfig = &quot;expires 5m;&quot;;
            return = &quot;200 '1'&quot;;
          };
          &quot;/.well-known/webfinger&quot; = {
            extraConfig = &quot;expires 12h;&quot;;
            return = &quot;301 https://social.garudalinux.org$request_uri&quot;;
          };
        };
        quic = true;
        serverAliases = [ &quot;www.garudalinux.org&quot; ];
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;cloud.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = {
            extraConfig = ''
              # Increase our buffer size to allow bigger up- &amp; downloads
              client_max_body_size                  2048M;
              proxy_max_temp_file_size              2048M;
              proxy_request_buffering               off;

              # HSTS headers
              add_header Strict-Transport-Security &quot;max-age=31536000; includeSubdomains; preload&quot; always;

              # Allow accessing through trusted domain
              proxy_set_header Host $host;
              proxy_set_header X-Real-IP $remote_addr;
              set_real_ip_from      172.0.0.0/16;
            '';
            proxyPass = &quot;https://10.0.5.100:443&quot;;
          };
          &quot;/.well-known/carddav&quot; = {
            extraConfig = &quot;expires 12h;&quot;;
            return = &quot;301 $scheme://$host/remote.php/dav&quot;;
          };
          &quot;/.well-known/caldav&quot; = {
            extraConfig = &quot;expires 12h;&quot;;
            return = &quot;301 $scheme://$host/remote.php/dav&quot;;
          };
          &quot;/.well-known/webfinger&quot; = {
            return = &quot;301 $scheme://$host/index.php/.well-known/webfinger&quot;;
            extraConfig = ''
              access_log    off;
              log_not_found off;
            '';
          };
          &quot;/.well-known/nodeinfo&quot; = {
            extraConfig = ''
              access_log    off;
              log_not_found off;
            '';
            return = &quot;301 $scheme://$host/index.php/.well-known/nodeinfo&quot;;
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;search.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.110:5000&quot;; }; };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;searx.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.110:8080&quot;; }; };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;ffsync.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.100:5001&quot;; }; };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;repo.garudalinux.org&quot; = {
        addSSL = true;
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.30:80&quot;; }; };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;start.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.100:8083&quot;; }; };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;irc.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.100:9000&quot;; }; };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;bin.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.100:8082&quot;; }; };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;bitwarden.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = {
            proxyPass = &quot;http://10.0.5.100:8081&quot;;
            proxyWebsockets = true;
          };
        };
        quic = true;
        serverAliases = [ &quot;vault.garudalinux.org&quot; ];
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;status.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = { tryFiles = &quot;/status.html /status.html&quot;; };
          &quot;=/status.html&quot; = {
            extraConfig = &quot;expires 30d;&quot;;
            root = &quot;${sources.garuda-website}/internal&quot;;
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;stats.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = { tryFiles = &quot;/stats.html /stats.html&quot;; };
          &quot;=/stats.html&quot; = {
            extraConfig = &quot;expires 30d;&quot;;
            root = &quot;${sources.garuda-website}/internal&quot;;
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;forum.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          client_max_body_size 100M;
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
          proxy_set_header X-Forwarded-For $remote_addr;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = { proxyPass = &quot;http://10.0.5.70:80&quot;; };
          &quot;/c/announcements/announcements-maintenance/45.json&quot; = {
            extraConfig = &quot;expires 2m;&quot;;
            proxyPass = &quot;http://10.0.5.70:80&quot;;
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;social.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          client_max_body_size 100M;
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = {
            proxyPass = &quot;https://10.0.5.80:443&quot;;
            proxyWebsockets = true;
            extraConfig = ''
              proxy_set_header Host social.garudalinux.org;
            '';
          };
          &quot;/.well-known/webfinger&quot; = {
            proxyPass = &quot;https://10.0.5.80:443&quot;;
            proxyWebsockets = true;
            extraConfig = ''
              proxy_set_header Host social.garudalinux.org;
              if ($args ~* &quot;resource=acct:(.*)@(chaotic.cx|social.garudalinux.org)$&quot;) {
                set $w1 $1;
                rewrite .* /.well-known/webfinger?resource=acct:$w1@garudalinux.org? break;
              }
            '';
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;social-video.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          client_max_body_size 100M;
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
          location ~* .(mp4|webm)$ {
            proxy_pass https://10.0.5.80:443;
            proxy_set_header Host social.garudalinux.org;
          }
        '';
        locations = {
          &quot;/&quot; = { return = &quot;301 https://social.garudalinux.org$request_uri&quot;; };
        };
        http3 = true;
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;builds.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          proxy_buffering off;
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
          proxy_set_header Host $host;
        '';
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.20:80&quot;; }; };
        quic = true;
        serverAliases = [ &quot;cf-builds.garudalinux.org&quot; &quot;iso.builds.garudalinux.org&quot; ];
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;element.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = { proxyPass = &quot;http://10.0.5.100:8084&quot;; };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;wiki.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = { &quot;/&quot; = { proxyPass = &quot;http://10.0.5.100:3001&quot;; }; };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;mesh.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = {
            proxyPass = &quot;http://10.0.5.60:22260&quot;;
            extraConfig = ''
              proxy_http_version 1.1;
              proxy_read_timeout 330s;
              proxy_send_timeout 330s;
              proxy_set_header Connection $http_connection;
              proxy_set_header Upgrade $http_upgrade;
              proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
              proxy_set_header X-Forwarded-Host $host:$server_port;
              proxy_set_header X-Forwarded-Proto $scheme;
            '';
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;mesh.garudalinux.net&quot; = {
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        listen = [
          {
            addr = &quot;127.0.0.1&quot;;
            port = 80;
          }
        ];
        locations = {
          &quot;/&quot; = {
            extraConfig = ''
              proxy_send_timeout 330s;
              proxy_read_timeout 330s;
              proxy_set_header Connection $http_connection;
              proxy_set_header Upgrade $http_upgrade;

              allow 127.0.0.1;
              deny all;

              set $delimeter &quot;&quot;;
              if ($is_args) {
                set $delimeter &quot;&amp;&quot;;
              }
              set $args &quot;$args''${delimeter}user=cfaccess&amp;pass=${garuda-lib.secrets.meshcentral.cfaccess-user}&quot;;
              proxy_pass http://10.0.5.60:22260;
            '';
          };
        };
      };
      &quot;matrix.garudalinux.org&quot; = {
        addSSL = true;
        http3 = true;
        listen = [
          {
            addr = &quot;0.0.0.0&quot;;
            port = 443;
            ssl = true;
          }
          {
            addr = &quot;0.0.0.0&quot;;
            port = 8448;
            ssl = true;
          }
        ];
        locations = {
          &quot;/&quot; = {
            extraConfig = &quot;client_max_body_size 50M;&quot;;
            proxyPass = &quot;http://10.0.5.100:8008&quot;;
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;piped.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          location / {
            ${garuda-lib.setRealIpFromConfig}
            real_ip_header CF-Connecting-IP;
            proxy_buffering off;
            proxy_pass http://10.0.5.110:8088;
            proxy_set_header Host $host;
          }
        '';
        http3 = true;
        quic = true;
        serverAliases = [ &quot;piped-api.garudalinux.org&quot; &quot;piped-proxy.garudalinux.org&quot; ];
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;invidious.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = {
            extraConfig = ''
              proxy_buffering off;
              proxy_set_header Connection &quot;&quot;;
              proxy_http_version 1.1;
            '';
            proxyPass = &quot;http://10.0.5.110:3003&quot;;
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;lemmy.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = {
            extraConfig = ''
              proxy_set_header Host $host;
            '';
            proxyPass = &quot;http://10.0.5.120:80&quot;;
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
      &quot;lingva.garudalinux.org&quot; = {
        addSSL = true;
        extraConfig = ''
          ${garuda-lib.setRealIpFromConfig}
          real_ip_header CF-Connecting-IP;
        '';
        http3 = true;
        locations = {
          &quot;/&quot; = {
            proxyPass = &quot;http://10.0.5.110:3002&quot;;
          };
        };
        quic = true;
        useACMEHost = &quot;garudalinux.org&quot;;
      };
    };
  };

  # Cloudflared access to Meshcentral webinterface
  services.garuda-cloudflared = {
    enable = true;
    ingress = {
      &quot;matrixadmin.garudalinux.net&quot; = &quot;http://10.0.5.100:8085&quot;;
      &quot;mesh.garudalinux.net&quot; = &quot;http://127.0.0.1:80&quot;;
      &quot;test.garudalinux.net&quot; = &quot;http://10.0.5.40:8080&quot;;
      &quot;test2.garudalinux.net&quot; = &quot;http://10.0.5.40:8081&quot;;
    };
    tunnel-credentials =
      garuda-lib.secrets.cloudflare.cloudflared.esxi-web.cred;
  };

  system.stateVersion = &quot;23.05&quot;;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="garuda-mail-netcup-vps"><a class="header" href="#garuda-mail-netcup-vps">garuda-mail (Netcup VPS)</a></h2>
<h3 id="general-13"><a class="header" href="#general-13">General</a></h3>
<p>This system mainly consists of the <a href="https://gitlab.com/simple-nixos-mailserver/nixos-mailserver">simple-nixos-mailserver</a>. Its only purpose is providing a mail service to team members. The current config looks like <a href="https://gitlab.com/garuda-linux/infra-nix/-/blob/main/nixos/hosts/garuda-mail.nix?ref_type=heads#L47">this</a>.
In case of issues, the <a href="https://nixos-mailserver.readthedocs.io/en/latest/">documentation</a> can be consulted.</p>
<h3 id="mail-server-setup"><a class="header" href="#mail-server-setup">Mail server setup</a></h3>
<p>The mail server details are as follows:</p>
<ul>
<li>host: <code>mail.garudalinux.net</code></li>
<li>incoming: IMAP via <code>993</code></li>
<li>outgoing: SMTP via <code>587/465</code></li>
</ul>
<h3 id="backups-1"><a class="header" href="#backups-1">Backups</a></h3>
<p>Backups are happening daily via Borg. A Hetzner storage box is used to store multiple generations of backups.</p>
<h3 id="creating-a-new-user"><a class="header" href="#creating-a-new-user">Creating a new user</a></h3>
<p>A new user can be created be adding a new <code>loginAccounts</code> value and supplying the password via <code>secrets</code>. We make use of <code>hashedPasswordFile</code>, therefore new hashes can be generated by running <code>nix-shell -p mkpasswd --run 'mkpasswd -sm bcrypt'</code>. Add it to the <code>secrets</code>, <code>deploy</code> and <code>apply</code>. Don't forget to commit both changes.</p>
<h3 id="nix-expression-13"><a class="header" href="#nix-expression-13">Nix expression</a></h3>
<pre><code class="language-nix">{ config
, lib
, ...
}: {
  imports = [
    ../modules
    ./garuda-mail/hardware-configuration.nix
  ];

  # Base configuration
  networking.interfaces.ens3.ipv4.addresses = [{
    address = &quot;94.16.112.218&quot;;
    prefixLength = 22;
  }];
  networking.hostName = &quot;garuda-mail&quot;;
  networking.defaultGateway = &quot;94.16.112.3&quot;;

  # GRUB
  boot.loader.grub.devices = [ &quot;/dev/vda&quot; ];

  # Backup configurations to Hetzner storage box
  programs.ssh.macs = [ &quot;hmac-sha2-512&quot; ];
  services.borgbackup.jobs = {
    backupToHetzner = {
      compression = &quot;auto,zstd&quot;;
      doInit = true;
      encryption = {
        mode = &quot;repokey-blake2&quot;;
        passCommand = &quot;cat /var/garuda/secrets/backup/repo_key&quot;;
      };
      environment = {
        BORG_RSH = &quot;ssh -i /var/garuda/secrets/backup/ssh_garuda-mail -p 23&quot;;
      };
      paths = [ config.mailserver.mailDirectory &quot;/var/dkim&quot; ];
      prune.keep = {
        within = &quot;1d&quot;;
        daily = 5;
        weekly = 2;
        monthly = 1;
      };
      repo = &quot;u358867@u358867.your-storagebox.de:./garuda-mail&quot;;
      startAt = &quot;daily&quot;;
    };
  };

  # NixOS Mailserver
  mailserver = {
    certificateScheme = &quot;acme-nginx&quot;;
    dmarcReporting = {
      domain = &quot;garudalinux.org&quot;;
      enable = true;
      organizationName = &quot;Garuda Linux&quot;;
    };
    domains = [ &quot;garudalinux.org&quot; &quot;chaotic.cx&quot; &quot;dr460nf1r3.org&quot; ];
    enable = true;
    enableManageSieve = true;
    # Forwards (mostly chaotic.cx only)
    forwards =
      {
        &quot;coffee-machine@chaotic.cx&quot; = &quot;root@pedrohlc.com&quot;;
        &quot;islandc0der@chaotic.cx&quot; = &quot;jf.mundox@gmail.com&quot;;
        &quot;pedrohlc@chaotic.cx&quot; = &quot;root@pedrohlc.com&quot;;
        &quot;xstefen@chaotic.cx&quot; = &quot;me@xstefen.dev&quot;;
      };
    fqdn = &quot;mail.garudalinux.net&quot;;
    fullTextSearch = {
      enable = true;
      enforced = &quot;body&quot;;
      indexAttachments = true;
      memoryLimit = 512;
    };
    # To create the password hashes, use nix-shell -p mkpasswd --run 'mkpasswd -sm bcrypt'
    loginAccounts = {
      # garudalinux.org
      &quot;cloud@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/cloudatgl&quot;;
        sendOnly = true;
      };
      &quot;complaints@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/complaintsatgl&quot;;
      };
      &quot;dr460nf1r3@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/dr460nf1r3atgl&quot;;
      };
      &quot;filo@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/filoatgl&quot;;
      };
      &quot;gitlab@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/gitlabatgl&quot;;
      };
      &quot;mastodon@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/mastodonatgl&quot;;
        sendOnly = true;
      };
      &quot;naman@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/namanatgl&quot;;
      };
      &quot;noreply@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/noreplyatgl&quot;;
      };
      &quot;rohit@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/rohitatgl&quot;;
      };
      &quot;security@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/securityatgl&quot;;
      };
      &quot;sgs@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/sgsatgl&quot;;
      };
      &quot;spam-reports@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/spam-reportsatgl&quot;;
      };
      &quot;team@garudalinux.org&quot; = {
        aliases = [ &quot;root@garudalinux.org&quot; &quot;webmaster@garudalinux.org&quot; &quot;admin@garudalinux.org&quot; ];
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/teamatgl&quot;;
      };
      &quot;tne@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/tneatgl&quot;;
      };
      &quot;yorper@garudalinux.org&quot; = {
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/yorperatgl&quot;;
      };
      # chaotic.cx
      &quot;actions@chaotic.cx&quot; = {
        aliases = [ &quot;temeraire@chaotic.cx&quot; ];
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/actionsatcx&quot;;
      };
      &quot;nico@chaotic.cx&quot; = {
        aliases = [ &quot;dr460nf1r3@chaotic.cx&quot; &quot;root@chaotic.cx&quot; &quot;webmaster@chaotic.cx&quot; ];
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/nicoatcx&quot;;
      };
      # dr460nf1r3.org
      &quot;nico@dr460nf1r3.org&quot; = {
        aliases = [ &quot;@dr460nf1r3.org&quot; ];
        catchAll = [ &quot;dr460nf1r3.org&quot; ];
        hashedPasswordFile = &quot;/var/garuda/secrets/mail/nicoatdf&quot;;
      };
    };
    indexDir = &quot;/var/lib/dovecot/indices&quot;;
    monitoring = {
      alertAddress = &quot;team@garudalinux.org&quot;;
      enable = true;
    };
    rebootAfterKernelUpgrade.enable = true;
  };

  # Fix dovecot errors caused by failed scudo allocations
  environment.memoryAllocator.provider = lib.mkForce &quot;libc&quot;;

  # Postmaster alias
  services.postfix.postmasterAlias = &quot;nico@dr460nf1r3.org&quot;;

  system.stateVersion = &quot;22.05&quot;;
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="discourse"><a class="header" href="#discourse">Discourse</a></h1>
<p>Discourse is the application we use to host our forum.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="documentation"><a class="header" href="#documentation">Documentation</a></h1>
<h2 id="building-it"><a class="header" href="#building-it">Building it</a></h2>
<p>The documentation is created by using <a href="https://rust-lang.github.io/mdBook/index.html">mdBook</a>, which generates Markdown files and generates HTML pages for them. The documentation can be build by running:</p>
<pre><code class="language-sh">nix build .#docs # plain simple
</code></pre>
<p>The files can then be found at <code>./result/</code>, which is a symlink to the corresponding path in <code>/nix/store</code>. mdBook is also able automatically serve the current content and update it automatically whenever a change is detected. This makes testing and previewing content easy.</p>
<pre><code class="language-sh">mdbook serve --open # the latter additionally opens the website in a browser
</code></pre>
<h2 id="useful-information"><a class="header" href="#useful-information">Useful information</a></h2>
<p>While the general syntax for writing Markdown applies to mdBook, it has several extensions beyond the standard CommonMark specification.</p>
<ul>
<li><a href="https://rust-lang.github.io/mdBook/format/markdown.html">Markdown syntax</a></li>
<li><a href="https://rust-lang.github.io/mdBook/format/mdbook.html">mdBook specific features</a></li>
</ul>
<p>Especially importing code blocks as Markdown is really handy to keep content always up-to-date and helps providing a full text searchable code documentation.</p>
<h2 id="deployment"><a class="header" href="#deployment">Deployment</a></h2>
<p>Deployment to Cloudflare pages automated and happens whenever a commit to main occurs. A <a href="https://github.com/garuda-linux/infrastructure-nix/blob/main/.github/workflows/pages.yml">GitHub actions workflow</a> builds and pushes it to the <code>cf-pages</code> branch, which will then be used by the Cloudflare pages app to deploy the new version from.</p>
<pre><code class="language-yaml">---
name: Cloudflare pages
on:
  push:
    branches: [main]
    paths: [docs/**, README.md]
permissions:
  contents: write
jobs:
  build-and-deploy:
    concurrency: ci-${{ github.ref }}
    runs-on: ubuntu-latest
    steps:
      - name: Checkout 🛎️
        uses: actions/checkout@v4
      - name: Setup mdBook 📜
        uses: peaceiris/actions-mdbook@v1
        with:
          mdbook-version: latest
      - name: Install and Build 🔧
        run: cd docs &amp;&amp; mdbook build
      - name: Deploy 🚀
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_branch: cf-pages
          publish_dir: docs/book
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="credits"><a class="header" href="#credits">Credits</a></h1>
<ul>
<li>https://github.com/mozilla</li>
<li>https://github.com/JetBrains/JetBrainsMono</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>

    </div>
    </body>
</html>
